test,access-control-sys-admin-capability-check,access-control,Ensures that containers do not use SYS_ADMIN capability,skipped,2023-07-26 13:56:17.759758159 -0500 CDT m=+32.370262968,0001-01-01 00:00:00 +0000 UTC,,,"Exception possible if CNF uses mlock(), mlockall(), shmctl(), mmap(); exception will be considered for DPDK applications. Must identify which container requires the capability and detail why. Containers should not use the SYS_ADMIN Linux capability.",NonTelco,Mandatory
test,affiliated-certification-container-is-certified,affiliated-certification,Tests whether container images listed in the configuration file have passed the Red Hat Container Certification Program (CCP).,passed,2023-07-26 13:56:17.761934692 -0500 CDT m=+32.372439494,2023-07-26 13:56:18.912980027 -0500 CDT m=+33.523484832,,,Ensure that your container has passed the Red Hat Container Certification Program (CCP).,NonTelco,Mandatory
test,lifecycle-cpu-isolation,lifecycle,"CPU isolation requires: For each container within the pod, resource requests and limits must be identical. Request and Limits are in the form of whole CPUs. The runTimeClassName must be specified. Annotations required disabling CPU and IRQ load-balancing.",skipped,2023-07-26 13:56:17.761549902 -0500 CDT m=+32.372054703,0001-01-01 00:00:00 +0000 UTC,,,CPU isolation testing is enabled. Please ensure that all pods adhere to the CPU isolation requirements.,NonTelco,Optional
test,networking-dual-stack-service,networking,Checks that all services in namespaces under test are either ipv6 single stack or dual stack. This test case requires the deployment of the debug daemonset.,skipped,2023-07-26 13:56:18.913988715 -0500 CDT m=+33.524493523,0001-01-01 00:00:00 +0000 UTC,,,Configure every CNF services with either a single stack ipv6 or dual stack (ipv4/ipv6) load balancer.,NonTelco,Optional
test,operator-install-status-no-privileges,operator,The operator is not installed with privileged rights. Test passes if clusterPermissions is not present in the CSV manifest or is present with no resourceNames under its rules.,skipped,2023-07-26 13:56:17.75963049 -0500 CDT m=+32.370135295,0001-01-01 00:00:00 +0000 UTC,,,Ensure all the CNF operators have no privileges on cluster resources.,NonTelco,Mandatory
test,access-control-crd-roles,access-control,If an application creates CRDs it must supply a role to access those CRDs and no other API resources/permission. This test checks that there is at least one role present in each namespaces under test that only refers to CRDs under test.,skipped,2023-07-26 13:56:17.76086453 -0500 CDT m=+32.371369332,0001-01-01 00:00:00 +0000 UTC,,,Roles providing access to CRDs should not refer to any other api or resources. Change the generation of the CRD role accordingly,NonTelco,Optional
test,platform-alteration-boot-params,platform-alteration,"Tests that boot parameters are set through the MachineConfigOperator, and not set manually on the Node.",skipped,2023-07-26 13:56:17.759254081 -0500 CDT m=+32.369758886,0001-01-01 00:00:00 +0000 UTC,,,"Ensure that boot parameters are set directly through the MachineConfigOperator, or indirectly through the PerformanceAddonOperator. Boot parameters should not be changed directly through the Node, as OpenShift should manage the changes for you.",NonTelco,Mandatory
test,access-control-ssh-daemons,access-control,Check that pods do not run SSH daemons.,skipped,2023-07-26 13:56:17.760657476 -0500 CDT m=+32.371162277,0001-01-01 00:00:00 +0000 UTC,,,Ensure that no SSH daemons are running inside a pod. Pods should not run as SSH Daemons (replicaset or statefulset only).,NonTelco,Optional
test,affiliated-certification-container-is-certified-digest,affiliated-certification,Tests whether container images that are autodiscovered have passed the Red Hat Container Certification Program by their digest(CCP).,skipped,2023-07-26 13:56:18.913248204 -0500 CDT m=+33.523753009,0001-01-01 00:00:00 +0000 UTC,,,Ensure that your container has passed the Red Hat Container Certification Program (CCP).,NonTelco,Mandatory
test,lifecycle-pod-high-availability,lifecycle,Ensures that CNF Pods specify podAntiAffinity rules and replica value is set to more than 1.,skipped,2023-07-26 13:56:17.761271932 -0500 CDT m=+32.371776733,0001-01-01 00:00:00 +0000 UTC,,,"In high availability cases, Pod podAntiAffinity rule should be specified for pod scheduling and pod replica value is set to more than 1 .",NonTelco,Mandatory
test,networking-icmpv6-connectivity-multus,networking,Checks that each CNF Container is able to communicate via ICMPv6 on the Multus network(s). This test case requires the Deployment of the debug daemonset.,skipped,2023-07-26 13:56:18.913845651 -0500 CDT m=+33.524350462,0001-01-01 00:00:00 +0000 UTC,,,"Ensure that the CNF is able to communicate via the Multus network(s). In some rare cases, CNFs may require routing table changes in order to communicate over the Multus network(s). To exclude a particular pod from ICMPv6 connectivity tests, add the test-network-function.com/skip_connectivity_tests label to it.The label value is trivial, only its presence. Not applicable if IPv6/MULTUS is not supported.",NonTelco,Optional
test,networking-reserved-partner-ports,networking,Checks that pods and containers are not consuming ports designated as reserved by partner,skipped,2023-07-26 13:56:18.914068381 -0500 CDT m=+33.524573188,0001-01-01 00:00:00 +0000 UTC,,,Ensure ports are not being used that are reserved by our partner,NonTelco,Optional
test,platform-alteration-hugepages-2m-only,platform-alteration,Check that pods using hugepages only use 2Mi size,skipped,2023-07-26 13:56:17.759488741 -0500 CDT m=+32.369993545,0001-01-01 00:00:00 +0000 UTC,,,Modify pod to consume 2Mi hugepages only,NonTelco,Optional
test,platform-alteration-service-mesh-usage,platform-alteration,"Checks if the istio namespace (""istio-system"") is present. If it is present, checks that the istio sidecar is present in all pods under test.",skipped,2023-07-26 13:56:17.759327107 -0500 CDT m=+32.369831912,0001-01-01 00:00:00 +0000 UTC,,,Ensure all the CNF pods are using service mesh if the cluster provides it.,NonTelco,Optional
test,access-control-namespace,access-control,"Tests that all CNF's resources (PUTs and CRs) belong to valid namespaces. A valid namespace meets
the following conditions: (1) It was declared in the yaml config file under the targetNameSpaces
tag. (2) It does not have any of the following prefixes: default, openshift-, istio- and aspenmesh-",skipped,2023-07-26 13:56:17.760306959 -0500 CDT m=+32.370811770,0001-01-01 00:00:00 +0000 UTC,,,"Ensure that your CNF utilizes namespaces declared in the yaml config file. Additionally, the namespaces should not start with ""default, openshift-, istio- or aspenmesh-"".",NonTelco,Mandatory
test,manageability-container-port-name-format,manageability,Check that the container's ports name follow the naming conventions. Name field in ContainerPort section must be of form `<protocol>[-<suffix>]`. More naming convention requirements may be released in future,skipped,2023-07-26 13:56:17.760933434 -0500 CDT m=+32.371438242,0001-01-01 00:00:00 +0000 UTC,,,Ensure that the container's ports name follow our partner naming conventions,NonTelco,Optional
test,observability-pod-disruption-budget,observability,Checks to see if pod disruption budgets have allowed values for minAvailable and maxUnavailable,skipped,2023-07-26 13:56:17.761818239 -0500 CDT m=+32.372323042,0001-01-01 00:00:00 +0000 UTC,,,Ensure minAvailable is not zero and maxUnavailable does not equal the number of pods in the replica,NonTelco,Mandatory
test,performance-shared-cpu-pool-non-rt-scheduling-policy,performance,"Ensures that if application workload runs in shared CPU pool, it chooses non-RT CPU schedule policy to always share the CPU with other applications and kernel threads.",skipped,2023-07-26 13:56:18.913389789 -0500 CDT m=+33.523894597,0001-01-01 00:00:00 +0000 UTC,,,"Ensure that the workload running in Application shared CPU pool should choose non-RT CPU schedule policy, like SCHED _OTHER to always share the CPU with other applications and kernel threads.",NonTelco,Optional
test,platform-alteration-sysctl-config,platform-alteration,"Tests that no one has changed the node's sysctl configs after the node was created, the tests works by checking if the sysctl configs are consistent with the MachineConfig CR which defines how the node should be configured",skipped,2023-07-26 13:56:17.75928883 -0500 CDT m=+32.369793635,0001-01-01 00:00:00 +0000 UTC,,,"You should recreate the node or change the sysctls, recreating is recommended because there might be other unknown changes",NonTelco,Mandatory
test,platform-alteration-tainted-node-kernel,platform-alteration,"Ensures that the Node(s) hosting CNFs do not utilize tainted kernels. This test case is especially important to support Highly Available CNFs, since when a CNF is re-instantiated on a backup Node, that Node's kernel may not have the same hacks.'",skipped,2023-07-26 13:56:17.759089658 -0500 CDT m=+32.369594463,0001-01-01 00:00:00 +0000 UTC,,,Test failure indicates that the underlying Node's kernel is tainted. Ensure that you have not altered underlying Node(s) kernels in order to run the CNF.,NonTelco,Mandatory
test,access-control-security-context-privilege-escalation,access-control,Checks if privileged escalation is enabled (AllowPrivilegeEscalation=true).,skipped,2023-07-26 13:56:17.760015877 -0500 CDT m=+32.370520682,0001-01-01 00:00:00 +0000 UTC,,,Configure privilege escalation to false. Privileged escalation should not be allowed (AllowPrivilegeEscalation=false).,NonTelco,Mandatory
test,lifecycle-storage-required-pods,lifecycle,Checks that pods do not place persistent volumes on local storage.,skipped,2023-07-26 13:56:17.761668071 -0500 CDT m=+32.372172871,0001-01-01 00:00:00 +0000 UTC,,,"If pod is StatefulSet, make sure servicename is not local-storage (persistent volumes should not be on local storage).",NonTelco,Mandatory
test,performance-isolated-cpu-pool-rt-scheduling-policy,performance,Ensures that a workload running in an application-isolated exclusive CPU pool selects a RT CPU scheduling policy,skipped,2023-07-26 13:56:18.913479707 -0500 CDT m=+33.523984515,0001-01-01 00:00:00 +0000 UTC,,,Ensure that the workload running in an application-isolated exclusive CPU pool selects a RT CPU scheduling policy (such as SCHED_FIFO/SCHED_RR) with High priority.,NonTelco,Optional
test,lifecycle-container-shutdown,lifecycle,"Ensure that the containers lifecycle preStop management feature is configured. The most basic requirement for the lifecycle management of Pods in OpenShift are the ability to start and stop correctly. There are different ways a pod can stop on an OpenShift cluster. One way is that the pod can remain alive but non-functional. Another way is that the pod can crash and become non-functional. When pods are shut down by the platform they are sent a SIGTERM signal which means that the process in the container should start shutting down, closing connections and stopping all activity. If the pod doesn’t shut down within the default 30 seconds then the platform may send a SIGKILL signal which will stop the pod immediately. This method isn’t as clean and the default time between the SIGTERM and SIGKILL messages can be modified based on the requirements of the application. Containers should respond to SIGTERM/SIGKILL with graceful shutdown.",skipped,2023-07-26 13:56:17.760968973 -0500 CDT m=+32.371473774,0001-01-01 00:00:00 +0000 UTC,,,"The preStop can be used to gracefully stop the container and clean resources (e.g., DB connection). For details, see https://www.containiq.com/post/kubernetes-container-lifecycle-events-and-hooks and https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks. All pods must respond to SIGTERM signal and shutdown gracefully with a zero exit code.",NonTelco,Optional
test,access-control-projected-volume-service-account-token,access-control,Checks that pods do not use projected volumes and service account tokens,skipped,2023-07-26 13:56:17.760786554 -0500 CDT m=+32.371291356,0001-01-01 00:00:00 +0000 UTC,,,Ensure that pods do not use projected volumes and service account tokens,NonTelco,Optional
test,access-control-requests-and-limits,access-control,Check that containers have resource requests and limits specified in their spec.,skipped,2023-07-26 13:56:17.760696764 -0500 CDT m=+32.371201565,0001-01-01 00:00:00 +0000 UTC,,,Add requests and limits to your container spec. See: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits,NonTelco,Optional
test,lifecycle-affinity-required-pods,lifecycle,Checks that affinity rules are in place if AffinityRequired: 'true' labels are set on Pods.,skipped,2023-07-26 13:56:17.761582462 -0500 CDT m=+32.372087263,0001-01-01 00:00:00 +0000 UTC,,,"Pods which need to be co-located on the same node need Affinity rules. If a pod/statefulset/deployment is required to use affinity rules, please add AffinityRequired: 'true' as a label.",NonTelco,Optional
test,lifecycle-container-startup,lifecycle,"Ensure that the containers lifecycle postStart management feature is configured. A container must receive important events from the platform and conform/react to these events properly. For example, a container should catch SIGTERM or SIGKILL from the platform and shutdown as quickly as possible. Other typically important events from the platform are PostStart to initialize before servicing requests and PreStop to release resources cleanly before shutting down.",skipped,2023-07-26 13:56:17.761048751 -0500 CDT m=+32.371553552,0001-01-01 00:00:00 +0000 UTC,,,"PostStart is normally used to configure the container, set up dependencies, and record the new creation. You could use this event to check that a required API is available before the container’s main work begins. Kubernetes will not change the container’s state to Running until the PostStart script has executed successfully. For details, see https://www.containiq.com/post/kubernetes-container-lifecycle-events-and-hooks and https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks. PostStart is used to configure container, set up dependencies, record new creation. It can also be used to check that a required API is available before the container’s work begins.",NonTelco,Optional
test,lifecycle-startup-probe,lifecycle,"Check that all containers under test have startup probe defined. CNFs shall self-recover from common failures like pod failure, host failure, and network failure. Kubernetes native mechanisms such as health-checks (Liveness, Readiness and Startup Probes) shall be employed at a minimum.",skipped,2023-07-26 13:56:17.761200525 -0500 CDT m=+32.371705328,0001-01-01 00:00:00 +0000 UTC,,,Add a startup probe to deployed containers,NonTelco,Optional
test,lifecycle-statefulset-scaling,lifecycle,"Tests that CNF statefulsets support scale in/out operations. First, the test starts getting the current replicaCount (N) of the statefulset/s with the Pod Under Test. Then, it executes the scale-in oc command for (N-1) replicas. Lastly, it executes the scale-out oc command, restoring the original replicaCount of the statefulset/s. In case of statefulsets that are managed by HPA the test is changing the min and max value to statefulset Replica - 1 during scale-in and the original replicaCount again for both min/max during the scale-out stage. Lastly its restoring the original min/max replica of the statefulset/s",skipped,2023-07-26 13:56:17.761463371 -0500 CDT m=+32.371968172,0001-01-01 00:00:00 +0000 UTC,,,Ensure CNF statefulsets/replica sets can scale in/out successfully.,NonTelco,Mandatory
test,networking-undeclared-container-ports-usage,networking,Check that containers do not listen on ports that weren't declared in their specification. Platforms may be configured to block undeclared ports.,skipped,2023-07-26 13:56:18.913891627 -0500 CDT m=+33.524396434,0001-01-01 00:00:00 +0000 UTC,,,Ensure the CNF apps do not listen on undeclared containers' ports.,NonTelco,Optional
test,access-control-no-1337-uid,access-control,Checks that all pods are not using the securityContext UID 1337,skipped,2023-07-26 13:56:17.760757062 -0500 CDT m=+32.371261865,0001-01-01 00:00:00 +0000 UTC,,,Use another process UID that is not 1337.,NonTelco,Optional
test,access-control-pod-role-bindings,access-control,Ensures that a CNF does not utilize RoleBinding(s) in a non-CNF Namespace.,skipped,2023-07-26 13:56:17.760402 -0500 CDT m=+32.370906805,0001-01-01 00:00:00 +0000 UTC,,,Ensure the CNF is not configured to use RoleBinding(s) in a non-CNF Namespace. Scope of role must <= scope of creator of role.,NonTelco,Mandatory
test,access-control-security-context-non-root-user-check,access-control,Checks the security context runAsUser parameter in pods and containers to make sure it is not set to uid root(0). Pods and containers should not run as root (runAsUser is not set to uid0).,skipped,2023-07-26 13:56:17.759959301 -0500 CDT m=+32.370464106,0001-01-01 00:00:00 +0000 UTC,,,"Change the pod and containers ""runAsUser"" uid to something other than root(0)",NonTelco,Mandatory
test,affiliated-certification-helm-version,affiliated-certification,Test to check if the helm chart is v3,skipped,2023-07-26 13:56:17.761852769 -0500 CDT m=+32.372357570,0001-01-01 00:00:00 +0000 UTC,,,Check Helm Chart is v3 and not v2 which is not supported due to security risks associated with Tiller.,NonTelco,Mandatory
test,lifecycle-pod-toleration-bypass,lifecycle,"Check that pods do not have NoExecute, PreferNoSchedule, or NoSchedule tolerations that have been modified from the default.",skipped,2023-07-26 13:56:17.761618679 -0500 CDT m=+32.372123481,0001-01-01 00:00:00 +0000 UTC,,,"Do not allow pods to bypass the NoExecute, PreferNoSchedule, or NoSchedule tolerations that are default applied by Kubernetes.",NonTelco,Optional
test,networking-icmpv4-connectivity-multus,networking,Checks that each CNF Container is able to communicate via ICMPv4 on the Multus network(s). This test case requires the Deployment of the debug daemonset.,skipped,2023-07-26 13:56:18.913740559 -0500 CDT m=+33.524245368,0001-01-01 00:00:00 +0000 UTC,,,"Ensure that the CNF is able to communicate via the Multus network(s). In some rare cases, CNFs may require routing table changes in order to communicate over the Multus network(s). To exclude a particular pod from ICMPv4 connectivity tests, add the test-network-function.com/skip_connectivity_tests label to it. The label value is trivial, only its presence. Not applicable if MULTUS is not supported.",NonTelco,Optional
test,networking-icmpv6-connectivity,networking,Checks that each CNF Container is able to communicate via ICMPv6 on the Default OpenShift network. This test case requires the Deployment of the debug daemonset.,skipped,2023-07-26 13:56:18.913784085 -0500 CDT m=+33.524288886,0001-01-01 00:00:00 +0000 UTC,,,"Ensure that the CNF is able to communicate via the Default OpenShift network. In some rare cases, CNFs may require routing table changes in order to communicate over the Default network. To exclude a particular pod from ICMPv6 connectivity tests, add the test-network-function.com/skip_connectivity_tests label to it. The label value is trivial, only its presence. Not applicable if IPv6 is not supported.",NonTelco,Optional
test,operator-install-status-succeeded,operator,"Ensures that the target CNF operators report ""Succeeded"" as their installation status.",skipped,2023-07-26 13:56:17.759580124 -0500 CDT m=+32.370084929,0001-01-01 00:00:00 +0000 UTC,,,Ensure all the CNF operators have been successfully installed by OLM.,NonTelco,Mandatory
test,platform-alteration-hugepages-1g-only,platform-alteration,Check that pods using hugepages only use 1Gi size,skipped,2023-07-26 13:56:17.759532927 -0500 CDT m=+32.370037734,0001-01-01 00:00:00 +0000 UTC,,,Modify pod to consume 1Gi hugepages only,NonTelco,Optional
test,lifecycle-liveness-probe,lifecycle,"Check that all containers under test have liveness probe defined. The most basic requirement for the lifecycle management of Pods in OpenShift are the ability to start and stop correctly. When starting up, health probes like liveness and readiness checks can be put into place to ensure the application is functioning properly.",skipped,2023-07-26 13:56:17.761170956 -0500 CDT m=+32.371675757,0001-01-01 00:00:00 +0000 UTC,,,"Add a liveness probe to deployed containers. CNFs shall self-recover from common failures like pod failure, host failure, and network failure. Kubernetes native mechanisms such as health-checks (Liveness, Readiness and Startup Probes) shall be employed at a minimum.",NonTelco,Optional
test,lifecycle-pod-recreation,lifecycle,"Tests that a CNF is configured to support High Availability. First, this test cordons and drains a Node that hosts the CNF Pod. Next, the test ensures that OpenShift can re-instantiate the Pod on another Node, and that the actual replica count matches the desired replica count.",skipped,2023-07-26 13:56:17.761368264 -0500 CDT m=+32.371873069,0001-01-01 00:00:00 +0000 UTC,,,"Ensure that CNF Pod(s) utilize a configuration that supports High Availability. Additionally, ensure that there are available Nodes in the OpenShift cluster that can be utilized in the event that a host Node fails.",NonTelco,Mandatory
test,operator-install-source,operator,Tests whether a CNF Operator is installed via OLM.,skipped,2023-07-26 13:56:17.75967049 -0500 CDT m=+32.370175292,0001-01-01 00:00:00 +0000 UTC,,,Ensure that your Operator is installed via OLM.,NonTelco,Mandatory
test,platform-alteration-is-selinux-enforcing,platform-alteration,"verifies that all openshift platform/cluster nodes have selinux in ""Enforcing"" mode.",skipped,2023-07-26 13:56:17.759164584 -0500 CDT m=+32.369669389,0001-01-01 00:00:00 +0000 UTC,,,Configure selinux and enable enforcing mode.,NonTelco,Mandatory
test,access-control-pod-automount-service-account-token,access-control,Check that all pods under test have automountServiceAccountToken set to false. Only pods that require access to the kubernetes API server should have automountServiceAccountToken set to true,skipped,2023-07-26 13:56:17.760492254 -0500 CDT m=+32.370997055,0001-01-01 00:00:00 +0000 UTC,,,"Check that pod has automountServiceAccountToken set to false or pod is attached to service account which has automountServiceAccountToken set to false, unless the pod needs access to the kubernetes API server. Pods which do not need API access should set automountServiceAccountToken to false in pod spec.",NonTelco,Optional
test,lifecycle-crd-scaling,lifecycle,"Tests that CNF crd support scale in/out operations. First, the test starts getting the current replicaCount (N) of the crd/s with the Pod Under Test. Then, it executes the scale-in oc command for (N-1) replicas. Lastly, it executes the scale-out oc command, restoring the original replicaCount of the crd/s. In case of crd that are managed by HPA the test is changing the min and max value to crd Replica - 1 during scale-in and the original replicaCount again for both min/max during the scale-out stage. Lastly its restoring the original min/max replica of the crd/s",skipped,2023-07-26 13:56:17.761002946 -0500 CDT m=+32.371507746,0001-01-01 00:00:00 +0000 UTC,,,Ensure CNF crd/replica sets can scale in/out successfully.,NonTelco,Mandatory
test,observability-crd-status,observability,Checks that all CRDs have a status sub-resource specification (Spec.versions[].Schema.OpenAPIV3Schema.Properties[“status”]).,skipped,2023-07-26 13:56:17.761738524 -0500 CDT m=+32.372243327,0001-01-01 00:00:00 +0000 UTC,,,Ensure that all the CRDs have a meaningful status specification (Spec.versions[].Schema.OpenAPIV3Schema.Properties[“status”]).,NonTelco,Mandatory
test,performance-rt-apps-no-exec-probes,performance,Ensures that if one container runs a real time application exec probes are not used,skipped,2023-07-26 13:56:18.913327163 -0500 CDT m=+33.523831969,0001-01-01 00:00:00 +0000 UTC,,,Ensure that if one container runs a real time application exec probes are not used,NonTelco,Optional
test,platform-alteration-isredhat-release,platform-alteration,verifies if the container base image is redhat.,skipped,2023-07-26 13:56:17.759126188 -0500 CDT m=+32.369630993,0001-01-01 00:00:00 +0000 UTC,,,Build a new container image that is based on UBI (Red Hat Universal Base Image).,NonTelco,Mandatory
test,access-control-container-host-port,access-control,Verifies if containers define a hostPort.,skipped,2023-07-26 13:56:17.7600508 -0500 CDT m=+32.370555605,0001-01-01 00:00:00 +0000 UTC,,,Remove hostPort configuration from the container. CNF should avoid accessing host resources - containers should not configure HostPort.,NonTelco,Mandatory
test,access-control-pod-host-network,access-control,Verifies that the spec.HostNetwork parameter is not set (not present),skipped,2023-07-26 13:56:17.760100661 -0500 CDT m=+32.370605466,0001-01-01 00:00:00 +0000 UTC,,,Set the spec.HostNetwork parameter to false in the pod configuration. CNF should avoid accessing host resources - spec.HostNetwork should be false.,NonTelco,Mandatory
test,access-control-sys-ptrace-capability,access-control,"Check that if process namespace sharing is enabled for a Pod then the SYS_PTRACE capability is allowed. This capability is required when using Process Namespace Sharing. This is used when processes from one Container need to be exposed to another Container. For example, to send signals like SIGHUP from a process in a Container to another process in another Container. For more information on these capabilities refer to https://cloud.redhat.com/blog/linux-capabilities-in-openshift and https://kubernetes.io/docs/tasks/configure-pod-container/share-process-namespace/",skipped,2023-07-26 13:56:17.760593514 -0500 CDT m=+32.371098316,0001-01-01 00:00:00 +0000 UTC,,,Allow the SYS_PTRACE capability when enabling process namespace sharing for a Pod,NonTelco,Optional
test,networking-dpdk-cpu-pinning-exec-probe,networking,"If a CNF is doing CPU pinning, exec probes may not be used.",skipped,2023-07-26 13:56:18.91410609 -0500 CDT m=+33.524610898,0001-01-01 00:00:00 +0000 UTC,,,If the CNF is doing CPU pinning and running a DPDK process do not use exec probes (executing a command within the container) as it may pile up and block the node eventually.,NonTelco,Optional
test,networking-icmpv4-connectivity,networking,Checks that each CNF Container is able to communicate via ICMPv4 on the Default OpenShift network. This test case requires the Deployment of the debug daemonset.,skipped,2023-07-26 13:56:18.913692284 -0500 CDT m=+33.524197089,0001-01-01 00:00:00 +0000 UTC,,,"Ensure that the CNF is able to communicate via the Default OpenShift network. In some rare cases, CNFs may require routing table changes in order to communicate over the Default network. To exclude a particular pod from ICMPv4 connectivity tests, add the test-network-function.com/skip_connectivity_tests label to it. The label value is trivial, only its presence.",NonTelco,Mandatory
test,platform-alteration-ocp-node-os-lifecycle,platform-alteration,Tests that the nodes running in the cluster have operating systems that are compatible with the deployed version of OpenShift.,skipped,2023-07-26 13:56:17.75943909 -0500 CDT m=+32.369943895,0001-01-01 00:00:00 +0000 UTC,,,Please update your workers to a version that is supported by your version of OpenShift,NonTelco,Mandatory
test,access-control-cluster-role-bindings,access-control,Tests that a Pod does not specify ClusterRoleBindings.,skipped,2023-07-26 13:56:17.760453103 -0500 CDT m=+32.370957904,0001-01-01 00:00:00 +0000 UTC,,,"In most cases, Pod's should not have ClusterRoleBindings. The suggested remediation is to remove the need for ClusterRoleBindings, if possible. Cluster roles and cluster role bindings discouraged unless absolutely needed by CNF (often reserved for cluster admin only).",NonTelco,Optional
test,access-control-net-admin-capability-check,access-control,"Ensures that containers do not use NET_ADMIN capability. Note: this test also ensures iptables and nftables are not configured by CNF pods:
- NET_ADMIN and NET_RAW are required to modify nftables (namespaced) which is not desired inside pods.
nftables should be configured by an administrator outside the scope of the CNF. nftables are usually configured
by operators, for instance the Performance Addon Operator (PAO) or istio.
- Privileged container are required to modify host iptables, which is not safe to perform inside pods. nftables
should be configured by an administrator outside the scope of the CNF. iptables are usually configured by operators,
for instance the Performance Addon Operator (PAO) or istio.",skipped,2023-07-26 13:56:17.759825408 -0500 CDT m=+32.370330213,0001-01-01 00:00:00 +0000 UTC,,,"Exception possible if CNF uses mlock(), mlockall(), shmctl(), mmap(); exception will be considered for DPDK applications. Must identify which container requires the capability and detail why.",NonTelco,Optional
test,performance-exclusive-cpu-pool,performance,Ensures that if one container in a Pod selects an exclusive CPU pool the rest select the same type of CPU pool,skipped,2023-07-26 13:56:18.913288536 -0500 CDT m=+33.523793346,0001-01-01 00:00:00 +0000 UTC,,,Ensure that if one container in a Pod selects an exclusive CPU pool the rest also select this type of CPU pool,NonTelco,Optional
test,access-control-pod-host-pid,access-control,Verifies that the spec.HostPid parameter is set to false,skipped,2023-07-26 13:56:17.760239398 -0500 CDT m=+32.370744203,0001-01-01 00:00:00 +0000 UTC,,,Set the spec.HostPid parameter to false in the pod configuration. CNF should avoid accessing host resources - spec.HostPid should be false.,NonTelco,Mandatory
test,lifecycle-deployment-scaling,lifecycle,"Tests that CNF deployments support scale in/out operations. First, the test starts getting the current replicaCount (N) of the deployment/s with the Pod Under Test. Then, it executes the scale-in oc command for (N-1) replicas. Lastly, it executes the scale-out oc command, restoring the original replicaCount of the deployment/s. In case of deployments that are managed by HPA the test is changing the min and max value to deployment Replica - 1 during scale-in and the original replicaCount again for both min/max during the scale-out stage. Lastly its restoring the original min/max replica of the deployment/s",skipped,2023-07-26 13:56:17.761412916 -0500 CDT m=+32.371917720,0001-01-01 00:00:00 +0000 UTC,,,Ensure CNF deployments/replica sets can scale in/out successfully.,NonTelco,Mandatory
test,lifecycle-image-pull-policy,lifecycle,"Ensure that the containers under test are using IfNotPresent as Image Pull Policy. If there is a situation where the container dies and needs to be restarted, the image pull policy becomes important. PullIfNotPresent is recommended so that a loss of image registry access does not prevent the pod from restarting.",skipped,2023-07-26 13:56:17.761079384 -0500 CDT m=+32.371584185,0001-01-01 00:00:00 +0000 UTC,,,Ensure that the containers under test are using IfNotPresent as Image Pull Policy.,NonTelco,Optional
test,lifecycle-readiness-probe,lifecycle,"Check that all containers under test have readiness probe defined. There are different ways a pod can stop on on OpenShift cluster. One way is that the pod can remain alive but non-functional. Another way is that the pod can crash and become non-functional. In the first case, if the administrator has implemented liveness and readiness checks, OpenShift can stop the pod and either restart it on the same node or a different node in the cluster. For the second case, when the application in the pod stops, it should exit with a code and write suitable log entries to help the administrator diagnose what the issue was that caused the problem.",skipped,2023-07-26 13:56:17.761120958 -0500 CDT m=+32.371625760,0001-01-01 00:00:00 +0000 UTC,,,Add a readiness probe to deployed containers,NonTelco,Optional
test,manageability-containers-image-tag,manageability,Check that image tag exists on containers.,skipped,2023-07-26 13:56:17.760895235 -0500 CDT m=+32.371400037,0001-01-01 00:00:00 +0000 UTC,,,"Ensure that all the container images are tagged. Checks containers have image tags (e.g. latest, stable, dev).",NonTelco,Optional
test,observability-container-logging,observability,"Check that all containers under test use standard input output and standard error when logging. A container must provide APIs for the platform to observe the container health and act accordingly. These APIs include health checks (liveness and readiness), logging to stderr and stdout for log aggregation (by tools such as Logstash or Filebeat), and integrate with tracing and metrics-gathering libraries (such as Prometheus or Metricbeat).",skipped,2023-07-26 13:56:17.761701034 -0500 CDT m=+32.372205835,0001-01-01 00:00:00 +0000 UTC,,,Ensure containers are not redirecting stdout/stderr,NonTelco,Optional
test,access-control-ipc-lock-capability-check,access-control,Ensures that containers do not use IPC_LOCK capability. CNF should avoid accessing host resources - spec.HostIpc should be false.,skipped,2023-07-26 13:56:17.759923284 -0500 CDT m=+32.370428089,0001-01-01 00:00:00 +0000 UTC,,,"Exception possible if CNF uses mlock(), mlockall(), shmctl(), mmap(); exception will be considered for DPDK applications. Must identify which container requires the capability and detail why.",NonTelco,Optional
test,access-control-pod-service-account,access-control,Tests that each CNF Pod utilizes a valid Service Account. Default or empty service account is not valid.,skipped,2023-07-26 13:56:17.760346784 -0500 CDT m=+32.370851590,0001-01-01 00:00:00 +0000 UTC,,,Ensure that the each CNF Pod is configured to use a valid Service Account,NonTelco,Mandatory
test,access-control-sys-nice-realtime-capability,access-control,"Check that pods running on nodes with realtime kernel enabled have the SYS_NICE capability enabled in their spec. In the case that a CNF is running on a node using the real-time kernel, SYS_NICE will be used to allow DPDK application to switch to SCHED_FIFO.",skipped,2023-07-26 13:56:17.760562374 -0500 CDT m=+32.371067175,0001-01-01 00:00:00 +0000 UTC,,,"If pods are scheduled to realtime kernel nodes, they must add SYS_NICE capability to their spec.",NonTelco,Optional
test,affiliated-certification-operator-is-certified,affiliated-certification,Tests whether CNF Operators listed in the configuration file have passed the Red Hat Operator Certification Program (OCP).,skipped,2023-07-26 13:56:18.913125447 -0500 CDT m=+33.523630260,0001-01-01 00:00:00 +0000 UTC,,,Ensure that your Operator has passed Red Hat's Operator Certification Program (OCP).,NonTelco,Mandatory
test,lifecycle-persistent-volume-reclaim-policy,lifecycle,Check that the persistent volumes the CNF pods are using have a reclaim policy of delete. Network Functions should clear persistent storage by deleting their PVs when removing their application from a cluster.,skipped,2023-07-26 13:56:17.76151256 -0500 CDT m=+32.372017360,0001-01-01 00:00:00 +0000 UTC,,,Ensure that all persistent volumes are using the reclaim policy: delete,NonTelco,Optional
test,networking-network-policy-deny-all,networking,Check that network policies attached to namespaces running CNF pods contain a default deny-all rule for both ingress and egress traffic,skipped,2023-07-26 13:56:18.914025964 -0500 CDT m=+33.524530772,0001-01-01 00:00:00 +0000 UTC,,,"Ensure that a NetworkPolicy with a default deny-all is applied. After the default is applied, apply a network policy to allow the traffic your application requires.",NonTelco,Optional
test,networking-ocp-reserved-ports-usage,networking,Check that containers do not listen on ports that are reserved by OpenShift,skipped,2023-07-26 13:56:18.913936386 -0500 CDT m=+33.524441193,0001-01-01 00:00:00 +0000 UTC,,,"Ensure that CNF apps do not listen on ports that are reserved by OpenShift. The following ports are reserved by OpenShift and must NOT be used by any application: 22623, 22624.",NonTelco,Mandatory
test,observability-termination-policy,observability,"Check that all containers are using terminationMessagePolicy: FallbackToLogsOnError. There are different ways a pod can stop on an OpenShift cluster. One way is that the pod can remain alive but non-functional. Another way is that the pod can crash and become non-functional. In the first case, if the administrator has implemented liveness and readiness checks, OpenShift can stop the pod and either restart it on the same node or a different node in the cluster. For the second case, when the application in the pod stops, it should exit with a code and write suitable log entries to help the administrator diagnose what the issue was that caused the problem.",skipped,2023-07-26 13:56:17.761771778 -0500 CDT m=+32.372276578,0001-01-01 00:00:00 +0000 UTC,,,Ensure containers are all using FallbackToLogsOnError in terminationMessagePolicy,NonTelco,Optional
test,platform-alteration-base-image,platform-alteration,"Ensures that the Container Base Image is not altered post-startup. This test is a heuristic, and ensures that there are no changes to the following directories: 1) /var/lib/rpm 2) /var/lib/dpkg 3) /bin 4) /sbin 5) /lib 6) /lib64 7) /usr/bin 8) /usr/sbin 9) /usr/lib 10) /usr/lib64",skipped,2023-07-26 13:56:17.759028882 -0500 CDT m=+32.369533687,0001-01-01 00:00:00 +0000 UTC,,,"Ensure that Container applications do not modify the Container Base Image. In particular, ensure that the following directories are not modified: 1) /var/lib/rpm 2) /var/lib/dpkg 3) /bin 4) /sbin 5) /lib 6) /lib64 7) /usr/bin 8) /usr/sbin 9) /usr/lib 10) /usr/lib64 Ensure that all required binaries are built directly into the container image, and are not installed post startup.",NonTelco,Mandatory
test,platform-alteration-ocp-lifecycle,platform-alteration,Tests that the running OCP version is not end of life.,skipped,2023-07-26 13:56:17.75936616 -0500 CDT m=+32.369870970,0001-01-01 00:00:00 +0000 UTC,,,Please update your cluster to a version that is generally available.,NonTelco,Mandatory
test,access-control-namespace-resource-quota,access-control,Checks to see if CNF workload pods are running in namespaces that have resource quotas applied.,skipped,2023-07-26 13:56:17.760626518 -0500 CDT m=+32.371131321,0001-01-01 00:00:00 +0000 UTC,,,Apply a ResourceQuota to the namespace your CNF is running in. The CNF namespace should have resource quota defined.,NonTelco,Optional
test,access-control-pod-host-ipc,access-control,Verifies that the spec.HostIpc parameter is set to false,skipped,2023-07-26 13:56:17.760195364 -0500 CDT m=+32.370700168,0001-01-01 00:00:00 +0000 UTC,,,Set the spec.HostIpc parameter to false in the pod configuration. CNF should avoid accessing host resources - spec.HostIpc should be false.,NonTelco,Mandatory
test,access-control-security-context,access-control,Checks the security context matches one of the 4 categories,skipped,2023-07-26 13:56:17.759715489 -0500 CDT m=+32.370220294,0001-01-01 00:00:00 +0000 UTC,,,"Exception possible if CNF uses mlock(), mlockall(), shmctl(), mmap(); exception will be considered for DPDK applications. Must identify which container requires the capability and document why. If the container had the right configuration of the allowed category from the 4 approved list then the test will pass. The 4 categories are defined in Requirement ID 94118 of the Extended Best Practices guide (private repo)",NonTelco,Optional
test,lifecycle-pod-scheduling,lifecycle,"Ensures that CNF Pods do not specify nodeSelector or nodeAffinity. In most cases, Pods should allow for instantiation on any underlying Node. CNFs shall not use node selectors nor taints/tolerations to assign pod location.",skipped,2023-07-26 13:56:17.761326683 -0500 CDT m=+32.371831487,0001-01-01 00:00:00 +0000 UTC,,,"In most cases, Pod's should not specify their host Nodes through nodeSelector or nodeAffinity. However, there are cases in which CNFs require specialized hardware specific to a particular class of Node.",NonTelco,Optional
test,networking-restart-on-reboot-sriov-pod,networking,Ensures that the label restart-on-reboot exists on pods that use SRIOV network interfaces.,skipped,2023-07-26 13:56:18.914152667 -0500 CDT m=+33.524657474,0001-01-01 00:00:00 +0000 UTC,,,Ensure that the label restart-on-reboot exists on pods that use SRIOV network interfaces.,NonTelco,Optional
test,platform-alteration-hugepages-config,platform-alteration,"Checks to see that HugePage settings have been configured through MachineConfig, and not manually on the underlying Node. This test case applies only to Nodes that are configured with the ""worker"" MachineConfigSet. First, the ""worker"" MachineConfig is polled, and the Hugepage settings are extracted. Next, the underlying Nodes are polled for configured HugePages through inspection of /proc/meminfo. The results are compared, and the test passes only if they are the same.",skipped,2023-07-26 13:56:17.759200268 -0500 CDT m=+32.369705072,0001-01-01 00:00:00 +0000 UTC,,,"HugePage settings should be configured either directly through the MachineConfigOperator or indirectly using the PerformanceAddonOperator. This ensures that OpenShift is aware of the special MachineConfig requirements, and can provision your CNF on a Node that is part of the corresponding MachineConfigSet. Avoid making changes directly to an underlying Node, and let OpenShift handle the heavy lifting of configuring advanced settings. This test case applies only to Nodes that are configured with the ""worker"" MachineConfigSet.",NonTelco,Mandatory
test,access-control-net-raw-capability-check,access-control,"Ensures that containers do not use NET_RAW capability. Note: this test also ensures iptables and nftables are not configured by CNF pods:
- NET_ADMIN and NET_RAW are required to modify nftables (namespaced) which is not desired inside pods.
nftables should be configured by an administrator outside the scope of the CNF. nftables are usually configured
by operators, for instance the Performance Addon Operator (PAO) or istio.
- Privileged container are required to modify host iptables, which is not safe to perform inside pods. nftables
should be configured by an administrator outside the scope of the CNF. iptables are usually configured by operators,
for instance the Performance Addon Operator (PAO) or istio.",skipped,2023-07-26 13:56:17.759869913 -0500 CDT m=+32.370374718,0001-01-01 00:00:00 +0000 UTC,,,"Exception possible if CNF uses mlock(), mlockall(), shmctl(), mmap(); exception will be considered for DPDK applications. Must identify which container requires the capability and detail why.",NonTelco,Optional
test,access-control-one-process-per-container,access-control,Check that all containers under test have only one process running,skipped,2023-07-26 13:56:17.760526016 -0500 CDT m=+32.371030818,0001-01-01 00:00:00 +0000 UTC,,,Launch only one process per container. Should adhere to 1 process per container best practice wherever possible.,NonTelco,Optional
test,access-control-pod-host-path,access-control,Verifies that the spec.HostPath parameter is not set (not present),skipped,2023-07-26 13:56:17.760146206 -0500 CDT m=+32.370651014,0001-01-01 00:00:00 +0000 UTC,,,Set the spec.HostPath parameter to false in the pod configuration. CNF should avoid accessing host resources - spec.HostPath should be false.,NonTelco,Mandatory
test,access-control-service-type,access-control,Tests that each CNF Service does not utilize NodePort(s).,skipped,2023-07-26 13:56:17.76082574 -0500 CDT m=+32.371330542,0001-01-01 00:00:00 +0000 UTC,,,Ensure Services are not configured to use NodePort(s).CNF should avoid accessing host resources - tests that each CNF Service does not utilize NodePort(s).,NonTelco,Mandatory
test,affiliated-certification-helmchart-is-certified,affiliated-certification,Tests whether helm charts listed in the cluster passed the Red Hat Helm Certification Program.,skipped,2023-07-26 13:56:18.913208113 -0500 CDT m=+33.523712918,0001-01-01 00:00:00 +0000 UTC,,,Ensure that the helm charts under test passed the Red Hat's helm Certification Program (e.g. listed in https://charts.openshift.io/index.yaml).,NonTelco,Mandatory
test,lifecycle-pod-owner-type,lifecycle,Tests that CNF Pod(s) are deployed as part of a ReplicaSet(s)/StatefulSet(s).,skipped,2023-07-26 13:56:17.761237273 -0500 CDT m=+32.371742073,0001-01-01 00:00:00 +0000 UTC,,,Deploy the CNF using ReplicaSet/StatefulSet.,NonTelco,Optional
test,performance-exclusive-cpu-pool-rt-scheduling-policy,performance,"Ensures that if application workload runs in exclusive CPU pool, it chooses RT CPU schedule policy and set the priority less than 10.",skipped,2023-07-26 13:56:18.913426317 -0500 CDT m=+33.523931124,0001-01-01 00:00:00 +0000 UTC,,,"Ensure that the workload running in Application exclusive CPU pool can choose RT CPU scheduling policy, but should set priority less than 10",NonTelco,Optional
