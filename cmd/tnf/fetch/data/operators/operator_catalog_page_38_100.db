{
  "data": [
    {
      "_id": "6374b9f92e831b3fd5b48bcd",
      "alm_examples": [
        {
          "api_version": "tenantoperator.stakater.com/v1beta1",
          "kind": "Tenant",
          "metadata": {
            "name": "bluesky"
          },
          "spec": {
            "editors": {
              "groups": [
                "alpha"
              ],
              "users": [
                "john@aurora.org"
              ]
            },
            "namespaces": [
              "dev",
              "build",
              "prod"
            ],
            "owners": {
              "users": [
                "anna@aurora.org",
                "anthony@aurora.org"
              ]
            },
            "quota": "small"
          }
        },
        {
          "api_version": "tenantoperator.stakater.com/v1alpha1",
          "kind": "IntegrationConfig",
          "metadata": {
            "name": "tenant-operator-config",
            "namespace": "multi-tenant-operator"
          },
          "spec": {
            "argocd": {
              "clusterResourceWhitelist": [
                {
                  "group": "tronador.stakater.com",
                  "kind": "EnvironmentProvisioner"
                }
              ],
              "namespace": "openshift-operators",
              "namespaceResourceBlacklist": [
                {
                  "group": "",
                  "kind": "ResourceQuota"
                }
              ]
            },
            "openshift": {
              "clusterAdminGroups": [
                "cluster-admins"
              ],
              "group": {
                "labels": {
                  "role": "customer-reader"
                }
              },
              "namespaceAccessPolicy": {
                "deny": {
                  "privilegedNamespaces": {
                    "groups": [
                      "cluster-admins"
                    ],
                    "users": [
                      "system:serviceaccount:openshift-argocd:argocd-application-controller",
                      "adam@stakater.com"
                    ]
                  }
                }
              },
              "privilegedNamespaces": [
                "default",
                "^openshift-*",
                "^kube-*"
              ],
              "privilegedServiceAccounts": [
                "^system:serviceaccount:openshift-*",
                "^system:serviceaccount:kube-*"
              ],
              "project": {
                "annotations": {
                  "openshift.io/node-selector": "node-role.kubernetes.io/worker="
                },
                "labels": {
                  "stakater.com/workload-monitoring": "true"
                }
              },
              "sandbox": {
                "labels": {
                  "stakater.com/kind": "sandbox"
                }
              }
            },
            "rhsso": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "auth-secrets",
                  "namespace": "openshift-auth"
                },
                "url": "https://iam-keycloak-auth.apps.prod.abcdefghi.kubeapp.cloud/"
              }
            },
            "vault": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "vault-root-token",
                  "namespace": "vault"
                },
                "url": "https://vault.apps.prod.abcdefghi.kubeapp.cloud/"
              },
              "sso": {
                "accessorID": "<ACCESSOR_ID_TOKEN>",
                "clientName": "vault"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/stakater/tenant-operator-0@sha256:c425d6688659ae4cfe20ef3ad202123d7902634d7f57c4cea1c2e1a08019fc82",
      "bundle_path_digest": "sha256:c425d6688659ae4cfe20ef3ad202123d7902634d7f57c4cea1c2e1a08019fc82",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "0.7.5",
      "creation_date": "2022-11-16T10:22:49.946000+00:00",
      "csv_description": "tenant operator",
      "csv_display_name": "tenant-operator",
      "csv_metadata_description": "",
      "csv_name": "tenant-operator.v0.7.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T06:35:58.738000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "tenant-operator",
      "provided_apis": [
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateInstance",
          "plural": "templateinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Template",
          "plural": "templates",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "IntegrationConfig",
          "plural": "integrationconfigs",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "ResourceSupervisor",
          "plural": "resourcesupervisors",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateGroupInstance",
          "plural": "templategroupinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Quota",
          "plural": "quotas",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta2"
        }
      ],
      "provider": "stakater",
      "related_images": [
        {
          "digest": "sha256:c27a7c01e5968aff16b6bb6670423f992d1a1de1a16e7e260d12908d3322431c",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:c27a7c01e5968aff16b6bb6670423f992d1a1de1a16e7e260d12908d3322431c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:16bba1ae63876c0b42283adb966fdb19c583c9c1830e2c621feab6713ab73873",
          "image": "registry.connect.redhat.com/stakater/tenant-operator@sha256:16bba1ae63876c0b42283adb966fdb19c583c9c1830e2c621feab6713ab73873",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "0.7.2",
      "version_original": "0.7.2"
    },
    {
      "_id": "6374b9fa2e831b3fd5b48bd1",
      "alm_examples": [
        {
          "api_version": "tenantoperator.stakater.com/v1beta1",
          "kind": "Tenant",
          "metadata": {
            "name": "bluesky"
          },
          "spec": {
            "editors": {
              "groups": [
                "alpha"
              ],
              "users": [
                "john@aurora.org"
              ]
            },
            "namespaces": [
              "dev",
              "build",
              "prod"
            ],
            "owners": {
              "users": [
                "anna@aurora.org",
                "anthony@aurora.org"
              ]
            },
            "quota": "small"
          }
        },
        {
          "api_version": "tenantoperator.stakater.com/v1alpha1",
          "kind": "IntegrationConfig",
          "metadata": {
            "name": "tenant-operator-config",
            "namespace": "multi-tenant-operator"
          },
          "spec": {
            "argocd": {
              "clusterResourceWhitelist": [
                {
                  "group": "tronador.stakater.com",
                  "kind": "EnvironmentProvisioner"
                }
              ],
              "namespace": "openshift-operators",
              "namespaceResourceBlacklist": [
                {
                  "group": "",
                  "kind": "ResourceQuota"
                }
              ]
            },
            "openshift": {
              "clusterAdminGroups": [
                "cluster-admins"
              ],
              "group": {
                "labels": {
                  "role": "customer-reader"
                }
              },
              "namespaceAccessPolicy": {
                "deny": {
                  "privilegedNamespaces": {
                    "groups": [
                      "cluster-admins"
                    ],
                    "users": [
                      "system:serviceaccount:openshift-argocd:argocd-application-controller",
                      "adam@stakater.com"
                    ]
                  }
                }
              },
              "privilegedNamespaces": [
                "default",
                "^openshift-*",
                "^kube-*"
              ],
              "privilegedServiceAccounts": [
                "^system:serviceaccount:openshift-*",
                "^system:serviceaccount:kube-*"
              ],
              "project": {
                "annotations": {
                  "openshift.io/node-selector": "node-role.kubernetes.io/worker="
                },
                "labels": {
                  "stakater.com/workload-monitoring": "true"
                }
              },
              "sandbox": {
                "labels": {
                  "stakater.com/kind": "sandbox"
                }
              }
            },
            "rhsso": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "auth-secrets",
                  "namespace": "openshift-auth"
                },
                "url": "https://iam-keycloak-auth.apps.prod.abcdefghi.kubeapp.cloud/"
              }
            },
            "vault": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "vault-root-token",
                  "namespace": "vault"
                },
                "url": "https://vault.apps.prod.abcdefghi.kubeapp.cloud/"
              },
              "sso": {
                "accessorID": "<ACCESSOR_ID_TOKEN>",
                "clientName": "vault"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/stakater/tenant-operator-0@sha256:c425d6688659ae4cfe20ef3ad202123d7902634d7f57c4cea1c2e1a08019fc82",
      "bundle_path_digest": "sha256:c425d6688659ae4cfe20ef3ad202123d7902634d7f57c4cea1c2e1a08019fc82",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-16T10:22:50.960000+00:00",
      "csv_description": "tenant operator",
      "csv_display_name": "tenant-operator",
      "csv_metadata_description": "",
      "csv_name": "tenant-operator.v0.7.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T06:36:06.274000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "tenant-operator",
      "provided_apis": [
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateInstance",
          "plural": "templateinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Template",
          "plural": "templates",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "IntegrationConfig",
          "plural": "integrationconfigs",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "ResourceSupervisor",
          "plural": "resourcesupervisors",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateGroupInstance",
          "plural": "templategroupinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Quota",
          "plural": "quotas",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta2"
        }
      ],
      "provider": "stakater",
      "related_images": [
        {
          "digest": "sha256:c27a7c01e5968aff16b6bb6670423f992d1a1de1a16e7e260d12908d3322431c",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:c27a7c01e5968aff16b6bb6670423f992d1a1de1a16e7e260d12908d3322431c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:16bba1ae63876c0b42283adb966fdb19c583c9c1830e2c621feab6713ab73873",
          "image": "registry.connect.redhat.com/stakater/tenant-operator@sha256:16bba1ae63876c0b42283adb966fdb19c583c9c1830e2c621feab6713ab73873",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "0.7.2",
      "version_original": "0.7.2"
    },
    {
      "_id": "6374b9fc3f6a002c6b3659df",
      "alm_examples": [
        {
          "api_version": "tenantoperator.stakater.com/v1beta1",
          "kind": "Tenant",
          "metadata": {
            "name": "bluesky"
          },
          "spec": {
            "editors": {
              "groups": [
                "alpha"
              ],
              "users": [
                "john@aurora.org"
              ]
            },
            "namespaces": [
              "dev",
              "build",
              "prod"
            ],
            "owners": {
              "users": [
                "anna@aurora.org",
                "anthony@aurora.org"
              ]
            },
            "quota": "small"
          }
        },
        {
          "api_version": "tenantoperator.stakater.com/v1alpha1",
          "kind": "IntegrationConfig",
          "metadata": {
            "name": "tenant-operator-config",
            "namespace": "multi-tenant-operator"
          },
          "spec": {
            "argocd": {
              "clusterResourceWhitelist": [
                {
                  "group": "tronador.stakater.com",
                  "kind": "EnvironmentProvisioner"
                }
              ],
              "namespace": "openshift-operators",
              "namespaceResourceBlacklist": [
                {
                  "group": "",
                  "kind": "ResourceQuota"
                }
              ]
            },
            "openshift": {
              "clusterAdminGroups": [
                "cluster-admins"
              ],
              "group": {
                "labels": {
                  "role": "customer-reader"
                }
              },
              "namespaceAccessPolicy": {
                "deny": {
                  "privilegedNamespaces": {
                    "groups": [
                      "cluster-admins"
                    ],
                    "users": [
                      "system:serviceaccount:openshift-argocd:argocd-application-controller",
                      "adam@stakater.com"
                    ]
                  }
                }
              },
              "privilegedNamespaces": [
                "default",
                "^openshift-*",
                "^kube-*"
              ],
              "privilegedServiceAccounts": [
                "^system:serviceaccount:openshift-*",
                "^system:serviceaccount:kube-*"
              ],
              "project": {
                "annotations": {
                  "openshift.io/node-selector": "node-role.kubernetes.io/worker="
                },
                "labels": {
                  "stakater.com/workload-monitoring": "true"
                }
              },
              "sandbox": {
                "labels": {
                  "stakater.com/kind": "sandbox"
                }
              }
            },
            "rhsso": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "auth-secrets",
                  "namespace": "openshift-auth"
                },
                "url": "https://iam-keycloak-auth.apps.prod.abcdefghi.kubeapp.cloud/"
              }
            },
            "vault": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "vault-root-token",
                  "namespace": "vault"
                },
                "url": "https://vault.apps.prod.abcdefghi.kubeapp.cloud/"
              },
              "sso": {
                "accessorID": "<ACCESSOR_ID_TOKEN>",
                "clientName": "vault"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/stakater/tenant-operator-0@sha256:28e360fc4bfdc368cdbe3d755343f0a670c8e81352e3895b0ebf31a064ebdd29",
      "bundle_path_digest": "sha256:28e360fc4bfdc368cdbe3d755343f0a670c8e81352e3895b0ebf31a064ebdd29",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "0.7.5",
      "creation_date": "2022-11-16T10:22:52.043000+00:00",
      "csv_description": "tenant operator",
      "csv_display_name": "tenant-operator",
      "csv_metadata_description": "",
      "csv_name": "tenant-operator.v0.7.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T06:36:19.929000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "tenant-operator",
      "provided_apis": [
        {
          "group": "tenantoperator.stakater.com",
          "kind": "ResourceSupervisor",
          "plural": "resourcesupervisors",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateGroupInstance",
          "plural": "templategroupinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateInstance",
          "plural": "templateinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "IntegrationConfig",
          "plural": "integrationconfigs",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Template",
          "plural": "templates",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta2"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Quota",
          "plural": "quotas",
          "version": "v1beta1"
        }
      ],
      "provider": "stakater",
      "related_images": [
        {
          "digest": "sha256:c27a7c01e5968aff16b6bb6670423f992d1a1de1a16e7e260d12908d3322431c",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:c27a7c01e5968aff16b6bb6670423f992d1a1de1a16e7e260d12908d3322431c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:9ad0606e31c0cff08f9dce812d3757d5dc60a2f1e1df5b0f72f3e34b014bbfc8",
          "image": "registry.connect.redhat.com/stakater/tenant-operator@sha256:9ad0606e31c0cff08f9dce812d3757d5dc60a2f1e1df5b0f72f3e34b014bbfc8",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "0.7.3",
      "version_original": "0.7.3"
    },
    {
      "_id": "6374b9fd64d923486d25a1d6",
      "alm_examples": [
        {
          "api_version": "tenantoperator.stakater.com/v1beta1",
          "kind": "Tenant",
          "metadata": {
            "name": "bluesky"
          },
          "spec": {
            "editors": {
              "groups": [
                "alpha"
              ],
              "users": [
                "john@aurora.org"
              ]
            },
            "namespaces": [
              "dev",
              "build",
              "prod"
            ],
            "owners": {
              "users": [
                "anna@aurora.org",
                "anthony@aurora.org"
              ]
            },
            "quota": "small"
          }
        },
        {
          "api_version": "tenantoperator.stakater.com/v1alpha1",
          "kind": "IntegrationConfig",
          "metadata": {
            "name": "tenant-operator-config",
            "namespace": "multi-tenant-operator"
          },
          "spec": {
            "argocd": {
              "clusterResourceWhitelist": [
                {
                  "group": "tronador.stakater.com",
                  "kind": "EnvironmentProvisioner"
                }
              ],
              "namespace": "openshift-operators",
              "namespaceResourceBlacklist": [
                {
                  "group": "",
                  "kind": "ResourceQuota"
                }
              ]
            },
            "openshift": {
              "clusterAdminGroups": [
                "cluster-admins"
              ],
              "group": {
                "labels": {
                  "role": "customer-reader"
                }
              },
              "namespaceAccessPolicy": {
                "deny": {
                  "privilegedNamespaces": {
                    "groups": [
                      "cluster-admins"
                    ],
                    "users": [
                      "system:serviceaccount:openshift-argocd:argocd-application-controller",
                      "adam@stakater.com"
                    ]
                  }
                }
              },
              "privilegedNamespaces": [
                "default",
                "^openshift-*",
                "^kube-*"
              ],
              "privilegedServiceAccounts": [
                "^system:serviceaccount:openshift-*",
                "^system:serviceaccount:kube-*"
              ],
              "project": {
                "annotations": {
                  "openshift.io/node-selector": "node-role.kubernetes.io/worker="
                },
                "labels": {
                  "stakater.com/workload-monitoring": "true"
                }
              },
              "sandbox": {
                "labels": {
                  "stakater.com/kind": "sandbox"
                }
              }
            },
            "rhsso": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "auth-secrets",
                  "namespace": "openshift-auth"
                },
                "url": "https://iam-keycloak-auth.apps.prod.abcdefghi.kubeapp.cloud/"
              }
            },
            "vault": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "vault-root-token",
                  "namespace": "vault"
                },
                "url": "https://vault.apps.prod.abcdefghi.kubeapp.cloud/"
              },
              "sso": {
                "accessorID": "<ACCESSOR_ID_TOKEN>",
                "clientName": "vault"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/stakater/tenant-operator-0@sha256:a7137fc3c15527c3988979f430a7fc6fd92ddbf2fde0e48b135fb5326c69401b",
      "bundle_path_digest": "sha256:a7137fc3c15527c3988979f430a7fc6fd92ddbf2fde0e48b135fb5326c69401b",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "0.7.5",
      "creation_date": "2022-11-16T10:22:53.417000+00:00",
      "csv_description": "OpenShift is designed to support a single tenant platform, hence making it difficult for cluster admins to host multi-tenancy in a single OpenShift cluster. If multi-tenancy is achieved by sharing a cluster, it can have many advantages, e.g. efficient resource utilization, less configuration effort and easier sharing of cluster-internal resources among different tenants. Multi Tenant Operator helps to solve the complexity issues of doing true multi-tenancy by providing simplified abstractions on top of the native primitives to provide organizations and platform providers the tooling, self-service capabilities and robust automation needed to do secure and efficient Multi-Tenancy in a single OpenShift cluster.\n\n## Access Control\n\nMulti Tenant Operator provides several ClusterRoles that are automatically bound to the Tenants Namespaces used for managing access to the Namespaces and the resources they contain. You can also modify the default roles or create new roles to have full control and customize access control for your users and teams.\n\n## Self-Service\n\nWith Multi Tenant Operator, you can empower your users to safely provision namespaces for themselves and their teams (typically mapped to SSO groups). Team-owned namespaces and the resources inside of them count towards the team's quotas rather than the user's individual limits and are automatically shared with all team members according to the access rules you configure in tenant-operator.\n\n## HashiCorp Vault Multitenancy\n\nMulti Tenant Operator is not only providing strong Multi-Tenancy for the OpenShift internals but also extends the tenant's permission model to HashiCorp Vault where it can create vault paths and greatly ease the overhead of managing RBAC in Vault.\n\n## ArgoCD Multitenancy\n\nMulti Tenant Operator is not only providing strong Multi-Tenancy for the OpenShift internals but also extends the tenant's permission model to ArgoCD where it can provision AppProjects and Allowed Repositories for your tenants greatly easing the overhead of managing RBAC in ArgoCD.\n\n## Cost/Resource Optimization\n\nMulti Tenant Operator provides a mechanism for defining Resource Quotas at the tenant scope, meaning all namespaces belonging to a particular tenant share the defined quota, which is why you are able to safely enable dev teams to self-serve their namespaces whilst being confident that they can only use the resources allocated based on budget and business needs.\n\n## Sandboxed Dev Namespaces\n\nMulti Tenant Operator can be configured to automatically provision a namespace for every member of the specific tenant, that will also be pre-loaded with any selected templates and consume the same pool of resources from the tenant's quota creating safe sandboxed dev namespaces that teams can use as a scratch namespace for rapid prototyping and development.",
      "csv_display_name": "Multi Tenant Operator",
      "csv_metadata_description": "OpenShift is designed to support a single tenant platform, hence making it difficult for cluster admins to host multi-tenancy in a single OpenShift cluster. If multi-tenancy is achieved by sharing a cluster, it can have many advantages, e.g. efficient resource utilization, less configuration effort and easier sharing of cluster-internal resources among different tenants. Stakater Multi-Tenancy Operator helps to solve the complexity issues of doing true multi-tenancy by providing simplified abstractions on top of the native primitives to provide organizations and platform providers the tooling, self-service capabilities and robust automation needed to do secure and efficient Multi-Tenancy in a single OpenShift cluster.",
      "csv_name": "tenant-operator.v0.7.5",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T06:36:49.324000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "tenant-operator",
      "provided_apis": [
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Template",
          "plural": "templates",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta2"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "IntegrationConfig",
          "plural": "integrationconfigs",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Quota",
          "plural": "quotas",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "ResourceSupervisor",
          "plural": "resourcesupervisors",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateInstance",
          "plural": "templateinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateGroupInstance",
          "plural": "templategroupinstances",
          "version": "v1alpha1"
        }
      ],
      "provider": "Stakater",
      "related_images": [
        {
          "digest": "sha256:f7993b7a5458679621f6686bdc4ab818659e051ef6cdf6a8e107f627adf5f178",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:f7993b7a5458679621f6686bdc4ab818659e051ef6cdf6a8e107f627adf5f178",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:4ec7ee0365c6ee8bd3edf70336542e547b361857bd7175a218f709ae4dbc449d",
          "image": "registry.connect.redhat.com/stakater/tenant-operator@sha256:4ec7ee0365c6ee8bd3edf70336542e547b361857bd7175a218f709ae4dbc449d",
          "name": "manager"
        },
        {
          "digest": "sha256:4ec7ee0365c6ee8bd3edf70336542e547b361857bd7175a218f709ae4dbc449d",
          "image": "registry.connect.redhat.com/stakater/tenant-operator@sha256:4ec7ee0365c6ee8bd3edf70336542e547b361857bd7175a218f709ae4dbc449d",
          "name": "tenant-operator-4ec7ee0365c6ee8bd3edf70336542e547b361857bd7175a218f709ae4dbc449d-annotation"
        }
      ],
      "replaces": null,
      "skip_range": "<0.7.4",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "0.7.5",
      "version_original": "0.7.5"
    },
    {
      "_id": "6374b9fed012d3e7d00feca6",
      "alm_examples": [
        {
          "api_version": "tenantoperator.stakater.com/v1beta1",
          "kind": "Tenant",
          "metadata": {
            "name": "bluesky"
          },
          "spec": {
            "editors": {
              "groups": [
                "alpha"
              ],
              "users": [
                "john@aurora.org"
              ]
            },
            "namespaces": [
              "dev",
              "build",
              "prod"
            ],
            "owners": {
              "users": [
                "anna@aurora.org",
                "anthony@aurora.org"
              ]
            },
            "quota": "small"
          }
        },
        {
          "api_version": "tenantoperator.stakater.com/v1alpha1",
          "kind": "IntegrationConfig",
          "metadata": {
            "name": "tenant-operator-config",
            "namespace": "multi-tenant-operator"
          },
          "spec": {
            "argocd": {
              "clusterResourceWhitelist": [
                {
                  "group": "tronador.stakater.com",
                  "kind": "EnvironmentProvisioner"
                }
              ],
              "namespace": "openshift-operators",
              "namespaceResourceBlacklist": [
                {
                  "group": "",
                  "kind": "ResourceQuota"
                }
              ]
            },
            "openshift": {
              "clusterAdminGroups": [
                "cluster-admins"
              ],
              "group": {
                "labels": {
                  "role": "customer-reader"
                }
              },
              "namespaceAccessPolicy": {
                "deny": {
                  "privilegedNamespaces": {
                    "groups": [
                      "cluster-admins"
                    ],
                    "users": [
                      "system:serviceaccount:openshift-argocd:argocd-application-controller",
                      "adam@stakater.com"
                    ]
                  }
                }
              },
              "privilegedNamespaces": [
                "default",
                "^openshift-*",
                "^kube-*"
              ],
              "privilegedServiceAccounts": [
                "^system:serviceaccount:openshift-*",
                "^system:serviceaccount:kube-*"
              ],
              "project": {
                "annotations": {
                  "openshift.io/node-selector": "node-role.kubernetes.io/worker="
                },
                "labels": {
                  "stakater.com/workload-monitoring": "true"
                }
              },
              "sandbox": {
                "labels": {
                  "stakater.com/kind": "sandbox"
                }
              }
            },
            "rhsso": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "auth-secrets",
                  "namespace": "openshift-auth"
                },
                "url": "https://iam-keycloak-auth.apps.prod.abcdefghi.kubeapp.cloud/"
              }
            },
            "vault": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "vault-root-token",
                  "namespace": "vault"
                },
                "url": "https://vault.apps.prod.abcdefghi.kubeapp.cloud/"
              },
              "sso": {
                "accessorID": "<ACCESSOR_ID_TOKEN>",
                "clientName": "vault"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/stakater/tenant-operator-0@sha256:a7137fc3c15527c3988979f430a7fc6fd92ddbf2fde0e48b135fb5326c69401b",
      "bundle_path_digest": "sha256:a7137fc3c15527c3988979f430a7fc6fd92ddbf2fde0e48b135fb5326c69401b",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-16T10:22:54.697000+00:00",
      "csv_description": "OpenShift is designed to support a single tenant platform, hence making it difficult for cluster admins to host multi-tenancy in a single OpenShift cluster. If multi-tenancy is achieved by sharing a cluster, it can have many advantages, e.g. efficient resource utilization, less configuration effort and easier sharing of cluster-internal resources among different tenants. Multi Tenant Operator helps to solve the complexity issues of doing true multi-tenancy by providing simplified abstractions on top of the native primitives to provide organizations and platform providers the tooling, self-service capabilities and robust automation needed to do secure and efficient Multi-Tenancy in a single OpenShift cluster.\n\n## Access Control\n\nMulti Tenant Operator provides several ClusterRoles that are automatically bound to the Tenants Namespaces used for managing access to the Namespaces and the resources they contain. You can also modify the default roles or create new roles to have full control and customize access control for your users and teams.\n\n## Self-Service\n\nWith Multi Tenant Operator, you can empower your users to safely provision namespaces for themselves and their teams (typically mapped to SSO groups). Team-owned namespaces and the resources inside of them count towards the team's quotas rather than the user's individual limits and are automatically shared with all team members according to the access rules you configure in tenant-operator.\n\n## HashiCorp Vault Multitenancy\n\nMulti Tenant Operator is not only providing strong Multi-Tenancy for the OpenShift internals but also extends the tenant's permission model to HashiCorp Vault where it can create vault paths and greatly ease the overhead of managing RBAC in Vault.\n\n## ArgoCD Multitenancy\n\nMulti Tenant Operator is not only providing strong Multi-Tenancy for the OpenShift internals but also extends the tenant's permission model to ArgoCD where it can provision AppProjects and Allowed Repositories for your tenants greatly easing the overhead of managing RBAC in ArgoCD.\n\n## Cost/Resource Optimization\n\nMulti Tenant Operator provides a mechanism for defining Resource Quotas at the tenant scope, meaning all namespaces belonging to a particular tenant share the defined quota, which is why you are able to safely enable dev teams to self-serve their namespaces whilst being confident that they can only use the resources allocated based on budget and business needs.\n\n## Sandboxed Dev Namespaces\n\nMulti Tenant Operator can be configured to automatically provision a namespace for every member of the specific tenant, that will also be pre-loaded with any selected templates and consume the same pool of resources from the tenant's quota creating safe sandboxed dev namespaces that teams can use as a scratch namespace for rapid prototyping and development.",
      "csv_display_name": "Multi Tenant Operator",
      "csv_metadata_description": "OpenShift is designed to support a single tenant platform, hence making it difficult for cluster admins to host multi-tenancy in a single OpenShift cluster. If multi-tenancy is achieved by sharing a cluster, it can have many advantages, e.g. efficient resource utilization, less configuration effort and easier sharing of cluster-internal resources among different tenants. Stakater Multi-Tenancy Operator helps to solve the complexity issues of doing true multi-tenancy by providing simplified abstractions on top of the native primitives to provide organizations and platform providers the tooling, self-service capabilities and robust automation needed to do secure and efficient Multi-Tenancy in a single OpenShift cluster.",
      "csv_name": "tenant-operator.v0.7.5",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T06:36:55.881000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "tenant-operator",
      "provided_apis": [
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Template",
          "plural": "templates",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta2"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "IntegrationConfig",
          "plural": "integrationconfigs",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Quota",
          "plural": "quotas",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "ResourceSupervisor",
          "plural": "resourcesupervisors",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateInstance",
          "plural": "templateinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateGroupInstance",
          "plural": "templategroupinstances",
          "version": "v1alpha1"
        }
      ],
      "provider": "Stakater",
      "related_images": [
        {
          "digest": "sha256:f7993b7a5458679621f6686bdc4ab818659e051ef6cdf6a8e107f627adf5f178",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:f7993b7a5458679621f6686bdc4ab818659e051ef6cdf6a8e107f627adf5f178",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:4ec7ee0365c6ee8bd3edf70336542e547b361857bd7175a218f709ae4dbc449d",
          "image": "registry.connect.redhat.com/stakater/tenant-operator@sha256:4ec7ee0365c6ee8bd3edf70336542e547b361857bd7175a218f709ae4dbc449d",
          "name": "manager"
        },
        {
          "digest": "sha256:4ec7ee0365c6ee8bd3edf70336542e547b361857bd7175a218f709ae4dbc449d",
          "image": "registry.connect.redhat.com/stakater/tenant-operator@sha256:4ec7ee0365c6ee8bd3edf70336542e547b361857bd7175a218f709ae4dbc449d",
          "name": "tenant-operator-4ec7ee0365c6ee8bd3edf70336542e547b361857bd7175a218f709ae4dbc449d-annotation"
        }
      ],
      "replaces": null,
      "skip_range": "<0.7.4",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "0.7.5",
      "version_original": "0.7.5"
    },
    {
      "_id": "6374ba1d3f6a002c6b365a36",
      "alm_examples": [
        {
          "api_version": "tenantoperator.stakater.com/v1beta1",
          "kind": "Tenant",
          "metadata": {
            "name": "bluesky"
          },
          "spec": {
            "editors": {
              "groups": [
                "alpha"
              ],
              "users": [
                "john@aurora.org"
              ]
            },
            "namespaces": [
              "dev",
              "build",
              "prod"
            ],
            "owners": {
              "users": [
                "anna@aurora.org",
                "anthony@aurora.org"
              ]
            },
            "quota": "small"
          }
        },
        {
          "api_version": "tenantoperator.stakater.com/v1alpha1",
          "kind": "IntegrationConfig",
          "metadata": {
            "name": "tenant-operator-config",
            "namespace": "multi-tenant-operator"
          },
          "spec": {
            "argocd": {
              "clusterResourceWhitelist": [
                {
                  "group": "tronador.stakater.com",
                  "kind": "EnvironmentProvisioner"
                }
              ],
              "namespace": "openshift-operators",
              "namespaceResourceBlacklist": [
                {
                  "group": "",
                  "kind": "ResourceQuota"
                }
              ]
            },
            "openshift": {
              "clusterAdminGroups": [
                "cluster-admins"
              ],
              "group": {
                "labels": {
                  "role": "customer-reader"
                }
              },
              "namespaceAccessPolicy": {
                "deny": {
                  "privilegedNamespaces": {
                    "groups": [
                      "cluster-admins"
                    ],
                    "users": [
                      "system:serviceaccount:openshift-argocd:argocd-application-controller",
                      "adam@stakater.com"
                    ]
                  }
                }
              },
              "privilegedNamespaces": [
                "default",
                "^openshift-*",
                "^kube-*"
              ],
              "privilegedServiceAccounts": [
                "^system:serviceaccount:openshift-*",
                "^system:serviceaccount:kube-*"
              ],
              "project": {
                "annotations": {
                  "openshift.io/node-selector": "node-role.kubernetes.io/worker="
                },
                "labels": {
                  "stakater.com/workload-monitoring": "true"
                }
              },
              "sandbox": {
                "labels": {
                  "stakater.com/kind": "sandbox"
                }
              }
            },
            "rhsso": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "auth-secrets",
                  "namespace": "openshift-auth"
                },
                "url": "https://iam-keycloak-auth.apps.prod.abcdefghi.kubeapp.cloud/"
              }
            },
            "vault": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "vault-root-token",
                  "namespace": "vault"
                },
                "url": "https://vault.apps.prod.abcdefghi.kubeapp.cloud/"
              },
              "sso": {
                "accessorID": "<ACCESSOR_ID_TOKEN>",
                "clientName": "vault"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/stakater/tenant-operator-0@sha256:6f893ad8a063fe7602d2425479a430f463a931ab84a9861d1143af89306b6d40",
      "bundle_path_digest": "sha256:6f893ad8a063fe7602d2425479a430f463a931ab84a9861d1143af89306b6d40",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "0.7.5",
      "creation_date": "2022-11-16T10:23:25.563000+00:00",
      "csv_description": "tenant operator",
      "csv_display_name": "tenant-operator",
      "csv_metadata_description": "",
      "csv_name": "tenant-operator.v0.7.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T07:29:37.561000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "tenant-operator",
      "provided_apis": [
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateInstance",
          "plural": "templateinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "ResourceSupervisor",
          "plural": "resourcesupervisors",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateGroupInstance",
          "plural": "templategroupinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Template",
          "plural": "templates",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta2"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "IntegrationConfig",
          "plural": "integrationconfigs",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Quota",
          "plural": "quotas",
          "version": "v1beta1"
        }
      ],
      "provider": "stakater",
      "related_images": [
        {
          "digest": "sha256:ef2c41fb899228a64cf2f61d7606a980a5f8fcae820da246d25c4f17faa0da3d",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:ef2c41fb899228a64cf2f61d7606a980a5f8fcae820da246d25c4f17faa0da3d",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:05e84618a81fa6f05a4a49a57a86a789e5b1473dc110d9742c2fb49f7be287c7",
          "image": "registry.connect.redhat.com/stakater/tenant-operator@sha256:05e84618a81fa6f05a4a49a57a86a789e5b1473dc110d9742c2fb49f7be287c7",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "0.7.0",
      "version_original": "0.7.0"
    },
    {
      "_id": "6374ba1e2e831b3fd5b48c3d",
      "alm_examples": [
        {
          "api_version": "tenantoperator.stakater.com/v1beta1",
          "kind": "Tenant",
          "metadata": {
            "name": "bluesky"
          },
          "spec": {
            "editors": {
              "groups": [
                "alpha"
              ],
              "users": [
                "john@aurora.org"
              ]
            },
            "namespaces": [
              "dev",
              "build",
              "prod"
            ],
            "owners": {
              "users": [
                "anna@aurora.org",
                "anthony@aurora.org"
              ]
            },
            "quota": "small"
          }
        },
        {
          "api_version": "tenantoperator.stakater.com/v1alpha1",
          "kind": "IntegrationConfig",
          "metadata": {
            "name": "tenant-operator-config",
            "namespace": "multi-tenant-operator"
          },
          "spec": {
            "argocd": {
              "clusterResourceWhitelist": [
                {
                  "group": "tronador.stakater.com",
                  "kind": "EnvironmentProvisioner"
                }
              ],
              "namespace": "openshift-operators",
              "namespaceResourceBlacklist": [
                {
                  "group": "",
                  "kind": "ResourceQuota"
                }
              ]
            },
            "openshift": {
              "clusterAdminGroups": [
                "cluster-admins"
              ],
              "group": {
                "labels": {
                  "role": "customer-reader"
                }
              },
              "namespaceAccessPolicy": {
                "deny": {
                  "privilegedNamespaces": {
                    "groups": [
                      "cluster-admins"
                    ],
                    "users": [
                      "system:serviceaccount:openshift-argocd:argocd-application-controller",
                      "adam@stakater.com"
                    ]
                  }
                }
              },
              "privilegedNamespaces": [
                "default",
                "^openshift-*",
                "^kube-*"
              ],
              "privilegedServiceAccounts": [
                "^system:serviceaccount:openshift-*",
                "^system:serviceaccount:kube-*"
              ],
              "project": {
                "annotations": {
                  "openshift.io/node-selector": "node-role.kubernetes.io/worker="
                },
                "labels": {
                  "stakater.com/workload-monitoring": "true"
                }
              },
              "sandbox": {
                "labels": {
                  "stakater.com/kind": "sandbox"
                }
              }
            },
            "rhsso": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "auth-secrets",
                  "namespace": "openshift-auth"
                },
                "url": "https://iam-keycloak-auth.apps.prod.abcdefghi.kubeapp.cloud/"
              }
            },
            "vault": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "vault-root-token",
                  "namespace": "vault"
                },
                "url": "https://vault.apps.prod.abcdefghi.kubeapp.cloud/"
              },
              "sso": {
                "accessorID": "<ACCESSOR_ID_TOKEN>",
                "clientName": "vault"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/stakater/tenant-operator-0@sha256:6f893ad8a063fe7602d2425479a430f463a931ab84a9861d1143af89306b6d40",
      "bundle_path_digest": "sha256:6f893ad8a063fe7602d2425479a430f463a931ab84a9861d1143af89306b6d40",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-16T10:23:26.389000+00:00",
      "csv_description": "tenant operator",
      "csv_display_name": "tenant-operator",
      "csv_metadata_description": "",
      "csv_name": "tenant-operator.v0.7.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:29:39.059000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "tenant-operator",
      "provided_apis": [
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateInstance",
          "plural": "templateinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "ResourceSupervisor",
          "plural": "resourcesupervisors",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateGroupInstance",
          "plural": "templategroupinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Template",
          "plural": "templates",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta2"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "IntegrationConfig",
          "plural": "integrationconfigs",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Quota",
          "plural": "quotas",
          "version": "v1beta1"
        }
      ],
      "provider": "stakater",
      "related_images": [
        {
          "digest": "sha256:ef2c41fb899228a64cf2f61d7606a980a5f8fcae820da246d25c4f17faa0da3d",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:ef2c41fb899228a64cf2f61d7606a980a5f8fcae820da246d25c4f17faa0da3d",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:05e84618a81fa6f05a4a49a57a86a789e5b1473dc110d9742c2fb49f7be287c7",
          "image": "registry.connect.redhat.com/stakater/tenant-operator@sha256:05e84618a81fa6f05a4a49a57a86a789e5b1473dc110d9742c2fb49f7be287c7",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "0.7.0",
      "version_original": "0.7.0"
    },
    {
      "_id": "6374ba1f3f6a002c6b365a3f",
      "alm_examples": [
        {
          "api_version": "tenantoperator.stakater.com/v1beta1",
          "kind": "Tenant",
          "metadata": {
            "name": "bluesky"
          },
          "spec": {
            "editors": {
              "groups": [
                "alpha"
              ],
              "users": [
                "john@aurora.org"
              ]
            },
            "namespaces": [
              "dev",
              "build",
              "prod"
            ],
            "owners": {
              "users": [
                "anna@aurora.org",
                "anthony@aurora.org"
              ]
            },
            "quota": "small"
          }
        },
        {
          "api_version": "tenantoperator.stakater.com/v1alpha1",
          "kind": "IntegrationConfig",
          "metadata": {
            "name": "tenant-operator-config",
            "namespace": "multi-tenant-operator"
          },
          "spec": {
            "argocd": {
              "clusterResourceWhitelist": [
                {
                  "group": "tronador.stakater.com",
                  "kind": "EnvironmentProvisioner"
                }
              ],
              "namespace": "openshift-operators",
              "namespaceResourceBlacklist": [
                {
                  "group": "",
                  "kind": "ResourceQuota"
                }
              ]
            },
            "openshift": {
              "clusterAdminGroups": [
                "cluster-admins"
              ],
              "group": {
                "labels": {
                  "role": "customer-reader"
                }
              },
              "namespaceAccessPolicy": {
                "deny": {
                  "privilegedNamespaces": {
                    "groups": [
                      "cluster-admins"
                    ],
                    "users": [
                      "system:serviceaccount:openshift-argocd:argocd-application-controller",
                      "adam@stakater.com"
                    ]
                  }
                }
              },
              "privilegedNamespaces": [
                "default",
                "^openshift-*",
                "^kube-*"
              ],
              "privilegedServiceAccounts": [
                "^system:serviceaccount:openshift-*",
                "^system:serviceaccount:kube-*"
              ],
              "project": {
                "annotations": {
                  "openshift.io/node-selector": "node-role.kubernetes.io/worker="
                },
                "labels": {
                  "stakater.com/workload-monitoring": "true"
                }
              },
              "sandbox": {
                "labels": {
                  "stakater.com/kind": "sandbox"
                }
              }
            },
            "rhsso": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "auth-secrets",
                  "namespace": "openshift-auth"
                },
                "url": "https://iam-keycloak-auth.apps.prod.abcdefghi.kubeapp.cloud/"
              }
            },
            "vault": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "vault-root-token",
                  "namespace": "vault"
                },
                "url": "https://vault.apps.prod.abcdefghi.kubeapp.cloud/"
              },
              "sso": {
                "accessorID": "<ACCESSOR_ID_TOKEN>",
                "clientName": "vault"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/stakater/tenant-operator-0@sha256:c425d6688659ae4cfe20ef3ad202123d7902634d7f57c4cea1c2e1a08019fc82",
      "bundle_path_digest": "sha256:c425d6688659ae4cfe20ef3ad202123d7902634d7f57c4cea1c2e1a08019fc82",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "0.7.5",
      "creation_date": "2022-11-16T10:23:27.477000+00:00",
      "csv_description": "tenant operator",
      "csv_display_name": "tenant-operator",
      "csv_metadata_description": "",
      "csv_name": "tenant-operator.v0.7.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T07:29:40.554000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "tenant-operator",
      "provided_apis": [
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateGroupInstance",
          "plural": "templategroupinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "IntegrationConfig",
          "plural": "integrationconfigs",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Template",
          "plural": "templates",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta2"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Quota",
          "plural": "quotas",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "ResourceSupervisor",
          "plural": "resourcesupervisors",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateInstance",
          "plural": "templateinstances",
          "version": "v1alpha1"
        }
      ],
      "provider": "stakater",
      "related_images": [
        {
          "digest": "sha256:c27a7c01e5968aff16b6bb6670423f992d1a1de1a16e7e260d12908d3322431c",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:c27a7c01e5968aff16b6bb6670423f992d1a1de1a16e7e260d12908d3322431c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:16bba1ae63876c0b42283adb966fdb19c583c9c1830e2c621feab6713ab73873",
          "image": "registry.connect.redhat.com/stakater/tenant-operator@sha256:16bba1ae63876c0b42283adb966fdb19c583c9c1830e2c621feab6713ab73873",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "0.7.2",
      "version_original": "0.7.2"
    },
    {
      "_id": "6374ba203f6a002c6b365a42",
      "alm_examples": [
        {
          "api_version": "tenantoperator.stakater.com/v1beta1",
          "kind": "Tenant",
          "metadata": {
            "name": "bluesky"
          },
          "spec": {
            "editors": {
              "groups": [
                "alpha"
              ],
              "users": [
                "john@aurora.org"
              ]
            },
            "namespaces": [
              "dev",
              "build",
              "prod"
            ],
            "owners": {
              "users": [
                "anna@aurora.org",
                "anthony@aurora.org"
              ]
            },
            "quota": "small"
          }
        },
        {
          "api_version": "tenantoperator.stakater.com/v1alpha1",
          "kind": "IntegrationConfig",
          "metadata": {
            "name": "tenant-operator-config",
            "namespace": "multi-tenant-operator"
          },
          "spec": {
            "argocd": {
              "clusterResourceWhitelist": [
                {
                  "group": "tronador.stakater.com",
                  "kind": "EnvironmentProvisioner"
                }
              ],
              "namespace": "openshift-operators",
              "namespaceResourceBlacklist": [
                {
                  "group": "",
                  "kind": "ResourceQuota"
                }
              ]
            },
            "openshift": {
              "clusterAdminGroups": [
                "cluster-admins"
              ],
              "group": {
                "labels": {
                  "role": "customer-reader"
                }
              },
              "namespaceAccessPolicy": {
                "deny": {
                  "privilegedNamespaces": {
                    "groups": [
                      "cluster-admins"
                    ],
                    "users": [
                      "system:serviceaccount:openshift-argocd:argocd-application-controller",
                      "adam@stakater.com"
                    ]
                  }
                }
              },
              "privilegedNamespaces": [
                "default",
                "^openshift-*",
                "^kube-*"
              ],
              "privilegedServiceAccounts": [
                "^system:serviceaccount:openshift-*",
                "^system:serviceaccount:kube-*"
              ],
              "project": {
                "annotations": {
                  "openshift.io/node-selector": "node-role.kubernetes.io/worker="
                },
                "labels": {
                  "stakater.com/workload-monitoring": "true"
                }
              },
              "sandbox": {
                "labels": {
                  "stakater.com/kind": "sandbox"
                }
              }
            },
            "rhsso": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "auth-secrets",
                  "namespace": "openshift-auth"
                },
                "url": "https://iam-keycloak-auth.apps.prod.abcdefghi.kubeapp.cloud/"
              }
            },
            "vault": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "vault-root-token",
                  "namespace": "vault"
                },
                "url": "https://vault.apps.prod.abcdefghi.kubeapp.cloud/"
              },
              "sso": {
                "accessorID": "<ACCESSOR_ID_TOKEN>",
                "clientName": "vault"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/stakater/tenant-operator-0@sha256:c425d6688659ae4cfe20ef3ad202123d7902634d7f57c4cea1c2e1a08019fc82",
      "bundle_path_digest": "sha256:c425d6688659ae4cfe20ef3ad202123d7902634d7f57c4cea1c2e1a08019fc82",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-16T10:23:28.409000+00:00",
      "csv_description": "tenant operator",
      "csv_display_name": "tenant-operator",
      "csv_metadata_description": "",
      "csv_name": "tenant-operator.v0.7.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:29:41.549000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "tenant-operator",
      "provided_apis": [
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateGroupInstance",
          "plural": "templategroupinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "IntegrationConfig",
          "plural": "integrationconfigs",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Template",
          "plural": "templates",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta2"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Quota",
          "plural": "quotas",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "ResourceSupervisor",
          "plural": "resourcesupervisors",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateInstance",
          "plural": "templateinstances",
          "version": "v1alpha1"
        }
      ],
      "provider": "stakater",
      "related_images": [
        {
          "digest": "sha256:c27a7c01e5968aff16b6bb6670423f992d1a1de1a16e7e260d12908d3322431c",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:c27a7c01e5968aff16b6bb6670423f992d1a1de1a16e7e260d12908d3322431c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:16bba1ae63876c0b42283adb966fdb19c583c9c1830e2c621feab6713ab73873",
          "image": "registry.connect.redhat.com/stakater/tenant-operator@sha256:16bba1ae63876c0b42283adb966fdb19c583c9c1830e2c621feab6713ab73873",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "0.7.2",
      "version_original": "0.7.2"
    },
    {
      "_id": "6374ba21fc5bb7604727706f",
      "alm_examples": [
        {
          "api_version": "tenantoperator.stakater.com/v1beta1",
          "kind": "Tenant",
          "metadata": {
            "name": "bluesky"
          },
          "spec": {
            "editors": {
              "groups": [
                "alpha"
              ],
              "users": [
                "john@aurora.org"
              ]
            },
            "namespaces": [
              "dev",
              "build",
              "prod"
            ],
            "owners": {
              "users": [
                "anna@aurora.org",
                "anthony@aurora.org"
              ]
            },
            "quota": "small"
          }
        },
        {
          "api_version": "tenantoperator.stakater.com/v1alpha1",
          "kind": "IntegrationConfig",
          "metadata": {
            "name": "tenant-operator-config",
            "namespace": "multi-tenant-operator"
          },
          "spec": {
            "argocd": {
              "clusterResourceWhitelist": [
                {
                  "group": "tronador.stakater.com",
                  "kind": "EnvironmentProvisioner"
                }
              ],
              "namespace": "openshift-operators",
              "namespaceResourceBlacklist": [
                {
                  "group": "",
                  "kind": "ResourceQuota"
                }
              ]
            },
            "openshift": {
              "clusterAdminGroups": [
                "cluster-admins"
              ],
              "group": {
                "labels": {
                  "role": "customer-reader"
                }
              },
              "namespaceAccessPolicy": {
                "deny": {
                  "privilegedNamespaces": {
                    "groups": [
                      "cluster-admins"
                    ],
                    "users": [
                      "system:serviceaccount:openshift-argocd:argocd-application-controller",
                      "adam@stakater.com"
                    ]
                  }
                }
              },
              "privilegedNamespaces": [
                "default",
                "^openshift-*",
                "^kube-*"
              ],
              "privilegedServiceAccounts": [
                "^system:serviceaccount:openshift-*",
                "^system:serviceaccount:kube-*"
              ],
              "project": {
                "annotations": {
                  "openshift.io/node-selector": "node-role.kubernetes.io/worker="
                },
                "labels": {
                  "stakater.com/workload-monitoring": "true"
                }
              },
              "sandbox": {
                "labels": {
                  "stakater.com/kind": "sandbox"
                }
              }
            },
            "rhsso": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "auth-secrets",
                  "namespace": "openshift-auth"
                },
                "url": "https://iam-keycloak-auth.apps.prod.abcdefghi.kubeapp.cloud/"
              }
            },
            "vault": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "vault-root-token",
                  "namespace": "vault"
                },
                "url": "https://vault.apps.prod.abcdefghi.kubeapp.cloud/"
              },
              "sso": {
                "accessorID": "<ACCESSOR_ID_TOKEN>",
                "clientName": "vault"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/stakater/tenant-operator-0@sha256:28e360fc4bfdc368cdbe3d755343f0a670c8e81352e3895b0ebf31a064ebdd29",
      "bundle_path_digest": "sha256:28e360fc4bfdc368cdbe3d755343f0a670c8e81352e3895b0ebf31a064ebdd29",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "0.7.5",
      "creation_date": "2022-11-16T10:23:29.168000+00:00",
      "csv_description": "tenant operator",
      "csv_display_name": "tenant-operator",
      "csv_metadata_description": "",
      "csv_name": "tenant-operator.v0.7.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T07:29:44.036000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "tenant-operator",
      "provided_apis": [
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Template",
          "plural": "templates",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "IntegrationConfig",
          "plural": "integrationconfigs",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "ResourceSupervisor",
          "plural": "resourcesupervisors",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateGroupInstance",
          "plural": "templategroupinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateInstance",
          "plural": "templateinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta2"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Quota",
          "plural": "quotas",
          "version": "v1beta1"
        }
      ],
      "provider": "stakater",
      "related_images": [
        {
          "digest": "sha256:c27a7c01e5968aff16b6bb6670423f992d1a1de1a16e7e260d12908d3322431c",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:c27a7c01e5968aff16b6bb6670423f992d1a1de1a16e7e260d12908d3322431c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:9ad0606e31c0cff08f9dce812d3757d5dc60a2f1e1df5b0f72f3e34b014bbfc8",
          "image": "registry.connect.redhat.com/stakater/tenant-operator@sha256:9ad0606e31c0cff08f9dce812d3757d5dc60a2f1e1df5b0f72f3e34b014bbfc8",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "0.7.3",
      "version_original": "0.7.3"
    },
    {
      "_id": "6374ba2264d923486d25a232",
      "alm_examples": [
        {
          "api_version": "tenantoperator.stakater.com/v1beta1",
          "kind": "Tenant",
          "metadata": {
            "name": "bluesky"
          },
          "spec": {
            "editors": {
              "groups": [
                "alpha"
              ],
              "users": [
                "john@aurora.org"
              ]
            },
            "namespaces": [
              "dev",
              "build",
              "prod"
            ],
            "owners": {
              "users": [
                "anna@aurora.org",
                "anthony@aurora.org"
              ]
            },
            "quota": "small"
          }
        },
        {
          "api_version": "tenantoperator.stakater.com/v1alpha1",
          "kind": "IntegrationConfig",
          "metadata": {
            "name": "tenant-operator-config",
            "namespace": "multi-tenant-operator"
          },
          "spec": {
            "argocd": {
              "clusterResourceWhitelist": [
                {
                  "group": "tronador.stakater.com",
                  "kind": "EnvironmentProvisioner"
                }
              ],
              "namespace": "openshift-operators",
              "namespaceResourceBlacklist": [
                {
                  "group": "",
                  "kind": "ResourceQuota"
                }
              ]
            },
            "openshift": {
              "clusterAdminGroups": [
                "cluster-admins"
              ],
              "group": {
                "labels": {
                  "role": "customer-reader"
                }
              },
              "namespaceAccessPolicy": {
                "deny": {
                  "privilegedNamespaces": {
                    "groups": [
                      "cluster-admins"
                    ],
                    "users": [
                      "system:serviceaccount:openshift-argocd:argocd-application-controller",
                      "adam@stakater.com"
                    ]
                  }
                }
              },
              "privilegedNamespaces": [
                "default",
                "^openshift-*",
                "^kube-*"
              ],
              "privilegedServiceAccounts": [
                "^system:serviceaccount:openshift-*",
                "^system:serviceaccount:kube-*"
              ],
              "project": {
                "annotations": {
                  "openshift.io/node-selector": "node-role.kubernetes.io/worker="
                },
                "labels": {
                  "stakater.com/workload-monitoring": "true"
                }
              },
              "sandbox": {
                "labels": {
                  "stakater.com/kind": "sandbox"
                }
              }
            },
            "rhsso": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "auth-secrets",
                  "namespace": "openshift-auth"
                },
                "url": "https://iam-keycloak-auth.apps.prod.abcdefghi.kubeapp.cloud/"
              }
            },
            "vault": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "vault-root-token",
                  "namespace": "vault"
                },
                "url": "https://vault.apps.prod.abcdefghi.kubeapp.cloud/"
              },
              "sso": {
                "accessorID": "<ACCESSOR_ID_TOKEN>",
                "clientName": "vault"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/stakater/tenant-operator-0@sha256:a7137fc3c15527c3988979f430a7fc6fd92ddbf2fde0e48b135fb5326c69401b",
      "bundle_path_digest": "sha256:a7137fc3c15527c3988979f430a7fc6fd92ddbf2fde0e48b135fb5326c69401b",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "0.7.5",
      "creation_date": "2022-11-16T10:23:30.149000+00:00",
      "csv_description": "OpenShift is designed to support a single tenant platform, hence making it difficult for cluster admins to host multi-tenancy in a single OpenShift cluster. If multi-tenancy is achieved by sharing a cluster, it can have many advantages, e.g. efficient resource utilization, less configuration effort and easier sharing of cluster-internal resources among different tenants. Multi Tenant Operator helps to solve the complexity issues of doing true multi-tenancy by providing simplified abstractions on top of the native primitives to provide organizations and platform providers the tooling, self-service capabilities and robust automation needed to do secure and efficient Multi-Tenancy in a single OpenShift cluster.\n\n## Access Control\n\nMulti Tenant Operator provides several ClusterRoles that are automatically bound to the Tenants Namespaces used for managing access to the Namespaces and the resources they contain. You can also modify the default roles or create new roles to have full control and customize access control for your users and teams.\n\n## Self-Service\n\nWith Multi Tenant Operator, you can empower your users to safely provision namespaces for themselves and their teams (typically mapped to SSO groups). Team-owned namespaces and the resources inside of them count towards the team's quotas rather than the user's individual limits and are automatically shared with all team members according to the access rules you configure in tenant-operator.\n\n## HashiCorp Vault Multitenancy\n\nMulti Tenant Operator is not only providing strong Multi-Tenancy for the OpenShift internals but also extends the tenant's permission model to HashiCorp Vault where it can create vault paths and greatly ease the overhead of managing RBAC in Vault.\n\n## ArgoCD Multitenancy\n\nMulti Tenant Operator is not only providing strong Multi-Tenancy for the OpenShift internals but also extends the tenant's permission model to ArgoCD where it can provision AppProjects and Allowed Repositories for your tenants greatly easing the overhead of managing RBAC in ArgoCD.\n\n## Cost/Resource Optimization\n\nMulti Tenant Operator provides a mechanism for defining Resource Quotas at the tenant scope, meaning all namespaces belonging to a particular tenant share the defined quota, which is why you are able to safely enable dev teams to self-serve their namespaces whilst being confident that they can only use the resources allocated based on budget and business needs.\n\n## Sandboxed Dev Namespaces\n\nMulti Tenant Operator can be configured to automatically provision a namespace for every member of the specific tenant, that will also be pre-loaded with any selected templates and consume the same pool of resources from the tenant's quota creating safe sandboxed dev namespaces that teams can use as a scratch namespace for rapid prototyping and development.",
      "csv_display_name": "Multi Tenant Operator",
      "csv_metadata_description": "OpenShift is designed to support a single tenant platform, hence making it difficult for cluster admins to host multi-tenancy in a single OpenShift cluster. If multi-tenancy is achieved by sharing a cluster, it can have many advantages, e.g. efficient resource utilization, less configuration effort and easier sharing of cluster-internal resources among different tenants. Stakater Multi-Tenancy Operator helps to solve the complexity issues of doing true multi-tenancy by providing simplified abstractions on top of the native primitives to provide organizations and platform providers the tooling, self-service capabilities and robust automation needed to do secure and efficient Multi-Tenancy in a single OpenShift cluster.",
      "csv_name": "tenant-operator.v0.7.5",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T07:29:51.981000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "tenant-operator",
      "provided_apis": [
        {
          "group": "tenantoperator.stakater.com",
          "kind": "IntegrationConfig",
          "plural": "integrationconfigs",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Quota",
          "plural": "quotas",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateGroupInstance",
          "plural": "templategroupinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateInstance",
          "plural": "templateinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "ResourceSupervisor",
          "plural": "resourcesupervisors",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Template",
          "plural": "templates",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta2"
        }
      ],
      "provider": "Stakater",
      "related_images": [
        {
          "digest": "sha256:f7993b7a5458679621f6686bdc4ab818659e051ef6cdf6a8e107f627adf5f178",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:f7993b7a5458679621f6686bdc4ab818659e051ef6cdf6a8e107f627adf5f178",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:4ec7ee0365c6ee8bd3edf70336542e547b361857bd7175a218f709ae4dbc449d",
          "image": "registry.connect.redhat.com/stakater/tenant-operator@sha256:4ec7ee0365c6ee8bd3edf70336542e547b361857bd7175a218f709ae4dbc449d",
          "name": "manager"
        },
        {
          "digest": "sha256:4ec7ee0365c6ee8bd3edf70336542e547b361857bd7175a218f709ae4dbc449d",
          "image": "registry.connect.redhat.com/stakater/tenant-operator@sha256:4ec7ee0365c6ee8bd3edf70336542e547b361857bd7175a218f709ae4dbc449d",
          "name": "tenant-operator-4ec7ee0365c6ee8bd3edf70336542e547b361857bd7175a218f709ae4dbc449d-annotation"
        }
      ],
      "replaces": null,
      "skip_range": "<0.7.4",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "0.7.5",
      "version_original": "0.7.5"
    },
    {
      "_id": "6374ba228b147d8e70147411",
      "alm_examples": [
        {
          "api_version": "tenantoperator.stakater.com/v1beta1",
          "kind": "Tenant",
          "metadata": {
            "name": "bluesky"
          },
          "spec": {
            "editors": {
              "groups": [
                "alpha"
              ],
              "users": [
                "john@aurora.org"
              ]
            },
            "namespaces": [
              "dev",
              "build",
              "prod"
            ],
            "owners": {
              "users": [
                "anna@aurora.org",
                "anthony@aurora.org"
              ]
            },
            "quota": "small"
          }
        },
        {
          "api_version": "tenantoperator.stakater.com/v1alpha1",
          "kind": "IntegrationConfig",
          "metadata": {
            "name": "tenant-operator-config",
            "namespace": "multi-tenant-operator"
          },
          "spec": {
            "argocd": {
              "clusterResourceWhitelist": [
                {
                  "group": "tronador.stakater.com",
                  "kind": "EnvironmentProvisioner"
                }
              ],
              "namespace": "openshift-operators",
              "namespaceResourceBlacklist": [
                {
                  "group": "",
                  "kind": "ResourceQuota"
                }
              ]
            },
            "openshift": {
              "clusterAdminGroups": [
                "cluster-admins"
              ],
              "group": {
                "labels": {
                  "role": "customer-reader"
                }
              },
              "namespaceAccessPolicy": {
                "deny": {
                  "privilegedNamespaces": {
                    "groups": [
                      "cluster-admins"
                    ],
                    "users": [
                      "system:serviceaccount:openshift-argocd:argocd-application-controller",
                      "adam@stakater.com"
                    ]
                  }
                }
              },
              "privilegedNamespaces": [
                "default",
                "^openshift-*",
                "^kube-*"
              ],
              "privilegedServiceAccounts": [
                "^system:serviceaccount:openshift-*",
                "^system:serviceaccount:kube-*"
              ],
              "project": {
                "annotations": {
                  "openshift.io/node-selector": "node-role.kubernetes.io/worker="
                },
                "labels": {
                  "stakater.com/workload-monitoring": "true"
                }
              },
              "sandbox": {
                "labels": {
                  "stakater.com/kind": "sandbox"
                }
              }
            },
            "rhsso": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "auth-secrets",
                  "namespace": "openshift-auth"
                },
                "url": "https://iam-keycloak-auth.apps.prod.abcdefghi.kubeapp.cloud/"
              }
            },
            "vault": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "vault-root-token",
                  "namespace": "vault"
                },
                "url": "https://vault.apps.prod.abcdefghi.kubeapp.cloud/"
              },
              "sso": {
                "accessorID": "<ACCESSOR_ID_TOKEN>",
                "clientName": "vault"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/stakater/tenant-operator-0@sha256:a7137fc3c15527c3988979f430a7fc6fd92ddbf2fde0e48b135fb5326c69401b",
      "bundle_path_digest": "sha256:a7137fc3c15527c3988979f430a7fc6fd92ddbf2fde0e48b135fb5326c69401b",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-16T10:23:30.900000+00:00",
      "csv_description": "OpenShift is designed to support a single tenant platform, hence making it difficult for cluster admins to host multi-tenancy in a single OpenShift cluster. If multi-tenancy is achieved by sharing a cluster, it can have many advantages, e.g. efficient resource utilization, less configuration effort and easier sharing of cluster-internal resources among different tenants. Multi Tenant Operator helps to solve the complexity issues of doing true multi-tenancy by providing simplified abstractions on top of the native primitives to provide organizations and platform providers the tooling, self-service capabilities and robust automation needed to do secure and efficient Multi-Tenancy in a single OpenShift cluster.\n\n## Access Control\n\nMulti Tenant Operator provides several ClusterRoles that are automatically bound to the Tenants Namespaces used for managing access to the Namespaces and the resources they contain. You can also modify the default roles or create new roles to have full control and customize access control for your users and teams.\n\n## Self-Service\n\nWith Multi Tenant Operator, you can empower your users to safely provision namespaces for themselves and their teams (typically mapped to SSO groups). Team-owned namespaces and the resources inside of them count towards the team's quotas rather than the user's individual limits and are automatically shared with all team members according to the access rules you configure in tenant-operator.\n\n## HashiCorp Vault Multitenancy\n\nMulti Tenant Operator is not only providing strong Multi-Tenancy for the OpenShift internals but also extends the tenant's permission model to HashiCorp Vault where it can create vault paths and greatly ease the overhead of managing RBAC in Vault.\n\n## ArgoCD Multitenancy\n\nMulti Tenant Operator is not only providing strong Multi-Tenancy for the OpenShift internals but also extends the tenant's permission model to ArgoCD where it can provision AppProjects and Allowed Repositories for your tenants greatly easing the overhead of managing RBAC in ArgoCD.\n\n## Cost/Resource Optimization\n\nMulti Tenant Operator provides a mechanism for defining Resource Quotas at the tenant scope, meaning all namespaces belonging to a particular tenant share the defined quota, which is why you are able to safely enable dev teams to self-serve their namespaces whilst being confident that they can only use the resources allocated based on budget and business needs.\n\n## Sandboxed Dev Namespaces\n\nMulti Tenant Operator can be configured to automatically provision a namespace for every member of the specific tenant, that will also be pre-loaded with any selected templates and consume the same pool of resources from the tenant's quota creating safe sandboxed dev namespaces that teams can use as a scratch namespace for rapid prototyping and development.",
      "csv_display_name": "Multi Tenant Operator",
      "csv_metadata_description": "OpenShift is designed to support a single tenant platform, hence making it difficult for cluster admins to host multi-tenancy in a single OpenShift cluster. If multi-tenancy is achieved by sharing a cluster, it can have many advantages, e.g. efficient resource utilization, less configuration effort and easier sharing of cluster-internal resources among different tenants. Stakater Multi-Tenancy Operator helps to solve the complexity issues of doing true multi-tenancy by providing simplified abstractions on top of the native primitives to provide organizations and platform providers the tooling, self-service capabilities and robust automation needed to do secure and efficient Multi-Tenancy in a single OpenShift cluster.",
      "csv_name": "tenant-operator.v0.7.5",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:29:55.661000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "tenant-operator",
      "provided_apis": [
        {
          "group": "tenantoperator.stakater.com",
          "kind": "IntegrationConfig",
          "plural": "integrationconfigs",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Quota",
          "plural": "quotas",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateGroupInstance",
          "plural": "templategroupinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateInstance",
          "plural": "templateinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "ResourceSupervisor",
          "plural": "resourcesupervisors",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Template",
          "plural": "templates",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta2"
        }
      ],
      "provider": "Stakater",
      "related_images": [
        {
          "digest": "sha256:f7993b7a5458679621f6686bdc4ab818659e051ef6cdf6a8e107f627adf5f178",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:f7993b7a5458679621f6686bdc4ab818659e051ef6cdf6a8e107f627adf5f178",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:4ec7ee0365c6ee8bd3edf70336542e547b361857bd7175a218f709ae4dbc449d",
          "image": "registry.connect.redhat.com/stakater/tenant-operator@sha256:4ec7ee0365c6ee8bd3edf70336542e547b361857bd7175a218f709ae4dbc449d",
          "name": "manager"
        },
        {
          "digest": "sha256:4ec7ee0365c6ee8bd3edf70336542e547b361857bd7175a218f709ae4dbc449d",
          "image": "registry.connect.redhat.com/stakater/tenant-operator@sha256:4ec7ee0365c6ee8bd3edf70336542e547b361857bd7175a218f709ae4dbc449d",
          "name": "tenant-operator-4ec7ee0365c6ee8bd3edf70336542e547b361857bd7175a218f709ae4dbc449d-annotation"
        }
      ],
      "replaces": null,
      "skip_range": "<0.7.4",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "0.7.5",
      "version_original": "0.7.5"
    },
    {
      "_id": "63753473039b5f41a63bfc59",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.7.1"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:6b410f2d77fb7aec1cddc90bcab8f5c373ff63970d7a2bfa309de9a69f7acd6d",
      "bundle_path_digest": "sha256:6b410f2d77fb7aec1cddc90bcab8f5c373ff63970d7a2bfa309de9a69f7acd6d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-16T19:05:23.929000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.18.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T06:35:33.248000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a",
          "name": "t8c-operator-1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a-annotation"
        },
        {
          "digest": "sha256:1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a",
          "name": "t8c-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "42.18.0",
      "version_original": "42.18.0"
    },
    {
      "_id": "6375347539c5577889420c08",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.7.1"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:6b410f2d77fb7aec1cddc90bcab8f5c373ff63970d7a2bfa309de9a69f7acd6d",
      "bundle_path_digest": "sha256:6b410f2d77fb7aec1cddc90bcab8f5c373ff63970d7a2bfa309de9a69f7acd6d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-16T19:05:25.397000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.18.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:07:13.973000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a",
          "name": "t8c-operator-1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a-annotation"
        },
        {
          "digest": "sha256:1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a",
          "name": "t8c-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "42.18.0",
      "version_original": "42.18.0"
    },
    {
      "_id": "63753496799f60c3015761c3",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.7.1"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:6b410f2d77fb7aec1cddc90bcab8f5c373ff63970d7a2bfa309de9a69f7acd6d",
      "bundle_path_digest": "sha256:6b410f2d77fb7aec1cddc90bcab8f5c373ff63970d7a2bfa309de9a69f7acd6d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-16T19:05:58.096000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.18.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:29:32.560000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a",
          "name": "t8c-operator-1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a-annotation"
        },
        {
          "digest": "sha256:1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a",
          "name": "t8c-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "42.18.0",
      "version_original": "42.18.0"
    },
    {
      "_id": "637534ec799f60c301576269",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.7.1"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:6b410f2d77fb7aec1cddc90bcab8f5c373ff63970d7a2bfa309de9a69f7acd6d",
      "bundle_path_digest": "sha256:6b410f2d77fb7aec1cddc90bcab8f5c373ff63970d7a2bfa309de9a69f7acd6d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-16T19:07:23.997000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.18.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T08:22:46.388000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a",
          "name": "t8c-operator-1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a-annotation"
        },
        {
          "digest": "sha256:1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a",
          "name": "t8c-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "42.18.0",
      "version_original": "42.18.0"
    },
    {
      "_id": "63753764d54d96b9ae5cc914",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.7.1"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:6b410f2d77fb7aec1cddc90bcab8f5c373ff63970d7a2bfa309de9a69f7acd6d",
      "bundle_path_digest": "sha256:6b410f2d77fb7aec1cddc90bcab8f5c373ff63970d7a2bfa309de9a69f7acd6d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-16T19:17:56.537000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.18.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:41:48.223000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a",
          "name": "t8c-operator-1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a-annotation"
        },
        {
          "digest": "sha256:1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:1c8d2364f6ae71db12012728669142c38e49c5ab3e648e364bba43159ddfec4a",
          "name": "t8c-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "42.18.0",
      "version_original": "42.18.0"
    },
    {
      "_id": "63766029820ea79a5e4dab5c",
      "alm_examples": [
        {
          "api_version": "anzo.cambridgesemantics.com/v1",
          "kind": "Anzo",
          "metadata": {
            "name": "agent01"
          },
          "spec": {
            "nodeConfig": {
              "spec": {
                "replicas": 1,
                "selector": {
                  "matchLabels": {
                    "app": "anzo"
                  }
                },
                "serviceName": "anzo-agent01",
                "template": {
                  "metadata": {
                    "labels": {
                      "app": "anzo"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "image": "registry.connect.redhat.com/cambridgesemantics/anzo@sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
                        "name": "anzo",
                        "resources": {
                          "limits": {
                            "cpu": "4000m",
                            "memory": "12Gi"
                          },
                          "requests": {
                            "cpu": "4000m",
                            "memory": "12Gi"
                          }
                        }
                      }
                    ],
                    "serviceAccountName": "anzo-operator"
                  }
                }
              }
            },
            "role": "AnzoAgent"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cambridgesemantics/anzo-operator-bundle@sha256:d4efa2bd80c4084ed7ec9c65e03e2064bbabdc0c0f4eb5a5a788f37d0e831c30",
      "bundle_path_digest": "sha256:d4efa2bd80c4084ed7ec9c65e03e2064bbabdc0c0f4eb5a5a788f37d0e831c30",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-17T16:24:09.974000+00:00",
      "csv_description": "The Anzo Operator provides the way to install and configure an anzo agent setup on Red Hat K8S environment.\nCurrently, this is supported only through when deployed as an Anzo Agent as part of an Anzo Unstructured deployment.\n\n### Installation\n Refer [installation instructions]( https://github.com/cambridgesemantics/csi-k8s-operator-anzo/blob/v2.0.2/README.md )\n\n### Documentation\n\nYou can find our documentation [here.]( https://docs.cambridgesemantics.com/anzo/userdoc/cloud-deployments.htm )\n\n### Support\n\nWe offer Support to our customers through [ Cambridge Semantics Customer Center ]( https://customercenter.cambridgesemantics.com/ ).",
      "csv_display_name": "Anzo Operator",
      "csv_metadata_description": "kubernetes operator for Anzo",
      "csv_name": "anzo-operator.v2.0.203",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T08:21:53.580000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "anzo-operator",
      "provided_apis": [
        {
          "group": "anzo.cambridgesemantics.com",
          "kind": "Anzo",
          "version": "v1"
        }
      ],
      "provider": "Cambridge Semantics Inc.",
      "related_images": [
        {
          "digest": "sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo@sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
          "name": "anzo"
        },
        {
          "digest": "sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-operator@sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "name": "anzo-operator"
        },
        {
          "digest": "sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-operator@sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "name": "anzo-operator-53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4-annotation"
        },
        {
          "digest": "sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-operator@sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "name": "manager"
        },
        {
          "digest": "sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo@sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
          "name": "anzo-a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "2.0.203",
      "version_original": "2.0.203"
    },
    {
      "_id": "637660769ab920c27f037962",
      "alm_examples": [
        {
          "api_version": "anzo.cambridgesemantics.com/v1",
          "kind": "Anzo",
          "metadata": {
            "name": "agent01"
          },
          "spec": {
            "nodeConfig": {
              "spec": {
                "replicas": 1,
                "selector": {
                  "matchLabels": {
                    "app": "anzo"
                  }
                },
                "serviceName": "anzo-agent01",
                "template": {
                  "metadata": {
                    "labels": {
                      "app": "anzo"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "image": "registry.connect.redhat.com/cambridgesemantics/anzo@sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
                        "name": "anzo",
                        "resources": {
                          "limits": {
                            "cpu": "4000m",
                            "memory": "12Gi"
                          },
                          "requests": {
                            "cpu": "4000m",
                            "memory": "12Gi"
                          }
                        }
                      }
                    ],
                    "serviceAccountName": "anzo-operator"
                  }
                }
              }
            },
            "role": "AnzoAgent"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cambridgesemantics/anzo-operator-bundle@sha256:d4efa2bd80c4084ed7ec9c65e03e2064bbabdc0c0f4eb5a5a788f37d0e831c30",
      "bundle_path_digest": "sha256:d4efa2bd80c4084ed7ec9c65e03e2064bbabdc0c0f4eb5a5a788f37d0e831c30",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-17T16:25:26.810000+00:00",
      "csv_description": "The Anzo Operator provides the way to install and configure an anzo agent setup on Red Hat K8S environment.\nCurrently, this is supported only through when deployed as an Anzo Agent as part of an Anzo Unstructured deployment.\n\n### Installation\n Refer [installation instructions]( https://github.com/cambridgesemantics/csi-k8s-operator-anzo/blob/v2.0.2/README.md )\n\n### Documentation\n\nYou can find our documentation [here.]( https://docs.cambridgesemantics.com/anzo/userdoc/cloud-deployments.htm )\n\n### Support\n\nWe offer Support to our customers through [ Cambridge Semantics Customer Center ]( https://customercenter.cambridgesemantics.com/ ).",
      "csv_display_name": "Anzo Operator",
      "csv_metadata_description": "kubernetes operator for Anzo",
      "csv_name": "anzo-operator.v2.0.203",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:06:28.602000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "anzo-operator",
      "provided_apis": [
        {
          "group": "anzo.cambridgesemantics.com",
          "kind": "Anzo",
          "version": "v1"
        }
      ],
      "provider": "Cambridge Semantics Inc.",
      "related_images": [
        {
          "digest": "sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo@sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
          "name": "anzo"
        },
        {
          "digest": "sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-operator@sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "name": "anzo-operator"
        },
        {
          "digest": "sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-operator@sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "name": "anzo-operator-53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4-annotation"
        },
        {
          "digest": "sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-operator@sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "name": "manager"
        },
        {
          "digest": "sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo@sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
          "name": "anzo-a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2.0.203",
      "version_original": "2.0.203"
    },
    {
      "_id": "63766087d861bd7aa7a6651b",
      "alm_examples": [
        {
          "api_version": "anzo.cambridgesemantics.com/v1",
          "kind": "Anzo",
          "metadata": {
            "name": "agent01"
          },
          "spec": {
            "nodeConfig": {
              "spec": {
                "replicas": 1,
                "selector": {
                  "matchLabels": {
                    "app": "anzo"
                  }
                },
                "serviceName": "anzo-agent01",
                "template": {
                  "metadata": {
                    "labels": {
                      "app": "anzo"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "image": "registry.connect.redhat.com/cambridgesemantics/anzo@sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
                        "name": "anzo",
                        "resources": {
                          "limits": {
                            "cpu": "4000m",
                            "memory": "12Gi"
                          },
                          "requests": {
                            "cpu": "4000m",
                            "memory": "12Gi"
                          }
                        }
                      }
                    ],
                    "serviceAccountName": "anzo-operator"
                  }
                }
              }
            },
            "role": "AnzoAgent"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cambridgesemantics/anzo-operator-bundle@sha256:d4efa2bd80c4084ed7ec9c65e03e2064bbabdc0c0f4eb5a5a788f37d0e831c30",
      "bundle_path_digest": "sha256:d4efa2bd80c4084ed7ec9c65e03e2064bbabdc0c0f4eb5a5a788f37d0e831c30",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-17T16:25:43.137000+00:00",
      "csv_description": "The Anzo Operator provides the way to install and configure an anzo agent setup on Red Hat K8S environment.\nCurrently, this is supported only through when deployed as an Anzo Agent as part of an Anzo Unstructured deployment.\n\n### Installation\n Refer [installation instructions]( https://github.com/cambridgesemantics/csi-k8s-operator-anzo/blob/v2.0.2/README.md )\n\n### Documentation\n\nYou can find our documentation [here.]( https://docs.cambridgesemantics.com/anzo/userdoc/cloud-deployments.htm )\n\n### Support\n\nWe offer Support to our customers through [ Cambridge Semantics Customer Center ]( https://customercenter.cambridgesemantics.com/ ).",
      "csv_display_name": "Anzo Operator",
      "csv_metadata_description": "kubernetes operator for Anzo",
      "csv_name": "anzo-operator.v2.0.203",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T08:19:06.749000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "anzo-operator",
      "provided_apis": [
        {
          "group": "anzo.cambridgesemantics.com",
          "kind": "Anzo",
          "plural": "anzos",
          "version": "v1"
        }
      ],
      "provider": "Cambridge Semantics Inc.",
      "related_images": [
        {
          "digest": "sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo@sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
          "name": "anzo"
        },
        {
          "digest": "sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-operator@sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "name": "anzo-operator"
        },
        {
          "digest": "sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-operator@sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "name": "anzo-operator-53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4-annotation"
        },
        {
          "digest": "sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-operator@sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "name": "manager"
        },
        {
          "digest": "sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo@sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
          "name": "anzo-a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "2.0.203",
      "version_original": "2.0.203"
    },
    {
      "_id": "637660a7d54d96b9ae5eb1ba",
      "alm_examples": [
        {
          "api_version": "anzo.cambridgesemantics.com/v1",
          "kind": "Anzo",
          "metadata": {
            "name": "agent01"
          },
          "spec": {
            "nodeConfig": {
              "spec": {
                "replicas": 1,
                "selector": {
                  "matchLabels": {
                    "app": "anzo"
                  }
                },
                "serviceName": "anzo-agent01",
                "template": {
                  "metadata": {
                    "labels": {
                      "app": "anzo"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "image": "registry.connect.redhat.com/cambridgesemantics/anzo@sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
                        "name": "anzo",
                        "resources": {
                          "limits": {
                            "cpu": "4000m",
                            "memory": "12Gi"
                          },
                          "requests": {
                            "cpu": "4000m",
                            "memory": "12Gi"
                          }
                        }
                      }
                    ],
                    "serviceAccountName": "anzo-operator"
                  }
                }
              }
            },
            "role": "AnzoAgent"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cambridgesemantics/anzo-operator-bundle@sha256:d4efa2bd80c4084ed7ec9c65e03e2064bbabdc0c0f4eb5a5a788f37d0e831c30",
      "bundle_path_digest": "sha256:d4efa2bd80c4084ed7ec9c65e03e2064bbabdc0c0f4eb5a5a788f37d0e831c30",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-17T16:26:15.034000+00:00",
      "csv_description": "The Anzo Operator provides the way to install and configure an anzo agent setup on Red Hat K8S environment.\nCurrently, this is supported only through when deployed as an Anzo Agent as part of an Anzo Unstructured deployment.\n\n### Installation\n Refer [installation instructions]( https://github.com/cambridgesemantics/csi-k8s-operator-anzo/blob/v2.0.2/README.md )\n\n### Documentation\n\nYou can find our documentation [here.]( https://docs.cambridgesemantics.com/anzo/userdoc/cloud-deployments.htm )\n\n### Support\n\nWe offer Support to our customers through [ Cambridge Semantics Customer Center ]( https://customercenter.cambridgesemantics.com/ ).",
      "csv_display_name": "Anzo Operator",
      "csv_metadata_description": "kubernetes operator for Anzo",
      "csv_name": "anzo-operator.v2.0.203",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:03:15.346000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "anzo-operator",
      "provided_apis": [
        {
          "group": "anzo.cambridgesemantics.com",
          "kind": "Anzo",
          "plural": "anzos",
          "version": "v1"
        }
      ],
      "provider": "Cambridge Semantics Inc.",
      "related_images": [
        {
          "digest": "sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo@sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
          "name": "anzo"
        },
        {
          "digest": "sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-operator@sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "name": "anzo-operator"
        },
        {
          "digest": "sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-operator@sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "name": "anzo-operator-53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4-annotation"
        },
        {
          "digest": "sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-operator@sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "name": "manager"
        },
        {
          "digest": "sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo@sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
          "name": "anzo-a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2.0.203",
      "version_original": "2.0.203"
    },
    {
      "_id": "637661349dc40044c5f5966b",
      "alm_examples": [
        {
          "api_version": "anzo.cambridgesemantics.com/v1",
          "kind": "Anzo",
          "metadata": {
            "name": "agent01"
          },
          "spec": {
            "nodeConfig": {
              "spec": {
                "replicas": 1,
                "selector": {
                  "matchLabels": {
                    "app": "anzo"
                  }
                },
                "serviceName": "anzo-agent01",
                "template": {
                  "metadata": {
                    "labels": {
                      "app": "anzo"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "image": "registry.connect.redhat.com/cambridgesemantics/anzo@sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
                        "name": "anzo",
                        "resources": {
                          "limits": {
                            "cpu": "4000m",
                            "memory": "12Gi"
                          },
                          "requests": {
                            "cpu": "4000m",
                            "memory": "12Gi"
                          }
                        }
                      }
                    ],
                    "serviceAccountName": "anzo-operator"
                  }
                }
              }
            },
            "role": "AnzoAgent"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cambridgesemantics/anzo-operator-bundle@sha256:d4efa2bd80c4084ed7ec9c65e03e2064bbabdc0c0f4eb5a5a788f37d0e831c30",
      "bundle_path_digest": "sha256:d4efa2bd80c4084ed7ec9c65e03e2064bbabdc0c0f4eb5a5a788f37d0e831c30",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-17T16:28:36.322000+00:00",
      "csv_description": "The Anzo Operator provides the way to install and configure an anzo agent setup on Red Hat K8S environment.\nCurrently, this is supported only through when deployed as an Anzo Agent as part of an Anzo Unstructured deployment.\n\n### Installation\n Refer [installation instructions]( https://github.com/cambridgesemantics/csi-k8s-operator-anzo/blob/v2.0.2/README.md )\n\n### Documentation\n\nYou can find our documentation [here.]( https://docs.cambridgesemantics.com/anzo/userdoc/cloud-deployments.htm )\n\n### Support\n\nWe offer Support to our customers through [ Cambridge Semantics Customer Center ]( https://customercenter.cambridgesemantics.com/ ).",
      "csv_display_name": "Anzo Operator",
      "csv_metadata_description": "kubernetes operator for Anzo",
      "csv_name": "anzo-operator.v2.0.203",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:45:36.178000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "anzo-operator",
      "provided_apis": [
        {
          "group": "anzo.cambridgesemantics.com",
          "kind": "Anzo",
          "plural": "anzos",
          "version": "v1"
        }
      ],
      "provider": "Cambridge Semantics Inc.",
      "related_images": [
        {
          "digest": "sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo@sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
          "name": "anzo"
        },
        {
          "digest": "sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-operator@sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "name": "anzo-operator"
        },
        {
          "digest": "sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-operator@sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "name": "anzo-operator-53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4-annotation"
        },
        {
          "digest": "sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-operator@sha256:53c1e0a6ec6ae9fc3b43cc3b494b20d1d77e94b433a216492f492cff7b71a9b4",
          "name": "manager"
        },
        {
          "digest": "sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo@sha256:a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e",
          "name": "anzo-a7e76e1c7e9e62cf9dae89b55f3255fb707259a9a326ac087f83e689a05ae60e-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2.0.203",
      "version_original": "2.0.203"
    },
    {
      "_id": "63766f6d5e3261eca76c5527",
      "alm_examples": [
        {
          "api_version": "anzounstructured.clusters.cambridgesemantics.com/v1",
          "kind": "AnzoUnstructured",
          "metadata": {
            "name": "au01"
          },
          "spec": {
            "auWorker": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app": "anzounstructured"
                    }
                  },
                  "serviceName": "au-au01-w",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app": "anzounstructured"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
                          "name": "w",
                          "resources": {
                            "limits": {
                              "cpu": "2",
                              "memory": "4Gi"
                            },
                            "requests": {
                              "cpu": "2",
                              "memory": "4Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "unstructured-operator"
                    }
                  }
                }
              }
            },
            "msLeader": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app": "anzounstructured"
                    }
                  },
                  "serviceName": "au-au01-ms",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app": "anzounstructured"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-leader@sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
                          "name": "ms",
                          "resources": {
                            "limits": {
                              "cpu": "2",
                              "memory": "4Gi"
                            },
                            "requests": {
                              "cpu": "2",
                              "memory": "4Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "unstructured-operator"
                    }
                  }
                }
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-operator-bundle@sha256:6dfc5fd834fb54073f0a6cd0d64a57e89a35621424c0e7cd7e6fd1927d420f49",
      "bundle_path_digest": "sha256:6dfc5fd834fb54073f0a6cd0d64a57e89a35621424c0e7cd7e6fd1927d420f49",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-17T17:29:17.865000+00:00",
      "csv_description": "The Anzo Unstructured Operator provides the way to install and configure an anzo unstructured setup on Red Hat K8S environment.\nCurrently, this is possible only through existing Anzo installation.\n\n### Installation\n Refer [installation instructions]( https://github.com/cambridgesemantics/csi-k8s-operator-anzo-unstructured/blob/v2.0.2/README.md )\n\n### Documentation\n\nYou can find our documentation [here.]( https://docs.cambridgesemantics.com/anzo/userdoc/cloud-deployments.htm )\n\n### Support\n\nWe offer Support to our customers through [ Cambridge Semantics Customer Center ]( https://customercenter.cambridgesemantics.com/ ).",
      "csv_display_name": "Anzo Unstructured Operator",
      "csv_metadata_description": "Kubernetes Operator for Anzo Unstructured",
      "csv_name": "anzounstructured-operator.v2.0.203",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T08:31:13.031000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "anzounstructured-operator",
      "provided_apis": [
        {
          "group": "anzounstructured.clusters.cambridgesemantics.com",
          "kind": "AnzoUnstructured",
          "version": "v1"
        }
      ],
      "provider": "Cambridge Semantics Inc.",
      "related_images": [
        {
          "digest": "sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-leader@sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "name": "anzo-microservices-leader"
        },
        {
          "digest": "sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "name": "anzo-unstructured-worker"
        },
        {
          "digest": "sha256:f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee",
          "image": "registry.connect.redhat.com/cambridgesemantics/unstructured-operator@sha256:f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee",
          "name": "unstructured-operator-f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee-annotation"
        },
        {
          "digest": "sha256:f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee",
          "image": "registry.connect.redhat.com/cambridgesemantics/unstructured-operator@sha256:f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee",
          "name": "manager"
        },
        {
          "digest": "sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-leader@sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "name": "anzo_microservices_leader"
        },
        {
          "digest": "sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "name": "anzo_unstructured_worker"
        },
        {
          "digest": "sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-leader@sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "name": "anzo-unstructured-leader-f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac-annotation"
        },
        {
          "digest": "sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "name": "anzo-unstructured-worker-24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "2.0.203",
      "version_original": "2.0.203"
    },
    {
      "_id": "63766fef39c55778894417dc",
      "alm_examples": [
        {
          "api_version": "anzounstructured.clusters.cambridgesemantics.com/v1",
          "kind": "AnzoUnstructured",
          "metadata": {
            "name": "au01"
          },
          "spec": {
            "auWorker": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app": "anzounstructured"
                    }
                  },
                  "serviceName": "au-au01-w",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app": "anzounstructured"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
                          "name": "w",
                          "resources": {
                            "limits": {
                              "cpu": "2",
                              "memory": "4Gi"
                            },
                            "requests": {
                              "cpu": "2",
                              "memory": "4Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "unstructured-operator"
                    }
                  }
                }
              }
            },
            "msLeader": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app": "anzounstructured"
                    }
                  },
                  "serviceName": "au-au01-ms",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app": "anzounstructured"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-leader@sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
                          "name": "ms",
                          "resources": {
                            "limits": {
                              "cpu": "2",
                              "memory": "4Gi"
                            },
                            "requests": {
                              "cpu": "2",
                              "memory": "4Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "unstructured-operator"
                    }
                  }
                }
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-operator-bundle@sha256:6dfc5fd834fb54073f0a6cd0d64a57e89a35621424c0e7cd7e6fd1927d420f49",
      "bundle_path_digest": "sha256:6dfc5fd834fb54073f0a6cd0d64a57e89a35621424c0e7cd7e6fd1927d420f49",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-17T17:31:27.269000+00:00",
      "csv_description": "The Anzo Unstructured Operator provides the way to install and configure an anzo unstructured setup on Red Hat K8S environment.\nCurrently, this is possible only through existing Anzo installation.\n\n### Installation\n Refer [installation instructions]( https://github.com/cambridgesemantics/csi-k8s-operator-anzo-unstructured/blob/v2.0.2/README.md )\n\n### Documentation\n\nYou can find our documentation [here.]( https://docs.cambridgesemantics.com/anzo/userdoc/cloud-deployments.htm )\n\n### Support\n\nWe offer Support to our customers through [ Cambridge Semantics Customer Center ]( https://customercenter.cambridgesemantics.com/ ).",
      "csv_display_name": "Anzo Unstructured Operator",
      "csv_metadata_description": "Kubernetes Operator for Anzo Unstructured",
      "csv_name": "anzounstructured-operator.v2.0.203",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T06:42:25.255000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "anzounstructured-operator",
      "provided_apis": [
        {
          "group": "anzounstructured.clusters.cambridgesemantics.com",
          "kind": "AnzoUnstructured",
          "version": "v1"
        }
      ],
      "provider": "Cambridge Semantics Inc.",
      "related_images": [
        {
          "digest": "sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-leader@sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "name": "anzo-microservices-leader"
        },
        {
          "digest": "sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "name": "anzo-unstructured-worker"
        },
        {
          "digest": "sha256:f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee",
          "image": "registry.connect.redhat.com/cambridgesemantics/unstructured-operator@sha256:f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee",
          "name": "unstructured-operator-f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee-annotation"
        },
        {
          "digest": "sha256:f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee",
          "image": "registry.connect.redhat.com/cambridgesemantics/unstructured-operator@sha256:f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee",
          "name": "manager"
        },
        {
          "digest": "sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-leader@sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "name": "anzo_microservices_leader"
        },
        {
          "digest": "sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "name": "anzo_unstructured_worker"
        },
        {
          "digest": "sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-leader@sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "name": "anzo-unstructured-leader-f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac-annotation"
        },
        {
          "digest": "sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "name": "anzo-unstructured-worker-24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2.0.203",
      "version_original": "2.0.203"
    },
    {
      "_id": "637670095e3261eca76c563f",
      "alm_examples": [
        {
          "api_version": "anzounstructured.clusters.cambridgesemantics.com/v1",
          "kind": "AnzoUnstructured",
          "metadata": {
            "name": "au01"
          },
          "spec": {
            "auWorker": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app": "anzounstructured"
                    }
                  },
                  "serviceName": "au-au01-w",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app": "anzounstructured"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
                          "name": "w",
                          "resources": {
                            "limits": {
                              "cpu": "2",
                              "memory": "4Gi"
                            },
                            "requests": {
                              "cpu": "2",
                              "memory": "4Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "unstructured-operator"
                    }
                  }
                }
              }
            },
            "msLeader": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app": "anzounstructured"
                    }
                  },
                  "serviceName": "au-au01-ms",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app": "anzounstructured"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-leader@sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
                          "name": "ms",
                          "resources": {
                            "limits": {
                              "cpu": "2",
                              "memory": "4Gi"
                            },
                            "requests": {
                              "cpu": "2",
                              "memory": "4Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "unstructured-operator"
                    }
                  }
                }
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-operator-bundle@sha256:6dfc5fd834fb54073f0a6cd0d64a57e89a35621424c0e7cd7e6fd1927d420f49",
      "bundle_path_digest": "sha256:6dfc5fd834fb54073f0a6cd0d64a57e89a35621424c0e7cd7e6fd1927d420f49",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-17T17:31:53.511000+00:00",
      "csv_description": "The Anzo Unstructured Operator provides the way to install and configure an anzo unstructured setup on Red Hat K8S environment.\nCurrently, this is possible only through existing Anzo installation.\n\n### Installation\n Refer [installation instructions]( https://github.com/cambridgesemantics/csi-k8s-operator-anzo-unstructured/blob/v2.0.2/README.md )\n\n### Documentation\n\nYou can find our documentation [here.]( https://docs.cambridgesemantics.com/anzo/userdoc/cloud-deployments.htm )\n\n### Support\n\nWe offer Support to our customers through [ Cambridge Semantics Customer Center ]( https://customercenter.cambridgesemantics.com/ ).",
      "csv_display_name": "Anzo Unstructured Operator",
      "csv_metadata_description": "Kubernetes Operator for Anzo Unstructured",
      "csv_name": "anzounstructured-operator.v2.0.203",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T08:19:15.507000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "anzounstructured-operator",
      "provided_apis": [
        {
          "group": "anzounstructured.clusters.cambridgesemantics.com",
          "kind": "AnzoUnstructured",
          "plural": "anzounstructureds",
          "version": "v1"
        }
      ],
      "provider": "Cambridge Semantics Inc.",
      "related_images": [
        {
          "digest": "sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-leader@sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "name": "anzo-microservices-leader"
        },
        {
          "digest": "sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "name": "anzo-unstructured-worker"
        },
        {
          "digest": "sha256:f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee",
          "image": "registry.connect.redhat.com/cambridgesemantics/unstructured-operator@sha256:f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee",
          "name": "unstructured-operator-f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee-annotation"
        },
        {
          "digest": "sha256:f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee",
          "image": "registry.connect.redhat.com/cambridgesemantics/unstructured-operator@sha256:f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee",
          "name": "manager"
        },
        {
          "digest": "sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-leader@sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "name": "anzo_microservices_leader"
        },
        {
          "digest": "sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "name": "anzo_unstructured_worker"
        },
        {
          "digest": "sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-leader@sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "name": "anzo-unstructured-leader-f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac-annotation"
        },
        {
          "digest": "sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "name": "anzo-unstructured-worker-24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "2.0.203",
      "version_original": "2.0.203"
    },
    {
      "_id": "6376704f820ea79a5e4dcbbe",
      "alm_examples": [
        {
          "api_version": "anzounstructured.clusters.cambridgesemantics.com/v1",
          "kind": "AnzoUnstructured",
          "metadata": {
            "name": "au01"
          },
          "spec": {
            "auWorker": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app": "anzounstructured"
                    }
                  },
                  "serviceName": "au-au01-w",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app": "anzounstructured"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
                          "name": "w",
                          "resources": {
                            "limits": {
                              "cpu": "2",
                              "memory": "4Gi"
                            },
                            "requests": {
                              "cpu": "2",
                              "memory": "4Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "unstructured-operator"
                    }
                  }
                }
              }
            },
            "msLeader": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app": "anzounstructured"
                    }
                  },
                  "serviceName": "au-au01-ms",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app": "anzounstructured"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-leader@sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
                          "name": "ms",
                          "resources": {
                            "limits": {
                              "cpu": "2",
                              "memory": "4Gi"
                            },
                            "requests": {
                              "cpu": "2",
                              "memory": "4Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "unstructured-operator"
                    }
                  }
                }
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-operator-bundle@sha256:6dfc5fd834fb54073f0a6cd0d64a57e89a35621424c0e7cd7e6fd1927d420f49",
      "bundle_path_digest": "sha256:6dfc5fd834fb54073f0a6cd0d64a57e89a35621424c0e7cd7e6fd1927d420f49",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-17T17:33:03.201000+00:00",
      "csv_description": "The Anzo Unstructured Operator provides the way to install and configure an anzo unstructured setup on Red Hat K8S environment.\nCurrently, this is possible only through existing Anzo installation.\n\n### Installation\n Refer [installation instructions]( https://github.com/cambridgesemantics/csi-k8s-operator-anzo-unstructured/blob/v2.0.2/README.md )\n\n### Documentation\n\nYou can find our documentation [here.]( https://docs.cambridgesemantics.com/anzo/userdoc/cloud-deployments.htm )\n\n### Support\n\nWe offer Support to our customers through [ Cambridge Semantics Customer Center ]( https://customercenter.cambridgesemantics.com/ ).",
      "csv_display_name": "Anzo Unstructured Operator",
      "csv_metadata_description": "Kubernetes Operator for Anzo Unstructured",
      "csv_name": "anzounstructured-operator.v2.0.203",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:03:30.879000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "anzounstructured-operator",
      "provided_apis": [
        {
          "group": "anzounstructured.clusters.cambridgesemantics.com",
          "kind": "AnzoUnstructured",
          "plural": "anzounstructureds",
          "version": "v1"
        }
      ],
      "provider": "Cambridge Semantics Inc.",
      "related_images": [
        {
          "digest": "sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-leader@sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "name": "anzo-microservices-leader"
        },
        {
          "digest": "sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "name": "anzo-unstructured-worker"
        },
        {
          "digest": "sha256:f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee",
          "image": "registry.connect.redhat.com/cambridgesemantics/unstructured-operator@sha256:f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee",
          "name": "unstructured-operator-f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee-annotation"
        },
        {
          "digest": "sha256:f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee",
          "image": "registry.connect.redhat.com/cambridgesemantics/unstructured-operator@sha256:f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee",
          "name": "manager"
        },
        {
          "digest": "sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-leader@sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "name": "anzo_microservices_leader"
        },
        {
          "digest": "sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "name": "anzo_unstructured_worker"
        },
        {
          "digest": "sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-leader@sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "name": "anzo-unstructured-leader-f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac-annotation"
        },
        {
          "digest": "sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "name": "anzo-unstructured-worker-24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2.0.203",
      "version_original": "2.0.203"
    },
    {
      "_id": "6376710f039b5f41a63e0970",
      "alm_examples": [
        {
          "api_version": "anzounstructured.clusters.cambridgesemantics.com/v1",
          "kind": "AnzoUnstructured",
          "metadata": {
            "name": "au01"
          },
          "spec": {
            "auWorker": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app": "anzounstructured"
                    }
                  },
                  "serviceName": "au-au01-w",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app": "anzounstructured"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
                          "name": "w",
                          "resources": {
                            "limits": {
                              "cpu": "2",
                              "memory": "4Gi"
                            },
                            "requests": {
                              "cpu": "2",
                              "memory": "4Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "unstructured-operator"
                    }
                  }
                }
              }
            },
            "msLeader": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app": "anzounstructured"
                    }
                  },
                  "serviceName": "au-au01-ms",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app": "anzounstructured"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-leader@sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
                          "name": "ms",
                          "resources": {
                            "limits": {
                              "cpu": "2",
                              "memory": "4Gi"
                            },
                            "requests": {
                              "cpu": "2",
                              "memory": "4Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "unstructured-operator"
                    }
                  }
                }
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-operator-bundle@sha256:6dfc5fd834fb54073f0a6cd0d64a57e89a35621424c0e7cd7e6fd1927d420f49",
      "bundle_path_digest": "sha256:6dfc5fd834fb54073f0a6cd0d64a57e89a35621424c0e7cd7e6fd1927d420f49",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-17T17:36:15.157000+00:00",
      "csv_description": "The Anzo Unstructured Operator provides the way to install and configure an anzo unstructured setup on Red Hat K8S environment.\nCurrently, this is possible only through existing Anzo installation.\n\n### Installation\n Refer [installation instructions]( https://github.com/cambridgesemantics/csi-k8s-operator-anzo-unstructured/blob/v2.0.2/README.md )\n\n### Documentation\n\nYou can find our documentation [here.]( https://docs.cambridgesemantics.com/anzo/userdoc/cloud-deployments.htm )\n\n### Support\n\nWe offer Support to our customers through [ Cambridge Semantics Customer Center ]( https://customercenter.cambridgesemantics.com/ ).",
      "csv_display_name": "Anzo Unstructured Operator",
      "csv_metadata_description": "Kubernetes Operator for Anzo Unstructured",
      "csv_name": "anzounstructured-operator.v2.0.203",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:40:45.529000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "anzounstructured-operator",
      "provided_apis": [
        {
          "group": "anzounstructured.clusters.cambridgesemantics.com",
          "kind": "AnzoUnstructured",
          "plural": "anzounstructureds",
          "version": "v1"
        }
      ],
      "provider": "Cambridge Semantics Inc.",
      "related_images": [
        {
          "digest": "sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-leader@sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "name": "anzo-microservices-leader"
        },
        {
          "digest": "sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "name": "anzo-unstructured-worker"
        },
        {
          "digest": "sha256:f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee",
          "image": "registry.connect.redhat.com/cambridgesemantics/unstructured-operator@sha256:f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee",
          "name": "unstructured-operator-f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee-annotation"
        },
        {
          "digest": "sha256:f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee",
          "image": "registry.connect.redhat.com/cambridgesemantics/unstructured-operator@sha256:f0206453f3b4c98e5ccd87c3939902b577c2b27141f6d873a264996388cccbee",
          "name": "manager"
        },
        {
          "digest": "sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-leader@sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "name": "anzo_microservices_leader"
        },
        {
          "digest": "sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "name": "anzo_unstructured_worker"
        },
        {
          "digest": "sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-leader@sha256:f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac",
          "name": "anzo-unstructured-leader-f79a78a97ff53ac23db79ed7444bdf486ea5869b11dc2f31463892138558f6ac-annotation"
        },
        {
          "digest": "sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327",
          "name": "anzo-unstructured-worker-24bdcfd076049380be14aba2cea0d06dd5c7a68e4581ccf448a6f117c9319327-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2.0.203",
      "version_original": "2.0.203"
    },
    {
      "_id": "6376922dd861bd7aa7a6bf0b",
      "alm_examples": [
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Backup",
          "metadata": {
            "name": "backup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Cluster",
          "metadata": {
            "name": "cluster-sample"
          },
          "spec": {
            "instances": 3,
            "logLevel": "info",
            "primaryUpdateStrategy": "unsupervised",
            "storage": {
              "size": "1Gi"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Pooler",
          "metadata": {
            "name": "pooler-sample-rw"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "instances": 1,
            "pgbouncer": {
              "poolMode": "session"
            },
            "type": "rw"
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "ScheduledBackup",
          "metadata": {
            "name": "scheduledbackup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "schedule": "0 0 0 * * *"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [
        "amd64",
        "ppc64le",
        "s390x"
      ],
      "bundle_path": "registry.connect.redhat.com/enterprisedb/cloud-native-postgresql@sha256:c36c85656588ce1c5872a29e43a956e4abdf6dacedeec9c28bada5503afc579d",
      "bundle_path_digest": "sha256:c36c85656588ce1c5872a29e43a956e4abdf6dacedeec9c28bada5503afc579d",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable-v1.16",
      "creation_date": "2022-11-17T19:57:33.029000+00:00",
      "csv_description": "EDB Postgres for Kubernetes is an operator designed, developed, and supported by EDB that covers the full \nlifecycle of a highly available Postgres database clusters with a primary/standby architecture, using native\nstreaming replication. It is based on the open source CloudNativePG operator, and provides additional value\nsuch as compatibility with Oracle using EDB Postgres Advanced Server and additional supported platforms such\nas IBM Power and OpenShift.\n\nKey features available include:\n\n* Kubernetes API integration for high availability\n* Self-healing through failover and automated recreation of replicas\n* Capacity management with scale up/down capabilities\n* Planned switchovers for scheduled maintenance\n* Read-only and read-write Kubernetes services definitions\n* Rolling updates for Postgres minor versions and operator upgrades\n* Continuous backup and point-in-time recovery\n* Connection Pooling with PgBouncer\n* Integrated metrics exporter out of the box\n* PostgreSQL replication across multiple Kubernetes clusters\n* Red Hat certified operator for OpenShift\n\nThe operator has been renamed from Cloud Native PostgreSQL. Existing users of Cloud Native PostgreSQL will not\nexperience any change, as the underlying components and resources have not changed.\n",
      "csv_display_name": "EDB Postgres for Kubernetes",
      "csv_metadata_description": "Operator to manage Postgres high availability clusters with a primary/standby architecture.",
      "csv_name": "cloud-native-postgresql.v1.16.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T07:36:32.654000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "cloud-native-postgresql",
      "provided_apis": [
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Pooler",
          "plural": "poolers",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "ScheduledBackup",
          "plural": "scheduledbackups",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Backup",
          "plural": "backups",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Cluster",
          "plural": "clusters",
          "version": "v1"
        }
      ],
      "provider": "EnterpriseDB Corporation",
      "related_images": [
        {
          "digest": "sha256:08a3128dd4d6ac81a9f0a3c1fccd9491c6b840dd0a80c8bf55bf7dae867e7577",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:08a3128dd4d6ac81a9f0a3c1fccd9491c6b840dd0a80c8bf55bf7dae867e7577",
          "name": "cloud-native-postgresql-08a3128dd4d6ac81a9f0a3c1fccd9491c6b840dd0a80c8bf55bf7dae867e7577-annotation"
        },
        {
          "digest": "sha256:08a3128dd4d6ac81a9f0a3c1fccd9491c6b840dd0a80c8bf55bf7dae867e7577",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:08a3128dd4d6ac81a9f0a3c1fccd9491c6b840dd0a80c8bf55bf7dae867e7577",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": ">=1.15.3 < 1.16.4",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.16.4",
      "version_original": "1.16.4"
    },
    {
      "_id": "6376940dd54d96b9ae5f0cd3",
      "alm_examples": [
        {
          "api_version": "apps.gitlab.com/v1beta2",
          "kind": "Runner",
          "metadata": {
            "name": "example"
          },
          "spec": {
            "gitlabUrl": "https://gitlab.com",
            "imagePullPolicy": "Always",
            "tags": "openshift, test",
            "token": "gitlab-dev-runner-secret"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [
        "amd64",
        "ppc64le"
      ],
      "bundle_path": "registry.connect.redhat.com/gitlab/gitlab-runner-operator-bundle@sha256:99595cf7cdd3446b9d43c4cbcc602528c6ef58402151d4ca7e222383e283ae34",
      "bundle_path_digest": "sha256:99595cf7cdd3446b9d43c4cbcc602528c6ef58402151d4ca7e222383e283ae34",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-17T20:05:33.202000+00:00",
      "csv_description": "GitLab Runner is the lightweight, highly-scalable agent that runs your build jobs and sends the results back to a GitLab instance. GitLab Runner works in conjunction with GitLab CI/CD, the open-source continuous integration service included with GitLab.\n\nThe GitLab Runner operator manages the lifecycle of GitLab Runner in Kubernetes or Openshift clusters. The operator aims to automate the tasks needed to run your CI/CD jobs in your container orchestration platform.\n\n## Prerequisites\n\n  Install cert-manager:\n\n  ```shell\n  kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.7.1/cert-manager.yaml\n  ```\n\n## GitLab Runner version\n\nThis version of **GitLab Runner Operator** ships with **GitLab Runner v15.2.1**.\n\nTo use a different version of **GitLab Runner** change the [`runnerImage` and `helperImage` properties](https://docs.gitlab.com/runner/configuration/configuring_runner_operator.html#operator-properties).\n\n## Usage\n\n To link a GitLab Runner instance to a self-hosted GitLab instance or the hosted [GitLab](https://gitlab.com), you first need to:\n\n 1. Create a secret containing the `runner-registration-token` from your GitLab project.\n\n   ```\n  cat > gitlab-runner-secret.yml << EOF\n  apiVersion: v1\n  kind: Secret\n  metadata:\n    name: gitlab-runner-secret\n  type: Opaque\n  stringData:\n    runner-registration-token: REPLACE_ME # your project runner secret\n  EOF\n  ```\n\n  ```\n  oc apply -f gitlab-runner-secret.yml\n  ```\n\n 2. Create the Custom Resource Definition (CRD) file and include the following information. The tags value must be openshift for the job to run.\n\n   ```\n   cat > gitlab-runner.yml << EOF\n   apiVersion: apps.gitlab.com/v1beta2\n   kind: Runner\n   metadata:\n     name: gitlab-runner\n   spec:\n     gitlabUrl: https://gitlab.example.com\n     buildImage: alpine\n     token: gitlab-runner-secret\n     tags: openshift\n   EOF\n   ```\n\n  ```\n  oc apply -f gitlab-runner.yml\n  ```\n\n## Full documentation\n\nVisit [Install GitLab Runner Operator](https://docs.gitlab.com/runner/install/operator.html)\n",
      "csv_display_name": "GitLab Runner",
      "csv_metadata_description": "GitLab Runner operator manages lifecycle of GitLab Runner instances",
      "csv_name": "gitlab-runner-operator.v1.10.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T08:28:27.592000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "gitlab-runner-operator",
      "provided_apis": [
        {
          "group": "apps.gitlab.com",
          "kind": "Runner",
          "plural": "runners",
          "version": "v1beta2"
        }
      ],
      "provider": "GitLab, Inc.",
      "related_images": [
        {
          "digest": "sha256:93c7be4cf43263334824dcd1030ed61bf8c06a095e245b8aeaa5444453fdd613",
          "image": "registry.gitlab.com/gitlab-org/ci-cd/gitlab-runner-ubi-images/gitlab-runner-ocp@sha256:93c7be4cf43263334824dcd1030ed61bf8c06a095e245b8aeaa5444453fdd613",
          "name": "gitlab-runner"
        },
        {
          "digest": "sha256:cb796e3c768c8504c1b93c10b29dcf03b698c716e3f5764996dd46597dadcfc8",
          "image": "registry.gitlab.com/gitlab-org/ci-cd/gitlab-runner-ubi-images/gitlab-runner-helper-ocp@sha256:cb796e3c768c8504c1b93c10b29dcf03b698c716e3f5764996dd46597dadcfc8",
          "name": "gitlab-runner-helper"
        },
        {
          "digest": "sha256:337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80",
          "name": "gitlab-runner-operator"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80",
          "name": "gl-openshift/gitlab-runner-operator/gitlab-runner-operator-337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80-annotation"
        },
        {
          "digest": "sha256:337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.10.1",
      "version_original": "1.10.1"
    },
    {
      "_id": "63769503bd954e28072007f3",
      "alm_examples": [
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Backup",
          "metadata": {
            "name": "backup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Cluster",
          "metadata": {
            "name": "cluster-sample"
          },
          "spec": {
            "instances": 3,
            "logLevel": "info",
            "primaryUpdateStrategy": "unsupervised",
            "storage": {
              "size": "1Gi"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Pooler",
          "metadata": {
            "name": "pooler-sample-rw"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "instances": 1,
            "pgbouncer": {
              "poolMode": "session"
            },
            "type": "rw"
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "ScheduledBackup",
          "metadata": {
            "name": "scheduledbackup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "schedule": "0 0 0 * * *"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [
        "amd64",
        "ppc64le",
        "s390x"
      ],
      "bundle_path": "registry.connect.redhat.com/enterprisedb/cloud-native-postgresql@sha256:c36c85656588ce1c5872a29e43a956e4abdf6dacedeec9c28bada5503afc579d",
      "bundle_path_digest": "sha256:c36c85656588ce1c5872a29e43a956e4abdf6dacedeec9c28bada5503afc579d",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable-v1.16",
      "creation_date": "2022-11-17T20:09:39.588000+00:00",
      "csv_description": "EDB Postgres for Kubernetes is an operator designed, developed, and supported by EDB that covers the full \nlifecycle of a highly available Postgres database clusters with a primary/standby architecture, using native\nstreaming replication. It is based on the open source CloudNativePG operator, and provides additional value\nsuch as compatibility with Oracle using EDB Postgres Advanced Server and additional supported platforms such\nas IBM Power and OpenShift.\n\nKey features available include:\n\n* Kubernetes API integration for high availability\n* Self-healing through failover and automated recreation of replicas\n* Capacity management with scale up/down capabilities\n* Planned switchovers for scheduled maintenance\n* Read-only and read-write Kubernetes services definitions\n* Rolling updates for Postgres minor versions and operator upgrades\n* Continuous backup and point-in-time recovery\n* Connection Pooling with PgBouncer\n* Integrated metrics exporter out of the box\n* PostgreSQL replication across multiple Kubernetes clusters\n* Red Hat certified operator for OpenShift\n\nThe operator has been renamed from Cloud Native PostgreSQL. Existing users of Cloud Native PostgreSQL will not\nexperience any change, as the underlying components and resources have not changed.\n",
      "csv_display_name": "EDB Postgres for Kubernetes",
      "csv_metadata_description": "Operator to manage Postgres high availability clusters with a primary/standby architecture.",
      "csv_name": "cloud-native-postgresql.v1.16.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T07:07:50.477000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "cloud-native-postgresql",
      "provided_apis": [
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Backup",
          "plural": "backups",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Cluster",
          "plural": "clusters",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Pooler",
          "plural": "poolers",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "ScheduledBackup",
          "plural": "scheduledbackups",
          "version": "v1"
        }
      ],
      "provider": "EnterpriseDB Corporation",
      "related_images": [
        {
          "digest": "sha256:08a3128dd4d6ac81a9f0a3c1fccd9491c6b840dd0a80c8bf55bf7dae867e7577",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:08a3128dd4d6ac81a9f0a3c1fccd9491c6b840dd0a80c8bf55bf7dae867e7577",
          "name": "cloud-native-postgresql-08a3128dd4d6ac81a9f0a3c1fccd9491c6b840dd0a80c8bf55bf7dae867e7577-annotation"
        },
        {
          "digest": "sha256:08a3128dd4d6ac81a9f0a3c1fccd9491c6b840dd0a80c8bf55bf7dae867e7577",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:08a3128dd4d6ac81a9f0a3c1fccd9491c6b840dd0a80c8bf55bf7dae867e7577",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": ">=1.15.3 < 1.16.4",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.16.4",
      "version_original": "1.16.4"
    },
    {
      "_id": "63769504bd954e28072007f5",
      "alm_examples": [
        {
          "api_version": "apps.gitlab.com/v1beta2",
          "kind": "Runner",
          "metadata": {
            "name": "example"
          },
          "spec": {
            "gitlabUrl": "https://gitlab.com",
            "imagePullPolicy": "Always",
            "tags": "openshift, test",
            "token": "gitlab-dev-runner-secret"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [
        "amd64",
        "ppc64le"
      ],
      "bundle_path": "registry.connect.redhat.com/gitlab/gitlab-runner-operator-bundle@sha256:99595cf7cdd3446b9d43c4cbcc602528c6ef58402151d4ca7e222383e283ae34",
      "bundle_path_digest": "sha256:99595cf7cdd3446b9d43c4cbcc602528c6ef58402151d4ca7e222383e283ae34",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-17T20:09:40.079000+00:00",
      "csv_description": "GitLab Runner is the lightweight, highly-scalable agent that runs your build jobs and sends the results back to a GitLab instance. GitLab Runner works in conjunction with GitLab CI/CD, the open-source continuous integration service included with GitLab.\n\nThe GitLab Runner operator manages the lifecycle of GitLab Runner in Kubernetes or Openshift clusters. The operator aims to automate the tasks needed to run your CI/CD jobs in your container orchestration platform.\n\n## Prerequisites\n\n  Install cert-manager:\n\n  ```shell\n  kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.7.1/cert-manager.yaml\n  ```\n\n## GitLab Runner version\n\nThis version of **GitLab Runner Operator** ships with **GitLab Runner v15.2.1**.\n\nTo use a different version of **GitLab Runner** change the [`runnerImage` and `helperImage` properties](https://docs.gitlab.com/runner/configuration/configuring_runner_operator.html#operator-properties).\n\n## Usage\n\n To link a GitLab Runner instance to a self-hosted GitLab instance or the hosted [GitLab](https://gitlab.com), you first need to:\n\n 1. Create a secret containing the `runner-registration-token` from your GitLab project.\n\n   ```\n  cat > gitlab-runner-secret.yml << EOF\n  apiVersion: v1\n  kind: Secret\n  metadata:\n    name: gitlab-runner-secret\n  type: Opaque\n  stringData:\n    runner-registration-token: REPLACE_ME # your project runner secret\n  EOF\n  ```\n\n  ```\n  oc apply -f gitlab-runner-secret.yml\n  ```\n\n 2. Create the Custom Resource Definition (CRD) file and include the following information. The tags value must be openshift for the job to run.\n\n   ```\n   cat > gitlab-runner.yml << EOF\n   apiVersion: apps.gitlab.com/v1beta2\n   kind: Runner\n   metadata:\n     name: gitlab-runner\n   spec:\n     gitlabUrl: https://gitlab.example.com\n     buildImage: alpine\n     token: gitlab-runner-secret\n     tags: openshift\n   EOF\n   ```\n\n  ```\n  oc apply -f gitlab-runner.yml\n  ```\n\n## Full documentation\n\nVisit [Install GitLab Runner Operator](https://docs.gitlab.com/runner/install/operator.html)\n",
      "csv_display_name": "GitLab Runner",
      "csv_metadata_description": "GitLab Runner operator manages lifecycle of GitLab Runner instances",
      "csv_name": "gitlab-runner-operator.v1.10.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:12:55.609000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "gitlab-runner-operator",
      "provided_apis": [
        {
          "group": "apps.gitlab.com",
          "kind": "Runner",
          "plural": "runners",
          "version": "v1beta2"
        }
      ],
      "provider": "GitLab, Inc.",
      "related_images": [
        {
          "digest": "sha256:93c7be4cf43263334824dcd1030ed61bf8c06a095e245b8aeaa5444453fdd613",
          "image": "registry.gitlab.com/gitlab-org/ci-cd/gitlab-runner-ubi-images/gitlab-runner-ocp@sha256:93c7be4cf43263334824dcd1030ed61bf8c06a095e245b8aeaa5444453fdd613",
          "name": "gitlab-runner"
        },
        {
          "digest": "sha256:cb796e3c768c8504c1b93c10b29dcf03b698c716e3f5764996dd46597dadcfc8",
          "image": "registry.gitlab.com/gitlab-org/ci-cd/gitlab-runner-ubi-images/gitlab-runner-helper-ocp@sha256:cb796e3c768c8504c1b93c10b29dcf03b698c716e3f5764996dd46597dadcfc8",
          "name": "gitlab-runner-helper"
        },
        {
          "digest": "sha256:337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80",
          "name": "gitlab-runner-operator"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80",
          "name": "gl-openshift/gitlab-runner-operator/gitlab-runner-operator-337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80-annotation"
        },
        {
          "digest": "sha256:337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.10.1",
      "version_original": "1.10.1"
    },
    {
      "_id": "637696085e3261eca76c9639",
      "alm_examples": [
        {
          "api_version": "apps.gitlab.com/v1beta2",
          "kind": "Runner",
          "metadata": {
            "name": "example"
          },
          "spec": {
            "gitlabUrl": "https://gitlab.com",
            "imagePullPolicy": "Always",
            "tags": "openshift, test",
            "token": "gitlab-dev-runner-secret"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [
        "amd64",
        "ppc64le"
      ],
      "bundle_path": "registry.connect.redhat.com/gitlab/gitlab-runner-operator-bundle@sha256:99595cf7cdd3446b9d43c4cbcc602528c6ef58402151d4ca7e222383e283ae34",
      "bundle_path_digest": "sha256:99595cf7cdd3446b9d43c4cbcc602528c6ef58402151d4ca7e222383e283ae34",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-17T20:14:00.511000+00:00",
      "csv_description": "GitLab Runner is the lightweight, highly-scalable agent that runs your build jobs and sends the results back to a GitLab instance. GitLab Runner works in conjunction with GitLab CI/CD, the open-source continuous integration service included with GitLab.\n\nThe GitLab Runner operator manages the lifecycle of GitLab Runner in Kubernetes or Openshift clusters. The operator aims to automate the tasks needed to run your CI/CD jobs in your container orchestration platform.\n\n## Prerequisites\n\n  Install cert-manager:\n\n  ```shell\n  kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.7.1/cert-manager.yaml\n  ```\n\n## GitLab Runner version\n\nThis version of **GitLab Runner Operator** ships with **GitLab Runner v15.2.1**.\n\nTo use a different version of **GitLab Runner** change the [`runnerImage` and `helperImage` properties](https://docs.gitlab.com/runner/configuration/configuring_runner_operator.html#operator-properties).\n\n## Usage\n\n To link a GitLab Runner instance to a self-hosted GitLab instance or the hosted [GitLab](https://gitlab.com), you first need to:\n\n 1. Create a secret containing the `runner-registration-token` from your GitLab project.\n\n   ```\n  cat > gitlab-runner-secret.yml << EOF\n  apiVersion: v1\n  kind: Secret\n  metadata:\n    name: gitlab-runner-secret\n  type: Opaque\n  stringData:\n    runner-registration-token: REPLACE_ME # your project runner secret\n  EOF\n  ```\n\n  ```\n  oc apply -f gitlab-runner-secret.yml\n  ```\n\n 2. Create the Custom Resource Definition (CRD) file and include the following information. The tags value must be openshift for the job to run.\n\n   ```\n   cat > gitlab-runner.yml << EOF\n   apiVersion: apps.gitlab.com/v1beta2\n   kind: Runner\n   metadata:\n     name: gitlab-runner\n   spec:\n     gitlabUrl: https://gitlab.example.com\n     buildImage: alpine\n     token: gitlab-runner-secret\n     tags: openshift\n   EOF\n   ```\n\n  ```\n  oc apply -f gitlab-runner.yml\n  ```\n\n## Full documentation\n\nVisit [Install GitLab Runner Operator](https://docs.gitlab.com/runner/install/operator.html)\n",
      "csv_display_name": "GitLab Runner",
      "csv_metadata_description": "GitLab Runner operator manages lifecycle of GitLab Runner instances",
      "csv_name": "gitlab-runner-operator.v1.10.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:40:44.836000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "gitlab-runner-operator",
      "provided_apis": [
        {
          "group": "apps.gitlab.com",
          "kind": "Runner",
          "plural": "runners",
          "version": "v1beta2"
        }
      ],
      "provider": "GitLab, Inc.",
      "related_images": [
        {
          "digest": "sha256:93c7be4cf43263334824dcd1030ed61bf8c06a095e245b8aeaa5444453fdd613",
          "image": "registry.gitlab.com/gitlab-org/ci-cd/gitlab-runner-ubi-images/gitlab-runner-ocp@sha256:93c7be4cf43263334824dcd1030ed61bf8c06a095e245b8aeaa5444453fdd613",
          "name": "gitlab-runner"
        },
        {
          "digest": "sha256:cb796e3c768c8504c1b93c10b29dcf03b698c716e3f5764996dd46597dadcfc8",
          "image": "registry.gitlab.com/gitlab-org/ci-cd/gitlab-runner-ubi-images/gitlab-runner-helper-ocp@sha256:cb796e3c768c8504c1b93c10b29dcf03b698c716e3f5764996dd46597dadcfc8",
          "name": "gitlab-runner-helper"
        },
        {
          "digest": "sha256:337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80",
          "name": "gitlab-runner-operator"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80",
          "name": "gl-openshift/gitlab-runner-operator/gitlab-runner-operator-337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80-annotation"
        },
        {
          "digest": "sha256:337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:337beb61817b051d1814b67a13223f72c34430f385dd8f91dcdf0f4867a30b80",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.10.1",
      "version_original": "1.10.1"
    },
    {
      "_id": "6376a023799f60c30159be32",
      "alm_examples": [
        {
          "api_version": "anzograph.clusters.cambridgesemantics.com/v2",
          "kind": "AnzoGraph",
          "metadata": {
            "name": "azg01"
          },
          "spec": {
            "db": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app_data": "anzograph-data-grpc",
                      "app_mgmt": "anzograph-mgmt-grpc"
                    }
                  },
                  "serviceName": "anzograph-azg01",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app_data": "anzograph-data-grpc",
                        "app_mgmt": "anzograph-mgmt-grpc"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
                          "name": "db",
                          "resources": {
                            "limits": {
                              "cpu": "8000m",
                              "memory": "8Gi"
                            },
                            "requests": {
                              "cpu": "8000m",
                              "memory": "8Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "anzograph-operator"
                    }
                  }
                }
              }
            },
            "deployFrontend": false,
            "frontend": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app_mgmt": "anzograph-frontend"
                    }
                  },
                  "serviceName": "anzograph-azg01",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app_mgmt": "anzograph-frontend"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
                          "name": "frontend",
                          "resources": {
                            "limits": {
                              "cpu": "2000m",
                              "memory": "4Gi"
                            },
                            "requests": {
                              "cpu": "2000m",
                              "memory": "4Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "anzograph-operator"
                    }
                  }
                }
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cambridgesemantics/anzograph-operator-bundle@sha256:113621bab4db52f1a8379a8e704eed0b8b0efb65a42748a1adbf38ebcf1b0712",
      "bundle_path_digest": "sha256:113621bab4db52f1a8379a8e704eed0b8b0efb65a42748a1adbf38ebcf1b0712",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-17T20:57:07.312000+00:00",
      "csv_description": "The AnzoGraph Operator provides the way to install and configure an AnzoGraph\ncluster on Red Hat K8S environment.\n\n### Installation\n Refer [installation instructions]( https://github.com/cambridgesemantics/csi-k8s-operator-anzograph/blob/v2.0.2/README_openshift_marketplace.md )\n\n### Documentation\n\nYou can find our documentation [here.]( https://docs.cambridgesemantics.com/anzograph/userdoc/ )\n\n### Support\n\nWe offer Support to our customers with the AnzoGraph db Enterprise Edition License [here]( https://customercenter.cambridgesemantics.com/ ). For AnzoGraph db Free Edition questions, get help from our Anzograph User Community at Stack Overflow. When submitting a question, include the tag 'anzograph'.",
      "csv_display_name": "AnzoGraph Operator",
      "csv_metadata_description": "kubernetes operator for AnzoGraph DB",
      "csv_name": "anzograph-operator.v2.0.203",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:11:03.124000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "anzograph-operator",
      "provided_apis": [
        {
          "group": "anzograph.clusters.cambridgesemantics.com",
          "kind": "AnzoGraph",
          "version": "v2"
        }
      ],
      "provider": "Cambridge Semantics Inc.",
      "related_images": [
        {
          "digest": "sha256:1c0356e592e45386abf468443dbcede51789fa5ac06dc95278acd9ef6e671731",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph@sha256:1c0356e592e45386abf468443dbcede51789fa5ac06dc95278acd9ef6e671731",
          "name": "anzograph-allinone"
        },
        {
          "digest": "sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "name": "anzograph-db"
        },
        {
          "digest": "sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "name": "anzograph-frontend"
        },
        {
          "digest": "sha256:02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-operator@sha256:02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86",
          "name": "anzograph-operator-02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86-annotation"
        },
        {
          "digest": "sha256:02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-operator@sha256:02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86",
          "name": "manager"
        },
        {
          "digest": "sha256:1c0356e592e45386abf468443dbcede51789fa5ac06dc95278acd9ef6e671731",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph@sha256:1c0356e592e45386abf468443dbcede51789fa5ac06dc95278acd9ef6e671731",
          "name": "anzograph_allinone"
        },
        {
          "digest": "sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "name": "anzograph_db"
        },
        {
          "digest": "sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "name": "anzograph_frontend"
        },
        {
          "digest": "sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "name": "anzograph-frontend-9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e-annotation"
        },
        {
          "digest": "sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "name": "anzograph-db-80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2.0.203",
      "version_original": "2.0.203"
    },
    {
      "_id": "6376a1f239c5577889446ab5",
      "alm_examples": [
        {
          "api_version": "anzograph.clusters.cambridgesemantics.com/v2",
          "kind": "AnzoGraph",
          "metadata": {
            "name": "azg01"
          },
          "spec": {
            "db": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app_data": "anzograph-data-grpc",
                      "app_mgmt": "anzograph-mgmt-grpc"
                    }
                  },
                  "serviceName": "anzograph-azg01",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app_data": "anzograph-data-grpc",
                        "app_mgmt": "anzograph-mgmt-grpc"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
                          "name": "db",
                          "resources": {
                            "limits": {
                              "cpu": "8000m",
                              "memory": "8Gi"
                            },
                            "requests": {
                              "cpu": "8000m",
                              "memory": "8Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "anzograph-operator"
                    }
                  }
                }
              }
            },
            "deployFrontend": false,
            "frontend": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app_mgmt": "anzograph-frontend"
                    }
                  },
                  "serviceName": "anzograph-azg01",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app_mgmt": "anzograph-frontend"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
                          "name": "frontend",
                          "resources": {
                            "limits": {
                              "cpu": "2000m",
                              "memory": "4Gi"
                            },
                            "requests": {
                              "cpu": "2000m",
                              "memory": "4Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "anzograph-operator"
                    }
                  }
                }
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cambridgesemantics/anzograph-operator-bundle@sha256:113621bab4db52f1a8379a8e704eed0b8b0efb65a42748a1adbf38ebcf1b0712",
      "bundle_path_digest": "sha256:113621bab4db52f1a8379a8e704eed0b8b0efb65a42748a1adbf38ebcf1b0712",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-17T21:04:50.094000+00:00",
      "csv_description": "The AnzoGraph Operator provides the way to install and configure an AnzoGraph\ncluster on Red Hat K8S environment.\n\n### Installation\n Refer [installation instructions]( https://github.com/cambridgesemantics/csi-k8s-operator-anzograph/blob/v2.0.2/README_openshift_marketplace.md )\n\n### Documentation\n\nYou can find our documentation [here.]( https://docs.cambridgesemantics.com/anzograph/userdoc/ )\n\n### Support\n\nWe offer Support to our customers with the AnzoGraph db Enterprise Edition License [here]( https://customercenter.cambridgesemantics.com/ ). For AnzoGraph db Free Edition questions, get help from our Anzograph User Community at Stack Overflow. When submitting a question, include the tag 'anzograph'.",
      "csv_display_name": "AnzoGraph Operator",
      "csv_metadata_description": "kubernetes operator for AnzoGraph DB",
      "csv_name": "anzograph-operator.v2.0.203",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:45:13.854000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "anzograph-operator",
      "provided_apis": [
        {
          "group": "anzograph.clusters.cambridgesemantics.com",
          "kind": "AnzoGraph",
          "plural": "anzographs",
          "version": "v2"
        }
      ],
      "provider": "Cambridge Semantics Inc.",
      "related_images": [
        {
          "digest": "sha256:1c0356e592e45386abf468443dbcede51789fa5ac06dc95278acd9ef6e671731",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph@sha256:1c0356e592e45386abf468443dbcede51789fa5ac06dc95278acd9ef6e671731",
          "name": "anzograph-allinone"
        },
        {
          "digest": "sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "name": "anzograph-db"
        },
        {
          "digest": "sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "name": "anzograph-frontend"
        },
        {
          "digest": "sha256:02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-operator@sha256:02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86",
          "name": "anzograph-operator-02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86-annotation"
        },
        {
          "digest": "sha256:02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-operator@sha256:02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86",
          "name": "manager"
        },
        {
          "digest": "sha256:1c0356e592e45386abf468443dbcede51789fa5ac06dc95278acd9ef6e671731",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph@sha256:1c0356e592e45386abf468443dbcede51789fa5ac06dc95278acd9ef6e671731",
          "name": "anzograph_allinone"
        },
        {
          "digest": "sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "name": "anzograph_db"
        },
        {
          "digest": "sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "name": "anzograph_frontend"
        },
        {
          "digest": "sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "name": "anzograph-frontend-9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e-annotation"
        },
        {
          "digest": "sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "name": "anzograph-db-80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2.0.203",
      "version_original": "2.0.203"
    },
    {
      "_id": "6376a2095e3261eca76caa1b",
      "alm_examples": [
        {
          "api_version": "anzograph.clusters.cambridgesemantics.com/v2",
          "kind": "AnzoGraph",
          "metadata": {
            "name": "azg01"
          },
          "spec": {
            "db": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app_data": "anzograph-data-grpc",
                      "app_mgmt": "anzograph-mgmt-grpc"
                    }
                  },
                  "serviceName": "anzograph-azg01",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app_data": "anzograph-data-grpc",
                        "app_mgmt": "anzograph-mgmt-grpc"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
                          "name": "db",
                          "resources": {
                            "limits": {
                              "cpu": "8000m",
                              "memory": "8Gi"
                            },
                            "requests": {
                              "cpu": "8000m",
                              "memory": "8Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "anzograph-operator"
                    }
                  }
                }
              }
            },
            "deployFrontend": false,
            "frontend": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app_mgmt": "anzograph-frontend"
                    }
                  },
                  "serviceName": "anzograph-azg01",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app_mgmt": "anzograph-frontend"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
                          "name": "frontend",
                          "resources": {
                            "limits": {
                              "cpu": "2000m",
                              "memory": "4Gi"
                            },
                            "requests": {
                              "cpu": "2000m",
                              "memory": "4Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "anzograph-operator"
                    }
                  }
                }
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cambridgesemantics/anzograph-operator-bundle@sha256:113621bab4db52f1a8379a8e704eed0b8b0efb65a42748a1adbf38ebcf1b0712",
      "bundle_path_digest": "sha256:113621bab4db52f1a8379a8e704eed0b8b0efb65a42748a1adbf38ebcf1b0712",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-17T21:05:13.830000+00:00",
      "csv_description": "The AnzoGraph Operator provides the way to install and configure an AnzoGraph\ncluster on Red Hat K8S environment.\n\n### Installation\n Refer [installation instructions]( https://github.com/cambridgesemantics/csi-k8s-operator-anzograph/blob/v2.0.2/README_openshift_marketplace.md )\n\n### Documentation\n\nYou can find our documentation [here.]( https://docs.cambridgesemantics.com/anzograph/userdoc/ )\n\n### Support\n\nWe offer Support to our customers with the AnzoGraph db Enterprise Edition License [here]( https://customercenter.cambridgesemantics.com/ ). For AnzoGraph db Free Edition questions, get help from our Anzograph User Community at Stack Overflow. When submitting a question, include the tag 'anzograph'.",
      "csv_display_name": "AnzoGraph Operator",
      "csv_metadata_description": "kubernetes operator for AnzoGraph DB",
      "csv_name": "anzograph-operator.v2.0.203",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T08:19:11.199000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "anzograph-operator",
      "provided_apis": [
        {
          "group": "anzograph.clusters.cambridgesemantics.com",
          "kind": "AnzoGraph",
          "plural": "anzographs",
          "version": "v2"
        }
      ],
      "provider": "Cambridge Semantics Inc.",
      "related_images": [
        {
          "digest": "sha256:1c0356e592e45386abf468443dbcede51789fa5ac06dc95278acd9ef6e671731",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph@sha256:1c0356e592e45386abf468443dbcede51789fa5ac06dc95278acd9ef6e671731",
          "name": "anzograph-allinone"
        },
        {
          "digest": "sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "name": "anzograph-db"
        },
        {
          "digest": "sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "name": "anzograph-frontend"
        },
        {
          "digest": "sha256:02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-operator@sha256:02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86",
          "name": "anzograph-operator-02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86-annotation"
        },
        {
          "digest": "sha256:02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-operator@sha256:02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86",
          "name": "manager"
        },
        {
          "digest": "sha256:1c0356e592e45386abf468443dbcede51789fa5ac06dc95278acd9ef6e671731",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph@sha256:1c0356e592e45386abf468443dbcede51789fa5ac06dc95278acd9ef6e671731",
          "name": "anzograph_allinone"
        },
        {
          "digest": "sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "name": "anzograph_db"
        },
        {
          "digest": "sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "name": "anzograph_frontend"
        },
        {
          "digest": "sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "name": "anzograph-frontend-9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e-annotation"
        },
        {
          "digest": "sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "name": "anzograph-db-80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "2.0.203",
      "version_original": "2.0.203"
    },
    {
      "_id": "6376a30dd54d96b9ae5f25de",
      "alm_examples": [
        {
          "api_version": "anzograph.clusters.cambridgesemantics.com/v2",
          "kind": "AnzoGraph",
          "metadata": {
            "name": "azg01"
          },
          "spec": {
            "db": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app_data": "anzograph-data-grpc",
                      "app_mgmt": "anzograph-mgmt-grpc"
                    }
                  },
                  "serviceName": "anzograph-azg01",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app_data": "anzograph-data-grpc",
                        "app_mgmt": "anzograph-mgmt-grpc"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
                          "name": "db",
                          "resources": {
                            "limits": {
                              "cpu": "8000m",
                              "memory": "8Gi"
                            },
                            "requests": {
                              "cpu": "8000m",
                              "memory": "8Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "anzograph-operator"
                    }
                  }
                }
              }
            },
            "deployFrontend": false,
            "frontend": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app_mgmt": "anzograph-frontend"
                    }
                  },
                  "serviceName": "anzograph-azg01",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app_mgmt": "anzograph-frontend"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
                          "name": "frontend",
                          "resources": {
                            "limits": {
                              "cpu": "2000m",
                              "memory": "4Gi"
                            },
                            "requests": {
                              "cpu": "2000m",
                              "memory": "4Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "anzograph-operator"
                    }
                  }
                }
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cambridgesemantics/anzograph-operator-bundle@sha256:113621bab4db52f1a8379a8e704eed0b8b0efb65a42748a1adbf38ebcf1b0712",
      "bundle_path_digest": "sha256:113621bab4db52f1a8379a8e704eed0b8b0efb65a42748a1adbf38ebcf1b0712",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-17T21:09:33.251000+00:00",
      "csv_description": "The AnzoGraph Operator provides the way to install and configure an AnzoGraph\ncluster on Red Hat K8S environment.\n\n### Installation\n Refer [installation instructions]( https://github.com/cambridgesemantics/csi-k8s-operator-anzograph/blob/v2.0.2/README_openshift_marketplace.md )\n\n### Documentation\n\nYou can find our documentation [here.]( https://docs.cambridgesemantics.com/anzograph/userdoc/ )\n\n### Support\n\nWe offer Support to our customers with the AnzoGraph db Enterprise Edition License [here]( https://customercenter.cambridgesemantics.com/ ). For AnzoGraph db Free Edition questions, get help from our Anzograph User Community at Stack Overflow. When submitting a question, include the tag 'anzograph'.",
      "csv_display_name": "AnzoGraph Operator",
      "csv_metadata_description": "kubernetes operator for AnzoGraph DB",
      "csv_name": "anzograph-operator.v2.0.203",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T08:37:44.659000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "anzograph-operator",
      "provided_apis": [
        {
          "group": "anzograph.clusters.cambridgesemantics.com",
          "kind": "AnzoGraph",
          "version": "v2"
        }
      ],
      "provider": "Cambridge Semantics Inc.",
      "related_images": [
        {
          "digest": "sha256:1c0356e592e45386abf468443dbcede51789fa5ac06dc95278acd9ef6e671731",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph@sha256:1c0356e592e45386abf468443dbcede51789fa5ac06dc95278acd9ef6e671731",
          "name": "anzograph-allinone"
        },
        {
          "digest": "sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "name": "anzograph-db"
        },
        {
          "digest": "sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "name": "anzograph-frontend"
        },
        {
          "digest": "sha256:02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-operator@sha256:02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86",
          "name": "anzograph-operator-02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86-annotation"
        },
        {
          "digest": "sha256:02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-operator@sha256:02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86",
          "name": "manager"
        },
        {
          "digest": "sha256:1c0356e592e45386abf468443dbcede51789fa5ac06dc95278acd9ef6e671731",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph@sha256:1c0356e592e45386abf468443dbcede51789fa5ac06dc95278acd9ef6e671731",
          "name": "anzograph_allinone"
        },
        {
          "digest": "sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "name": "anzograph_db"
        },
        {
          "digest": "sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "name": "anzograph_frontend"
        },
        {
          "digest": "sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "name": "anzograph-frontend-9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e-annotation"
        },
        {
          "digest": "sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "name": "anzograph-db-80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "2.0.203",
      "version_original": "2.0.203"
    },
    {
      "_id": "6376a320bd954e2807201f31",
      "alm_examples": [
        {
          "api_version": "anzograph.clusters.cambridgesemantics.com/v2",
          "kind": "AnzoGraph",
          "metadata": {
            "name": "azg01"
          },
          "spec": {
            "db": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app_data": "anzograph-data-grpc",
                      "app_mgmt": "anzograph-mgmt-grpc"
                    }
                  },
                  "serviceName": "anzograph-azg01",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app_data": "anzograph-data-grpc",
                        "app_mgmt": "anzograph-mgmt-grpc"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
                          "name": "db",
                          "resources": {
                            "limits": {
                              "cpu": "8000m",
                              "memory": "8Gi"
                            },
                            "requests": {
                              "cpu": "8000m",
                              "memory": "8Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "anzograph-operator"
                    }
                  }
                }
              }
            },
            "deployFrontend": false,
            "frontend": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app_mgmt": "anzograph-frontend"
                    }
                  },
                  "serviceName": "anzograph-azg01",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app_mgmt": "anzograph-frontend"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
                          "name": "frontend",
                          "resources": {
                            "limits": {
                              "cpu": "2000m",
                              "memory": "4Gi"
                            },
                            "requests": {
                              "cpu": "2000m",
                              "memory": "4Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "anzograph-operator"
                    }
                  }
                }
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cambridgesemantics/anzograph-operator-bundle@sha256:113621bab4db52f1a8379a8e704eed0b8b0efb65a42748a1adbf38ebcf1b0712",
      "bundle_path_digest": "sha256:113621bab4db52f1a8379a8e704eed0b8b0efb65a42748a1adbf38ebcf1b0712",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-17T21:09:52.184000+00:00",
      "csv_description": "The AnzoGraph Operator provides the way to install and configure an AnzoGraph\ncluster on Red Hat K8S environment.\n\n### Installation\n Refer [installation instructions]( https://github.com/cambridgesemantics/csi-k8s-operator-anzograph/blob/v2.0.2/README_openshift_marketplace.md )\n\n### Documentation\n\nYou can find our documentation [here.]( https://docs.cambridgesemantics.com/anzograph/userdoc/ )\n\n### Support\n\nWe offer Support to our customers with the AnzoGraph db Enterprise Edition License [here]( https://customercenter.cambridgesemantics.com/ ). For AnzoGraph db Free Edition questions, get help from our Anzograph User Community at Stack Overflow. When submitting a question, include the tag 'anzograph'.",
      "csv_display_name": "AnzoGraph Operator",
      "csv_metadata_description": "kubernetes operator for AnzoGraph DB",
      "csv_name": "anzograph-operator.v2.0.203",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:03:23.071000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "anzograph-operator",
      "provided_apis": [
        {
          "group": "anzograph.clusters.cambridgesemantics.com",
          "kind": "AnzoGraph",
          "plural": "anzographs",
          "version": "v2"
        }
      ],
      "provider": "Cambridge Semantics Inc.",
      "related_images": [
        {
          "digest": "sha256:1c0356e592e45386abf468443dbcede51789fa5ac06dc95278acd9ef6e671731",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph@sha256:1c0356e592e45386abf468443dbcede51789fa5ac06dc95278acd9ef6e671731",
          "name": "anzograph-allinone"
        },
        {
          "digest": "sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "name": "anzograph-db"
        },
        {
          "digest": "sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "name": "anzograph-frontend"
        },
        {
          "digest": "sha256:02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-operator@sha256:02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86",
          "name": "anzograph-operator-02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86-annotation"
        },
        {
          "digest": "sha256:02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-operator@sha256:02b6b63e96f4b37ac13e5a608d3cb1e36efff4e007ed7fcaa71091e2bd8f5c86",
          "name": "manager"
        },
        {
          "digest": "sha256:1c0356e592e45386abf468443dbcede51789fa5ac06dc95278acd9ef6e671731",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph@sha256:1c0356e592e45386abf468443dbcede51789fa5ac06dc95278acd9ef6e671731",
          "name": "anzograph_allinone"
        },
        {
          "digest": "sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "name": "anzograph_db"
        },
        {
          "digest": "sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "name": "anzograph_frontend"
        },
        {
          "digest": "sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e",
          "name": "anzograph-frontend-9bed178919e0f8275c4b6bb426a3c5026ad3fefdc885a4fbe5d4f24439a2269e-annotation"
        },
        {
          "digest": "sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7",
          "name": "anzograph-db-80fabf02d68f36c0bc465ffa72c259d272830e9924fd24576472060ae8d67ce7-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2.0.203",
      "version_original": "2.0.203"
    },
    {
      "_id": "6376aae09dc40044c5f6154c",
      "alm_examples": [
        {
          "api_version": "mellanox.com/v1alpha1",
          "kind": "HostDeviceNetwork",
          "metadata": {
            "name": "example-hostdevice-network"
          },
          "spec": {
            "ipam": "{\n  \"type\": \"whereabouts\",\n  \"range\": \"192.168.3.225/28\",\n  \"exclude\": [\n   \"192.168.3.229/30\",\n   \"192.168.3.236/32\"\n  ]\n}\n",
            "networkNamespace": "default",
            "resourceName": "hostdev"
          }
        },
        {
          "api_version": "mellanox.com/v1alpha1",
          "kind": "IPoIBNetwork",
          "metadata": {
            "name": "example-ipoibnetwork"
          },
          "spec": {
            "ipam": "{\n  \"type\": \"whereabouts\",\n  \"range\": \"192.168.6.225/28\",\n  \"exclude\": [\n   \"192.168.6.229/30\",\n   \"192.168.6.236/32\"\n  ]\n}\n",
            "master": "ibs3f1",
            "networkNamespace": "default"
          }
        },
        {
          "api_version": "mellanox.com/v1alpha1",
          "kind": "MacvlanNetwork",
          "metadata": {
            "name": "example-macvlannetwork"
          },
          "spec": {
            "ipam": "{\n  \"type\": \"whereabouts\",\n  \"range\": \"192.168.2.225/24\",\n  \"exclude\": [\n   \"192.168.2.229/30\",\n   \"192.168.2.236/32\"\n  ]\n}\n",
            "master": "ens2f0",
            "mode": "bridge",
            "mtu": 1500,
            "networkNamespace": "default"
          }
        },
        {
          "api_version": "mellanox.com/v1alpha1",
          "kind": "NicClusterPolicy",
          "metadata": {
            "name": "nic-cluster-policy"
          },
          "spec": {
            "ofedDriver": {
              "image": "mofed",
              "livenessProbe": {
                "initialDelaySeconds": 30,
                "periodSeconds": 30
              },
              "readinessProbe": {
                "initialDelaySeconds": 10,
                "periodSeconds": 30
              },
              "repository": "nvcr.io/nvidia/mellanox",
              "startupProbe": {
                "initialDelaySeconds": 10,
                "periodSeconds": 20
              },
              "upgradePolicy": {
                "autoUpgrade": false,
                "drain": {
                  "deleteEmptyDir": true,
                  "enable": true,
                  "force": true,
                  "podSelector": "",
                  "timeoutSeconds": 300
                },
                "maxParallelUpgrades": 1
              },
              "version": "5.8-1.0.1.1.2"
            },
            "rdmaSharedDevicePlugin": {
              "config": "{\n  \"configList\": [\n    {\n      \"resourceName\": \"rdma_shared_device_a\",\n      \"rdmaHcaMax\": 1000,\n      \"selectors\": {\n        \"ifNames\": [\"ens2f0\"]\n      }\n    }\n  ]\n}\n",
              "image": "k8s-rdma-shared-dev-plugin",
              "repository": "nvcr.io/nvidia/cloud-native",
              "version": "v1.3.2"
            },
            "sriovDevicePlugin": {
              "config": "{\n  \"resourceList\": [\n      {\n          \"resourcePrefix\": \"nvidia.com\",\n          \"resourceName\": \"hostdev\",\n          \"selectors\": {\n              \"vendors\": [\"15b3\"],\n              \"isRdma\": true\n          }\n      }\n  ]\n}\n",
              "image": "sriov-device-plugin",
              "repository": "ghcr.io/k8snetworkplumbingwg",
              "version": "v3.5.1"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/nvidia-network-operator/nvidia-network-operator@sha256:78b16fabf7a7fe7f85569ad111720daddac10e75cc61395f3b2feab9a94bb1c7",
      "bundle_path_digest": "sha256:78b16fabf7a7fe7f85569ad111720daddac10e75cc61395f3b2feab9a94bb1c7",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "v1.4.0",
      "creation_date": "2022-11-17T21:42:56.839000+00:00",
      "csv_description": "## NVIDIA Network Operator\nThe NVIDIA Network Operator simplifies the provisioning and management of NVIDIA networking resources  in a Kubernetes cluster. The operator automatically installs the required host networking software - bringing together all the needed components to provide high-speed network connectivity. These components include the NVIDIA networking driver, Kubernetes device plugin, CNI plugins, IP address management (IPAM) plugin and others.\nThe NVIDIA Network Operator works in conjunction with the NVIDIA GPU Operator to deliver high-throughput, low-latency networking for scale-out, GPU computing clusters.\n\nThe Network Operator uses Node Feature Discovery (NFD) labels in order to properly schedule resources.\nNodes can be labelled manually or using the NFD Operator. An example of `NodeFeatureDiscovery`\nconfiguration is available in the documentation.\nThe following NFD labels are used:\n`feature.node.kubernetes.io/pci-15b3.present` for nodes containing NVIDIA Networking hardware.\n`feature.node.kubernetes.io/pci-10de.present` for nodes containing NVIDIA GPU hardware.\n\nThe Network Operator is open-source. For more information on contributions and release artifacts, see the [GitHub repo](https://github.com/Mellanox/network-operator/)\n",
      "csv_display_name": "NVIDIA Network Operator",
      "csv_metadata_description": "Deploy and manage NVIDIA networking resources in Kubernetes",
      "csv_name": "nvidia-network-operator.v1.4.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:07:39.073000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "nvidia-network-operator",
      "provided_apis": [
        {
          "group": "mellanox.com",
          "kind": "HostDeviceNetwork",
          "version": "v1alpha1"
        },
        {
          "group": "mellanox.com",
          "kind": "IPoIBNetwork",
          "version": "v1alpha1"
        },
        {
          "group": "mellanox.com",
          "kind": "MacvlanNetwork",
          "version": "v1alpha1"
        },
        {
          "group": "mellanox.com",
          "kind": "NicClusterPolicy",
          "version": "v1alpha1"
        }
      ],
      "provider": "NVIDIA",
      "related_images": [
        {
          "digest": "sha256:3094dfbe6dac173d8d3373da29ba9173d5949665ea80b29c4909bc5d586ac82b",
          "image": "nvcr.io/nvidia/mellanox/mofed@sha256:ice-plugin@sha256:3094dfbe6dac173d8d3373da29ba9173d5949665ea80b29c4909bc5d586ac82b",
          "name": "mofed"
        },
        {
          "digest": "sha256:f717f9778f48665b7c592f2225df51b755a1fe048125e034a286c564ee10fd37",
          "image": "ghcr.io/k8snetworkplumbingwg/sriov-network-device-plugin@sha256:f717f9778f48665b7c592f2225df51b755a1fe048125e034a286c564ee10fd37",
          "name": "sriov-network-device-plugin"
        },
        {
          "digest": "sha256:941ad9ff5013e9e7ad5abeb0ea9f79d45379cfae88a628d923f87d2259bdd132",
          "image": "nvcr.io/nvidia/cloud-native/k8s-rdma-shared-dev-plugin@sha256:941ad9ff5013e9e7ad5abeb0ea9f79d45379cfae88a628d923f87d2259bdd132",
          "name": "rdma-shared-device-plugin"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:26d86d5ecccae0abb8003c06d17b6e6083a154350bebdabb5755149a86869224",
          "image": "nvcr.io/nvidia/cloud-native/network-operator@sha256:26d86d5ecccae0abb8003c06d17b6e6083a154350bebdabb5755149a86869224",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.4.0",
      "version_original": "1.4.0"
    },
    {
      "_id": "6376ac9f039b5f41a63e69e8",
      "alm_examples": [
        {
          "api_version": "mellanox.com/v1alpha1",
          "kind": "HostDeviceNetwork",
          "metadata": {
            "name": "example-hostdevice-network"
          },
          "spec": {
            "ipam": "{\n  \"type\": \"whereabouts\",\n  \"range\": \"192.168.3.225/28\",\n  \"exclude\": [\n   \"192.168.3.229/30\",\n   \"192.168.3.236/32\"\n  ]\n}\n",
            "networkNamespace": "default",
            "resourceName": "hostdev"
          }
        },
        {
          "api_version": "mellanox.com/v1alpha1",
          "kind": "IPoIBNetwork",
          "metadata": {
            "name": "example-ipoibnetwork"
          },
          "spec": {
            "ipam": "{\n  \"type\": \"whereabouts\",\n  \"range\": \"192.168.6.225/28\",\n  \"exclude\": [\n   \"192.168.6.229/30\",\n   \"192.168.6.236/32\"\n  ]\n}\n",
            "master": "ibs3f1",
            "networkNamespace": "default"
          }
        },
        {
          "api_version": "mellanox.com/v1alpha1",
          "kind": "MacvlanNetwork",
          "metadata": {
            "name": "example-macvlannetwork"
          },
          "spec": {
            "ipam": "{\n  \"type\": \"whereabouts\",\n  \"range\": \"192.168.2.225/24\",\n  \"exclude\": [\n   \"192.168.2.229/30\",\n   \"192.168.2.236/32\"\n  ]\n}\n",
            "master": "ens2f0",
            "mode": "bridge",
            "mtu": 1500,
            "networkNamespace": "default"
          }
        },
        {
          "api_version": "mellanox.com/v1alpha1",
          "kind": "NicClusterPolicy",
          "metadata": {
            "name": "nic-cluster-policy"
          },
          "spec": {
            "ofedDriver": {
              "image": "mofed",
              "livenessProbe": {
                "initialDelaySeconds": 30,
                "periodSeconds": 30
              },
              "readinessProbe": {
                "initialDelaySeconds": 10,
                "periodSeconds": 30
              },
              "repository": "nvcr.io/nvidia/mellanox",
              "startupProbe": {
                "initialDelaySeconds": 10,
                "periodSeconds": 20
              },
              "upgradePolicy": {
                "autoUpgrade": false,
                "drain": {
                  "deleteEmptyDir": true,
                  "enable": true,
                  "force": true,
                  "podSelector": "",
                  "timeoutSeconds": 300
                },
                "maxParallelUpgrades": 1
              },
              "version": "5.8-1.0.1.1.2"
            },
            "rdmaSharedDevicePlugin": {
              "config": "{\n  \"configList\": [\n    {\n      \"resourceName\": \"rdma_shared_device_a\",\n      \"rdmaHcaMax\": 1000,\n      \"selectors\": {\n        \"ifNames\": [\"ens2f0\"]\n      }\n    }\n  ]\n}\n",
              "image": "k8s-rdma-shared-dev-plugin",
              "repository": "nvcr.io/nvidia/cloud-native",
              "version": "v1.3.2"
            },
            "sriovDevicePlugin": {
              "config": "{\n  \"resourceList\": [\n      {\n          \"resourcePrefix\": \"nvidia.com\",\n          \"resourceName\": \"hostdev\",\n          \"selectors\": {\n              \"vendors\": [\"15b3\"],\n              \"isRdma\": true\n          }\n      }\n  ]\n}\n",
              "image": "sriov-device-plugin",
              "repository": "ghcr.io/k8snetworkplumbingwg",
              "version": "v3.5.1"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/nvidia-network-operator/nvidia-network-operator@sha256:78b16fabf7a7fe7f85569ad111720daddac10e75cc61395f3b2feab9a94bb1c7",
      "bundle_path_digest": "sha256:78b16fabf7a7fe7f85569ad111720daddac10e75cc61395f3b2feab9a94bb1c7",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "v1.4.0",
      "creation_date": "2022-11-17T21:50:23.556000+00:00",
      "csv_description": "## NVIDIA Network Operator\nThe NVIDIA Network Operator simplifies the provisioning and management of NVIDIA networking resources  in a Kubernetes cluster. The operator automatically installs the required host networking software - bringing together all the needed components to provide high-speed network connectivity. These components include the NVIDIA networking driver, Kubernetes device plugin, CNI plugins, IP address management (IPAM) plugin and others.\nThe NVIDIA Network Operator works in conjunction with the NVIDIA GPU Operator to deliver high-throughput, low-latency networking for scale-out, GPU computing clusters.\n\nThe Network Operator uses Node Feature Discovery (NFD) labels in order to properly schedule resources.\nNodes can be labelled manually or using the NFD Operator. An example of `NodeFeatureDiscovery`\nconfiguration is available in the documentation.\nThe following NFD labels are used:\n`feature.node.kubernetes.io/pci-15b3.present` for nodes containing NVIDIA Networking hardware.\n`feature.node.kubernetes.io/pci-10de.present` for nodes containing NVIDIA GPU hardware.\n\nThe Network Operator is open-source. For more information on contributions and release artifacts, see the [GitHub repo](https://github.com/Mellanox/network-operator/)\n",
      "csv_display_name": "NVIDIA Network Operator",
      "csv_metadata_description": "Deploy and manage NVIDIA networking resources in Kubernetes",
      "csv_name": "nvidia-network-operator.v1.4.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T08:46:02.278000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "nvidia-network-operator",
      "provided_apis": [
        {
          "group": "mellanox.com",
          "kind": "HostDeviceNetwork",
          "plural": "hostdevicenetworks",
          "version": "v1alpha1"
        },
        {
          "group": "mellanox.com",
          "kind": "IPoIBNetwork",
          "plural": "ipoibnetworks",
          "version": "v1alpha1"
        },
        {
          "group": "mellanox.com",
          "kind": "MacvlanNetwork",
          "plural": "macvlannetworks",
          "version": "v1alpha1"
        },
        {
          "group": "mellanox.com",
          "kind": "NicClusterPolicy",
          "plural": "nicclusterpolicies",
          "version": "v1alpha1"
        }
      ],
      "provider": "NVIDIA",
      "related_images": [
        {
          "digest": "sha256:3094dfbe6dac173d8d3373da29ba9173d5949665ea80b29c4909bc5d586ac82b",
          "image": "nvcr.io/nvidia/mellanox/mofed@sha256:ice-plugin@sha256:3094dfbe6dac173d8d3373da29ba9173d5949665ea80b29c4909bc5d586ac82b",
          "name": "mofed"
        },
        {
          "digest": "sha256:f717f9778f48665b7c592f2225df51b755a1fe048125e034a286c564ee10fd37",
          "image": "ghcr.io/k8snetworkplumbingwg/sriov-network-device-plugin@sha256:f717f9778f48665b7c592f2225df51b755a1fe048125e034a286c564ee10fd37",
          "name": "sriov-network-device-plugin"
        },
        {
          "digest": "sha256:941ad9ff5013e9e7ad5abeb0ea9f79d45379cfae88a628d923f87d2259bdd132",
          "image": "nvcr.io/nvidia/cloud-native/k8s-rdma-shared-dev-plugin@sha256:941ad9ff5013e9e7ad5abeb0ea9f79d45379cfae88a628d923f87d2259bdd132",
          "name": "rdma-shared-device-plugin"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:26d86d5ecccae0abb8003c06d17b6e6083a154350bebdabb5755149a86869224",
          "image": "nvcr.io/nvidia/cloud-native/network-operator@sha256:26d86d5ecccae0abb8003c06d17b6e6083a154350bebdabb5755149a86869224",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.4.0",
      "version_original": "1.4.0"
    },
    {
      "_id": "6377178930a3fe7750ffc780",
      "alm_examples": [
        {
          "api_version": "helm.infinidat.com/v1alpha1",
          "kind": "InfiniboxCsiDriver",
          "metadata": {
            "name": "infiniboxcsidriver-sample"
          },
          "spec": {
            "Infinibox_Cred": {
              "SecretName": "infinibox-creds",
              "hostname": "hostname",
              "inbound_secret": "0.0000000000000",
              "inbound_user": "iqn.2020-06.com.csi-driver-iscsi.infinidat:commonout",
              "outbound_secret": "0.0000000000000",
              "outbound_user": "iqn.2020-06.com.csi-driver-iscsi.infinidat:commonin",
              "password": "password",
              "username": "username"
            },
            "csiDriverName": "infinibox-csi-driver",
            "csiDriverVersion": "v2.2.0",
            "images": {
              "attachersidecar": "k8s.gcr.io/sig-storage/csi-attacher@sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
              "attachersidecar_pull_policy": "IfNotPresent",
              "csidriver": "registry.connect.redhat.com/infinidat/infinibox-csidriver-certified@sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
              "csidriver_pull_policy": "Always",
              "imagePullSecret": "private-docker-reg-secret",
              "provisionersidecar": "k8s.gcr.io/sig-storage/csi-provisioner@sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
              "provisionersidecar_pull_policy": "IfNotPresent",
              "registrarsidecar": "k8s.gcr.io/sig-storage/csi-node-driver-registrar@sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
              "registrarsidecar_pull_policy": "IfNotPresent",
              "resizersidecar": "k8s.gcr.io/sig-storage/csi-resizer@sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
              "resizersidecar_pull_policy": "IfNotPresent",
              "snapshottersidecar": "k8s.gcr.io/sig-storage/csi-snapshotter@sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
              "snapshottersidecar_pull_policy": "IfNotPresent"
            },
            "instanceCount": 1,
            "logLevel": "debug",
            "replicaCount": 1,
            "volumeNamePrefix": "csi"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/infinidat/infinibox-operator-certified-bundle@sha256:0f9b84efc0f136468fbbeb29ddae1ea8e71748eb0aaac3196b95d792540bfd39",
      "bundle_path_digest": "sha256:0f9b84efc0f136468fbbeb29ddae1ea8e71748eb0aaac3196b95d792540bfd39",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-11-18T05:26:33.912000+00:00",
      "csv_description": "Infinidat InfiniBox Container Storage Interface (CSI) Driver is a CNCF-compliant Kubernetes integration for InfiniBox storage systems, offering advanced enterprise functionality for petabyte-scale Kubernetes deployments including Red Hat OpenShift.\n \n## Features and Benefits\n  \n* **Multi-protocol flexibility** - manage Kubernetes Persistent Volumes attached via block and file protocols, including Fibre Channel, iSCSI, and NFS, with all Kubernetes PV access modes\n* **Multi-petabyte scalability** - support hundreds of thousands of PVs per InfiniBox system and control multiple InfiniBox arrays within a single Kubernetes cluster  \n* **Advanced enterprise features** - manage native InfiniBox snapshots and clones, including restoring from snapshots, and import PVs created outside of InfiniBox CSI Driver\n  \n## Required Parameters\n  \n* `hostname` - IP address or hostname of the InfiniBox management interface\n* `username` / `password` - InfiniBox credentials\n* `SecretName` - secret name, to be used in the StorageClass to define a specific InfiniBox for persistent volumes\n\n## Optional Parameters\n* `inbound_user` / `inbound_secret` / `outbound_user` / `outbound_secret` - credentials for iSCSI CHAP authentication\n",
      "csv_display_name": "InfiniBox CSI Driver - Operator",
      "csv_metadata_description": "CNCF-compliant Kubernetes integration for Infinidat InfiniBox storage systems, offering advanced enterprise functionality for petabyte-scale Kubernetes deployments including Red Hat OpenShift Platform.",
      "csv_name": "infinibox-operator.v2.2.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T08:31:47.316000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "infinibox-operator-certified",
      "provided_apis": [
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotClass",
          "plural": "volumesnapshotclasses",
          "version": "v1beta1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotContent",
          "plural": "volumesnapshotcontents",
          "version": "v1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotContent",
          "plural": "volumesnapshotcontents",
          "version": "v1beta1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshot",
          "plural": "volumesnapshots",
          "version": "v1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshot",
          "plural": "volumesnapshots",
          "version": "v1beta1"
        },
        {
          "group": "helm.infinidat.com",
          "kind": "InfiniboxCsiDriver",
          "plural": "infiniboxcsidrivers",
          "version": "v1alpha1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotClass",
          "plural": "volumesnapshotclasses",
          "version": "v1"
        }
      ],
      "provider": "Infinidat",
      "related_images": [
        {
          "digest": "sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
          "image": "registry.connect.redhat.com/infinidat/infinibox-csidriver-certified@sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
          "name": "infinibox-csidriver-certified-1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be-annotation"
        },
        {
          "digest": "sha256:d99a8d144816b951a67648c12c0b988936ccd25cf3754f3cd85ab8c01592248f",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:d99a8d144816b951a67648c12c0b988936ccd25cf3754f3cd85ab8c01592248f",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:e2c7d7df9de11bd2f9ce1faf299a4f13891a0e1e83ebbdb5fcf22e62b40b6a2a",
          "image": "registry.connect.redhat.com/infinidat/infinibox-operator-certified@sha256:e2c7d7df9de11bd2f9ce1faf299a4f13891a0e1e83ebbdb5fcf22e62b40b6a2a",
          "name": "manager"
        },
        {
          "digest": "sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
          "image": "k8s.gcr.io/sig-storage/csi-snapshotter@sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
          "name": "csi-snapshotter-89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709-annotation"
        },
        {
          "digest": "sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
          "image": "k8s.gcr.io/sig-storage/csi-resizer@sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
          "name": "csi-resizer-9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4-annotation"
        },
        {
          "digest": "sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
          "image": "k8s.gcr.io/sig-storage/csi-node-driver-registrar@sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
          "name": "csi-node-driver-registrar-4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6-annotation"
        },
        {
          "digest": "sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
          "image": "k8s.gcr.io/sig-storage/csi-provisioner@sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
          "name": "csi-provisioner-122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119-annotation"
        },
        {
          "digest": "sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
          "image": "k8s.gcr.io/sig-storage/csi-attacher@sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
          "name": "csi-attacher-8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b-annotation"
        }
      ],
      "replaces": null,
      "skip_range": "<2.2.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "2.2.0",
      "version_original": "2.2.0"
    },
    {
      "_id": "6377178a313b3f8bdba7fd82",
      "alm_examples": [
        {
          "api_version": "helm.infinidat.com/v1alpha1",
          "kind": "InfiniboxCsiDriver",
          "metadata": {
            "name": "infiniboxcsidriver-sample"
          },
          "spec": {
            "Infinibox_Cred": {
              "SecretName": "infinibox-creds",
              "hostname": "hostname",
              "inbound_secret": "0.0000000000000",
              "inbound_user": "iqn.2020-06.com.csi-driver-iscsi.infinidat:commonout",
              "outbound_secret": "0.0000000000000",
              "outbound_user": "iqn.2020-06.com.csi-driver-iscsi.infinidat:commonin",
              "password": "password",
              "username": "username"
            },
            "csiDriverName": "infinibox-csi-driver",
            "csiDriverVersion": "v2.2.0",
            "images": {
              "attachersidecar": "k8s.gcr.io/sig-storage/csi-attacher@sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
              "attachersidecar_pull_policy": "IfNotPresent",
              "csidriver": "registry.connect.redhat.com/infinidat/infinibox-csidriver-certified@sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
              "csidriver_pull_policy": "Always",
              "imagePullSecret": "private-docker-reg-secret",
              "provisionersidecar": "k8s.gcr.io/sig-storage/csi-provisioner@sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
              "provisionersidecar_pull_policy": "IfNotPresent",
              "registrarsidecar": "k8s.gcr.io/sig-storage/csi-node-driver-registrar@sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
              "registrarsidecar_pull_policy": "IfNotPresent",
              "resizersidecar": "k8s.gcr.io/sig-storage/csi-resizer@sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
              "resizersidecar_pull_policy": "IfNotPresent",
              "snapshottersidecar": "k8s.gcr.io/sig-storage/csi-snapshotter@sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
              "snapshottersidecar_pull_policy": "IfNotPresent"
            },
            "instanceCount": 1,
            "logLevel": "debug",
            "replicaCount": 1,
            "volumeNamePrefix": "csi"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/infinidat/infinibox-operator-certified-bundle@sha256:0f9b84efc0f136468fbbeb29ddae1ea8e71748eb0aaac3196b95d792540bfd39",
      "bundle_path_digest": "sha256:0f9b84efc0f136468fbbeb29ddae1ea8e71748eb0aaac3196b95d792540bfd39",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-18T05:26:34.902000+00:00",
      "csv_description": "Infinidat InfiniBox Container Storage Interface (CSI) Driver is a CNCF-compliant Kubernetes integration for InfiniBox storage systems, offering advanced enterprise functionality for petabyte-scale Kubernetes deployments including Red Hat OpenShift.\n \n## Features and Benefits\n  \n* **Multi-protocol flexibility** - manage Kubernetes Persistent Volumes attached via block and file protocols, including Fibre Channel, iSCSI, and NFS, with all Kubernetes PV access modes\n* **Multi-petabyte scalability** - support hundreds of thousands of PVs per InfiniBox system and control multiple InfiniBox arrays within a single Kubernetes cluster  \n* **Advanced enterprise features** - manage native InfiniBox snapshots and clones, including restoring from snapshots, and import PVs created outside of InfiniBox CSI Driver\n  \n## Required Parameters\n  \n* `hostname` - IP address or hostname of the InfiniBox management interface\n* `username` / `password` - InfiniBox credentials\n* `SecretName` - secret name, to be used in the StorageClass to define a specific InfiniBox for persistent volumes\n\n## Optional Parameters\n* `inbound_user` / `inbound_secret` / `outbound_user` / `outbound_secret` - credentials for iSCSI CHAP authentication\n",
      "csv_display_name": "InfiniBox CSI Driver - Operator",
      "csv_metadata_description": "CNCF-compliant Kubernetes integration for Infinidat InfiniBox storage systems, offering advanced enterprise functionality for petabyte-scale Kubernetes deployments including Red Hat OpenShift Platform.",
      "csv_name": "infinibox-operator.v2.2.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T08:31:54.715000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "infinibox-operator-certified",
      "provided_apis": [
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotClass",
          "plural": "volumesnapshotclasses",
          "version": "v1beta1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotContent",
          "plural": "volumesnapshotcontents",
          "version": "v1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotContent",
          "plural": "volumesnapshotcontents",
          "version": "v1beta1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshot",
          "plural": "volumesnapshots",
          "version": "v1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshot",
          "plural": "volumesnapshots",
          "version": "v1beta1"
        },
        {
          "group": "helm.infinidat.com",
          "kind": "InfiniboxCsiDriver",
          "plural": "infiniboxcsidrivers",
          "version": "v1alpha1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotClass",
          "plural": "volumesnapshotclasses",
          "version": "v1"
        }
      ],
      "provider": "Infinidat",
      "related_images": [
        {
          "digest": "sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
          "image": "registry.connect.redhat.com/infinidat/infinibox-csidriver-certified@sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
          "name": "infinibox-csidriver-certified-1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be-annotation"
        },
        {
          "digest": "sha256:d99a8d144816b951a67648c12c0b988936ccd25cf3754f3cd85ab8c01592248f",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:d99a8d144816b951a67648c12c0b988936ccd25cf3754f3cd85ab8c01592248f",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:e2c7d7df9de11bd2f9ce1faf299a4f13891a0e1e83ebbdb5fcf22e62b40b6a2a",
          "image": "registry.connect.redhat.com/infinidat/infinibox-operator-certified@sha256:e2c7d7df9de11bd2f9ce1faf299a4f13891a0e1e83ebbdb5fcf22e62b40b6a2a",
          "name": "manager"
        },
        {
          "digest": "sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
          "image": "k8s.gcr.io/sig-storage/csi-snapshotter@sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
          "name": "csi-snapshotter-89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709-annotation"
        },
        {
          "digest": "sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
          "image": "k8s.gcr.io/sig-storage/csi-resizer@sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
          "name": "csi-resizer-9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4-annotation"
        },
        {
          "digest": "sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
          "image": "k8s.gcr.io/sig-storage/csi-node-driver-registrar@sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
          "name": "csi-node-driver-registrar-4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6-annotation"
        },
        {
          "digest": "sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
          "image": "k8s.gcr.io/sig-storage/csi-provisioner@sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
          "name": "csi-provisioner-122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119-annotation"
        },
        {
          "digest": "sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
          "image": "k8s.gcr.io/sig-storage/csi-attacher@sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
          "name": "csi-attacher-8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b-annotation"
        }
      ],
      "replaces": null,
      "skip_range": "<2.2.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "2.2.0",
      "version_original": "2.2.0"
    },
    {
      "_id": "637717b8225a329f274be181",
      "alm_examples": [
        {
          "api_version": "helm.infinidat.com/v1alpha1",
          "kind": "InfiniboxCsiDriver",
          "metadata": {
            "name": "infiniboxcsidriver-sample"
          },
          "spec": {
            "Infinibox_Cred": {
              "SecretName": "infinibox-creds",
              "hostname": "hostname",
              "inbound_secret": "0.0000000000000",
              "inbound_user": "iqn.2020-06.com.csi-driver-iscsi.infinidat:commonout",
              "outbound_secret": "0.0000000000000",
              "outbound_user": "iqn.2020-06.com.csi-driver-iscsi.infinidat:commonin",
              "password": "password",
              "username": "username"
            },
            "csiDriverName": "infinibox-csi-driver",
            "csiDriverVersion": "v2.2.0",
            "images": {
              "attachersidecar": "k8s.gcr.io/sig-storage/csi-attacher@sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
              "attachersidecar_pull_policy": "IfNotPresent",
              "csidriver": "registry.connect.redhat.com/infinidat/infinibox-csidriver-certified@sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
              "csidriver_pull_policy": "Always",
              "imagePullSecret": "private-docker-reg-secret",
              "provisionersidecar": "k8s.gcr.io/sig-storage/csi-provisioner@sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
              "provisionersidecar_pull_policy": "IfNotPresent",
              "registrarsidecar": "k8s.gcr.io/sig-storage/csi-node-driver-registrar@sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
              "registrarsidecar_pull_policy": "IfNotPresent",
              "resizersidecar": "k8s.gcr.io/sig-storage/csi-resizer@sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
              "resizersidecar_pull_policy": "IfNotPresent",
              "snapshottersidecar": "k8s.gcr.io/sig-storage/csi-snapshotter@sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
              "snapshottersidecar_pull_policy": "IfNotPresent"
            },
            "instanceCount": 1,
            "logLevel": "debug",
            "replicaCount": 1,
            "volumeNamePrefix": "csi"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/infinidat/infinibox-operator-certified-bundle@sha256:0f9b84efc0f136468fbbeb29ddae1ea8e71748eb0aaac3196b95d792540bfd39",
      "bundle_path_digest": "sha256:0f9b84efc0f136468fbbeb29ddae1ea8e71748eb0aaac3196b95d792540bfd39",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-11-18T05:27:20.572000+00:00",
      "csv_description": "Infinidat InfiniBox Container Storage Interface (CSI) Driver is a CNCF-compliant Kubernetes integration for InfiniBox storage systems, offering advanced enterprise functionality for petabyte-scale Kubernetes deployments including Red Hat OpenShift.\n \n## Features and Benefits\n  \n* **Multi-protocol flexibility** - manage Kubernetes Persistent Volumes attached via block and file protocols, including Fibre Channel, iSCSI, and NFS, with all Kubernetes PV access modes\n* **Multi-petabyte scalability** - support hundreds of thousands of PVs per InfiniBox system and control multiple InfiniBox arrays within a single Kubernetes cluster  \n* **Advanced enterprise features** - manage native InfiniBox snapshots and clones, including restoring from snapshots, and import PVs created outside of InfiniBox CSI Driver\n  \n## Required Parameters\n  \n* `hostname` - IP address or hostname of the InfiniBox management interface\n* `username` / `password` - InfiniBox credentials\n* `SecretName` - secret name, to be used in the StorageClass to define a specific InfiniBox for persistent volumes\n\n## Optional Parameters\n* `inbound_user` / `inbound_secret` / `outbound_user` / `outbound_secret` - credentials for iSCSI CHAP authentication\n",
      "csv_display_name": "InfiniBox CSI Driver - Operator",
      "csv_metadata_description": "CNCF-compliant Kubernetes integration for Infinidat InfiniBox storage systems, offering advanced enterprise functionality for petabyte-scale Kubernetes deployments including Red Hat OpenShift Platform.",
      "csv_name": "infinibox-operator.v2.2.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T07:16:03.285000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "infinibox-operator-certified",
      "provided_apis": [
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotContent",
          "plural": "volumesnapshotcontents",
          "version": "v1beta1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshot",
          "plural": "volumesnapshots",
          "version": "v1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshot",
          "plural": "volumesnapshots",
          "version": "v1beta1"
        },
        {
          "group": "helm.infinidat.com",
          "kind": "InfiniboxCsiDriver",
          "plural": "infiniboxcsidrivers",
          "version": "v1alpha1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotClass",
          "plural": "volumesnapshotclasses",
          "version": "v1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotClass",
          "plural": "volumesnapshotclasses",
          "version": "v1beta1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotContent",
          "plural": "volumesnapshotcontents",
          "version": "v1"
        }
      ],
      "provider": "Infinidat",
      "related_images": [
        {
          "digest": "sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
          "image": "registry.connect.redhat.com/infinidat/infinibox-csidriver-certified@sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
          "name": "infinibox-csidriver-certified-1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be-annotation"
        },
        {
          "digest": "sha256:d99a8d144816b951a67648c12c0b988936ccd25cf3754f3cd85ab8c01592248f",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:d99a8d144816b951a67648c12c0b988936ccd25cf3754f3cd85ab8c01592248f",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:e2c7d7df9de11bd2f9ce1faf299a4f13891a0e1e83ebbdb5fcf22e62b40b6a2a",
          "image": "registry.connect.redhat.com/infinidat/infinibox-operator-certified@sha256:e2c7d7df9de11bd2f9ce1faf299a4f13891a0e1e83ebbdb5fcf22e62b40b6a2a",
          "name": "manager"
        },
        {
          "digest": "sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
          "image": "k8s.gcr.io/sig-storage/csi-snapshotter@sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
          "name": "csi-snapshotter-89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709-annotation"
        },
        {
          "digest": "sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
          "image": "k8s.gcr.io/sig-storage/csi-resizer@sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
          "name": "csi-resizer-9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4-annotation"
        },
        {
          "digest": "sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
          "image": "k8s.gcr.io/sig-storage/csi-node-driver-registrar@sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
          "name": "csi-node-driver-registrar-4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6-annotation"
        },
        {
          "digest": "sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
          "image": "k8s.gcr.io/sig-storage/csi-provisioner@sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
          "name": "csi-provisioner-122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119-annotation"
        },
        {
          "digest": "sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
          "image": "k8s.gcr.io/sig-storage/csi-attacher@sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
          "name": "csi-attacher-8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b-annotation"
        }
      ],
      "replaces": null,
      "skip_range": "<2.2.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2.2.0",
      "version_original": "2.2.0"
    },
    {
      "_id": "637717b939c5577889452944",
      "alm_examples": [
        {
          "api_version": "helm.infinidat.com/v1alpha1",
          "kind": "InfiniboxCsiDriver",
          "metadata": {
            "name": "infiniboxcsidriver-sample"
          },
          "spec": {
            "Infinibox_Cred": {
              "SecretName": "infinibox-creds",
              "hostname": "hostname",
              "inbound_secret": "0.0000000000000",
              "inbound_user": "iqn.2020-06.com.csi-driver-iscsi.infinidat:commonout",
              "outbound_secret": "0.0000000000000",
              "outbound_user": "iqn.2020-06.com.csi-driver-iscsi.infinidat:commonin",
              "password": "password",
              "username": "username"
            },
            "csiDriverName": "infinibox-csi-driver",
            "csiDriverVersion": "v2.2.0",
            "images": {
              "attachersidecar": "k8s.gcr.io/sig-storage/csi-attacher@sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
              "attachersidecar_pull_policy": "IfNotPresent",
              "csidriver": "registry.connect.redhat.com/infinidat/infinibox-csidriver-certified@sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
              "csidriver_pull_policy": "Always",
              "imagePullSecret": "private-docker-reg-secret",
              "provisionersidecar": "k8s.gcr.io/sig-storage/csi-provisioner@sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
              "provisionersidecar_pull_policy": "IfNotPresent",
              "registrarsidecar": "k8s.gcr.io/sig-storage/csi-node-driver-registrar@sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
              "registrarsidecar_pull_policy": "IfNotPresent",
              "resizersidecar": "k8s.gcr.io/sig-storage/csi-resizer@sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
              "resizersidecar_pull_policy": "IfNotPresent",
              "snapshottersidecar": "k8s.gcr.io/sig-storage/csi-snapshotter@sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
              "snapshottersidecar_pull_policy": "IfNotPresent"
            },
            "instanceCount": 1,
            "logLevel": "debug",
            "replicaCount": 1,
            "volumeNamePrefix": "csi"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/infinidat/infinibox-operator-certified-bundle@sha256:0f9b84efc0f136468fbbeb29ddae1ea8e71748eb0aaac3196b95d792540bfd39",
      "bundle_path_digest": "sha256:0f9b84efc0f136468fbbeb29ddae1ea8e71748eb0aaac3196b95d792540bfd39",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-18T05:27:21.312000+00:00",
      "csv_description": "Infinidat InfiniBox Container Storage Interface (CSI) Driver is a CNCF-compliant Kubernetes integration for InfiniBox storage systems, offering advanced enterprise functionality for petabyte-scale Kubernetes deployments including Red Hat OpenShift.\n \n## Features and Benefits\n  \n* **Multi-protocol flexibility** - manage Kubernetes Persistent Volumes attached via block and file protocols, including Fibre Channel, iSCSI, and NFS, with all Kubernetes PV access modes\n* **Multi-petabyte scalability** - support hundreds of thousands of PVs per InfiniBox system and control multiple InfiniBox arrays within a single Kubernetes cluster  \n* **Advanced enterprise features** - manage native InfiniBox snapshots and clones, including restoring from snapshots, and import PVs created outside of InfiniBox CSI Driver\n  \n## Required Parameters\n  \n* `hostname` - IP address or hostname of the InfiniBox management interface\n* `username` / `password` - InfiniBox credentials\n* `SecretName` - secret name, to be used in the StorageClass to define a specific InfiniBox for persistent volumes\n\n## Optional Parameters\n* `inbound_user` / `inbound_secret` / `outbound_user` / `outbound_secret` - credentials for iSCSI CHAP authentication\n",
      "csv_display_name": "InfiniBox CSI Driver - Operator",
      "csv_metadata_description": "CNCF-compliant Kubernetes integration for Infinidat InfiniBox storage systems, offering advanced enterprise functionality for petabyte-scale Kubernetes deployments including Red Hat OpenShift Platform.",
      "csv_name": "infinibox-operator.v2.2.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:16:07.486000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "infinibox-operator-certified",
      "provided_apis": [
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotContent",
          "plural": "volumesnapshotcontents",
          "version": "v1beta1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshot",
          "plural": "volumesnapshots",
          "version": "v1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshot",
          "plural": "volumesnapshots",
          "version": "v1beta1"
        },
        {
          "group": "helm.infinidat.com",
          "kind": "InfiniboxCsiDriver",
          "plural": "infiniboxcsidrivers",
          "version": "v1alpha1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotClass",
          "plural": "volumesnapshotclasses",
          "version": "v1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotClass",
          "plural": "volumesnapshotclasses",
          "version": "v1beta1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotContent",
          "plural": "volumesnapshotcontents",
          "version": "v1"
        }
      ],
      "provider": "Infinidat",
      "related_images": [
        {
          "digest": "sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
          "image": "registry.connect.redhat.com/infinidat/infinibox-csidriver-certified@sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
          "name": "infinibox-csidriver-certified-1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be-annotation"
        },
        {
          "digest": "sha256:d99a8d144816b951a67648c12c0b988936ccd25cf3754f3cd85ab8c01592248f",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:d99a8d144816b951a67648c12c0b988936ccd25cf3754f3cd85ab8c01592248f",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:e2c7d7df9de11bd2f9ce1faf299a4f13891a0e1e83ebbdb5fcf22e62b40b6a2a",
          "image": "registry.connect.redhat.com/infinidat/infinibox-operator-certified@sha256:e2c7d7df9de11bd2f9ce1faf299a4f13891a0e1e83ebbdb5fcf22e62b40b6a2a",
          "name": "manager"
        },
        {
          "digest": "sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
          "image": "k8s.gcr.io/sig-storage/csi-snapshotter@sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
          "name": "csi-snapshotter-89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709-annotation"
        },
        {
          "digest": "sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
          "image": "k8s.gcr.io/sig-storage/csi-resizer@sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
          "name": "csi-resizer-9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4-annotation"
        },
        {
          "digest": "sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
          "image": "k8s.gcr.io/sig-storage/csi-node-driver-registrar@sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
          "name": "csi-node-driver-registrar-4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6-annotation"
        },
        {
          "digest": "sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
          "image": "k8s.gcr.io/sig-storage/csi-provisioner@sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
          "name": "csi-provisioner-122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119-annotation"
        },
        {
          "digest": "sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
          "image": "k8s.gcr.io/sig-storage/csi-attacher@sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
          "name": "csi-attacher-8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b-annotation"
        }
      ],
      "replaces": null,
      "skip_range": "<2.2.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2.2.0",
      "version_original": "2.2.0"
    },
    {
      "_id": "637717ed313b3f8bdba7fe12",
      "alm_examples": [
        {
          "api_version": "helm.infinidat.com/v1alpha1",
          "kind": "InfiniboxCsiDriver",
          "metadata": {
            "name": "infiniboxcsidriver-sample"
          },
          "spec": {
            "Infinibox_Cred": {
              "SecretName": "infinibox-creds",
              "hostname": "hostname",
              "inbound_secret": "0.0000000000000",
              "inbound_user": "iqn.2020-06.com.csi-driver-iscsi.infinidat:commonout",
              "outbound_secret": "0.0000000000000",
              "outbound_user": "iqn.2020-06.com.csi-driver-iscsi.infinidat:commonin",
              "password": "password",
              "username": "username"
            },
            "csiDriverName": "infinibox-csi-driver",
            "csiDriverVersion": "v2.2.0",
            "images": {
              "attachersidecar": "k8s.gcr.io/sig-storage/csi-attacher@sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
              "attachersidecar_pull_policy": "IfNotPresent",
              "csidriver": "registry.connect.redhat.com/infinidat/infinibox-csidriver-certified@sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
              "csidriver_pull_policy": "Always",
              "imagePullSecret": "private-docker-reg-secret",
              "provisionersidecar": "k8s.gcr.io/sig-storage/csi-provisioner@sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
              "provisionersidecar_pull_policy": "IfNotPresent",
              "registrarsidecar": "k8s.gcr.io/sig-storage/csi-node-driver-registrar@sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
              "registrarsidecar_pull_policy": "IfNotPresent",
              "resizersidecar": "k8s.gcr.io/sig-storage/csi-resizer@sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
              "resizersidecar_pull_policy": "IfNotPresent",
              "snapshottersidecar": "k8s.gcr.io/sig-storage/csi-snapshotter@sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
              "snapshottersidecar_pull_policy": "IfNotPresent"
            },
            "instanceCount": 1,
            "logLevel": "debug",
            "replicaCount": 1,
            "volumeNamePrefix": "csi"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/infinidat/infinibox-operator-certified-bundle@sha256:0f9b84efc0f136468fbbeb29ddae1ea8e71748eb0aaac3196b95d792540bfd39",
      "bundle_path_digest": "sha256:0f9b84efc0f136468fbbeb29ddae1ea8e71748eb0aaac3196b95d792540bfd39",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-11-18T05:28:13.506000+00:00",
      "csv_description": "Infinidat InfiniBox Container Storage Interface (CSI) Driver is a CNCF-compliant Kubernetes integration for InfiniBox storage systems, offering advanced enterprise functionality for petabyte-scale Kubernetes deployments including Red Hat OpenShift.\n \n## Features and Benefits\n  \n* **Multi-protocol flexibility** - manage Kubernetes Persistent Volumes attached via block and file protocols, including Fibre Channel, iSCSI, and NFS, with all Kubernetes PV access modes\n* **Multi-petabyte scalability** - support hundreds of thousands of PVs per InfiniBox system and control multiple InfiniBox arrays within a single Kubernetes cluster  \n* **Advanced enterprise features** - manage native InfiniBox snapshots and clones, including restoring from snapshots, and import PVs created outside of InfiniBox CSI Driver\n  \n## Required Parameters\n  \n* `hostname` - IP address or hostname of the InfiniBox management interface\n* `username` / `password` - InfiniBox credentials\n* `SecretName` - secret name, to be used in the StorageClass to define a specific InfiniBox for persistent volumes\n\n## Optional Parameters\n* `inbound_user` / `inbound_secret` / `outbound_user` / `outbound_secret` - credentials for iSCSI CHAP authentication\n",
      "csv_display_name": "InfiniBox CSI Driver - Operator",
      "csv_metadata_description": "CNCF-compliant Kubernetes integration for Infinidat InfiniBox storage systems, offering advanced enterprise functionality for petabyte-scale Kubernetes deployments including Red Hat OpenShift Platform.",
      "csv_name": "infinibox-operator.v2.2.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T07:02:30.936000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "infinibox-operator-certified",
      "provided_apis": [
        {
          "group": "helm.infinidat.com",
          "kind": "InfiniboxCsiDriver",
          "version": "v1alpha1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshot",
          "version": "v1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshot",
          "version": "v1beta1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotClass",
          "version": "v1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotClass",
          "version": "v1beta1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotContent",
          "version": "v1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotContent",
          "version": "v1beta1"
        }
      ],
      "provider": "Infinidat",
      "related_images": [
        {
          "digest": "sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
          "image": "registry.connect.redhat.com/infinidat/infinibox-csidriver-certified@sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
          "name": "infinibox-csidriver-certified-1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be-annotation"
        },
        {
          "digest": "sha256:d99a8d144816b951a67648c12c0b988936ccd25cf3754f3cd85ab8c01592248f",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:d99a8d144816b951a67648c12c0b988936ccd25cf3754f3cd85ab8c01592248f",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:e2c7d7df9de11bd2f9ce1faf299a4f13891a0e1e83ebbdb5fcf22e62b40b6a2a",
          "image": "registry.connect.redhat.com/infinidat/infinibox-operator-certified@sha256:e2c7d7df9de11bd2f9ce1faf299a4f13891a0e1e83ebbdb5fcf22e62b40b6a2a",
          "name": "manager"
        },
        {
          "digest": "sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
          "image": "k8s.gcr.io/sig-storage/csi-snapshotter@sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
          "name": "csi-snapshotter-89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709-annotation"
        },
        {
          "digest": "sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
          "image": "k8s.gcr.io/sig-storage/csi-resizer@sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
          "name": "csi-resizer-9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4-annotation"
        },
        {
          "digest": "sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
          "image": "k8s.gcr.io/sig-storage/csi-node-driver-registrar@sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
          "name": "csi-node-driver-registrar-4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6-annotation"
        },
        {
          "digest": "sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
          "image": "k8s.gcr.io/sig-storage/csi-provisioner@sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
          "name": "csi-provisioner-122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119-annotation"
        },
        {
          "digest": "sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
          "image": "k8s.gcr.io/sig-storage/csi-attacher@sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
          "name": "csi-attacher-8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b-annotation"
        }
      ],
      "replaces": null,
      "skip_range": "<2.2.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2.2.0",
      "version_original": "2.2.0"
    },
    {
      "_id": "637717ee313b3f8bdba7fe17",
      "alm_examples": [
        {
          "api_version": "helm.infinidat.com/v1alpha1",
          "kind": "InfiniboxCsiDriver",
          "metadata": {
            "name": "infiniboxcsidriver-sample"
          },
          "spec": {
            "Infinibox_Cred": {
              "SecretName": "infinibox-creds",
              "hostname": "hostname",
              "inbound_secret": "0.0000000000000",
              "inbound_user": "iqn.2020-06.com.csi-driver-iscsi.infinidat:commonout",
              "outbound_secret": "0.0000000000000",
              "outbound_user": "iqn.2020-06.com.csi-driver-iscsi.infinidat:commonin",
              "password": "password",
              "username": "username"
            },
            "csiDriverName": "infinibox-csi-driver",
            "csiDriverVersion": "v2.2.0",
            "images": {
              "attachersidecar": "k8s.gcr.io/sig-storage/csi-attacher@sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
              "attachersidecar_pull_policy": "IfNotPresent",
              "csidriver": "registry.connect.redhat.com/infinidat/infinibox-csidriver-certified@sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
              "csidriver_pull_policy": "Always",
              "imagePullSecret": "private-docker-reg-secret",
              "provisionersidecar": "k8s.gcr.io/sig-storage/csi-provisioner@sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
              "provisionersidecar_pull_policy": "IfNotPresent",
              "registrarsidecar": "k8s.gcr.io/sig-storage/csi-node-driver-registrar@sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
              "registrarsidecar_pull_policy": "IfNotPresent",
              "resizersidecar": "k8s.gcr.io/sig-storage/csi-resizer@sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
              "resizersidecar_pull_policy": "IfNotPresent",
              "snapshottersidecar": "k8s.gcr.io/sig-storage/csi-snapshotter@sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
              "snapshottersidecar_pull_policy": "IfNotPresent"
            },
            "instanceCount": 1,
            "logLevel": "debug",
            "replicaCount": 1,
            "volumeNamePrefix": "csi"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/infinidat/infinibox-operator-certified-bundle@sha256:0f9b84efc0f136468fbbeb29ddae1ea8e71748eb0aaac3196b95d792540bfd39",
      "bundle_path_digest": "sha256:0f9b84efc0f136468fbbeb29ddae1ea8e71748eb0aaac3196b95d792540bfd39",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-18T05:28:14.616000+00:00",
      "csv_description": "Infinidat InfiniBox Container Storage Interface (CSI) Driver is a CNCF-compliant Kubernetes integration for InfiniBox storage systems, offering advanced enterprise functionality for petabyte-scale Kubernetes deployments including Red Hat OpenShift.\n \n## Features and Benefits\n  \n* **Multi-protocol flexibility** - manage Kubernetes Persistent Volumes attached via block and file protocols, including Fibre Channel, iSCSI, and NFS, with all Kubernetes PV access modes\n* **Multi-petabyte scalability** - support hundreds of thousands of PVs per InfiniBox system and control multiple InfiniBox arrays within a single Kubernetes cluster  \n* **Advanced enterprise features** - manage native InfiniBox snapshots and clones, including restoring from snapshots, and import PVs created outside of InfiniBox CSI Driver\n  \n## Required Parameters\n  \n* `hostname` - IP address or hostname of the InfiniBox management interface\n* `username` / `password` - InfiniBox credentials\n* `SecretName` - secret name, to be used in the StorageClass to define a specific InfiniBox for persistent volumes\n\n## Optional Parameters\n* `inbound_user` / `inbound_secret` / `outbound_user` / `outbound_secret` - credentials for iSCSI CHAP authentication\n",
      "csv_display_name": "InfiniBox CSI Driver - Operator",
      "csv_metadata_description": "CNCF-compliant Kubernetes integration for Infinidat InfiniBox storage systems, offering advanced enterprise functionality for petabyte-scale Kubernetes deployments including Red Hat OpenShift Platform.",
      "csv_name": "infinibox-operator.v2.2.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:02:37.572000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "infinibox-operator-certified",
      "provided_apis": [
        {
          "group": "helm.infinidat.com",
          "kind": "InfiniboxCsiDriver",
          "version": "v1alpha1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshot",
          "version": "v1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshot",
          "version": "v1beta1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotClass",
          "version": "v1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotClass",
          "version": "v1beta1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotContent",
          "version": "v1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotContent",
          "version": "v1beta1"
        }
      ],
      "provider": "Infinidat",
      "related_images": [
        {
          "digest": "sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
          "image": "registry.connect.redhat.com/infinidat/infinibox-csidriver-certified@sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
          "name": "infinibox-csidriver-certified-1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be-annotation"
        },
        {
          "digest": "sha256:d99a8d144816b951a67648c12c0b988936ccd25cf3754f3cd85ab8c01592248f",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:d99a8d144816b951a67648c12c0b988936ccd25cf3754f3cd85ab8c01592248f",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:e2c7d7df9de11bd2f9ce1faf299a4f13891a0e1e83ebbdb5fcf22e62b40b6a2a",
          "image": "registry.connect.redhat.com/infinidat/infinibox-operator-certified@sha256:e2c7d7df9de11bd2f9ce1faf299a4f13891a0e1e83ebbdb5fcf22e62b40b6a2a",
          "name": "manager"
        },
        {
          "digest": "sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
          "image": "k8s.gcr.io/sig-storage/csi-snapshotter@sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
          "name": "csi-snapshotter-89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709-annotation"
        },
        {
          "digest": "sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
          "image": "k8s.gcr.io/sig-storage/csi-resizer@sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
          "name": "csi-resizer-9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4-annotation"
        },
        {
          "digest": "sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
          "image": "k8s.gcr.io/sig-storage/csi-node-driver-registrar@sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
          "name": "csi-node-driver-registrar-4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6-annotation"
        },
        {
          "digest": "sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
          "image": "k8s.gcr.io/sig-storage/csi-provisioner@sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
          "name": "csi-provisioner-122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119-annotation"
        },
        {
          "digest": "sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
          "image": "k8s.gcr.io/sig-storage/csi-attacher@sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
          "name": "csi-attacher-8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b-annotation"
        }
      ],
      "replaces": null,
      "skip_range": "<2.2.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2.2.0",
      "version_original": "2.2.0"
    },
    {
      "_id": "63771884d54d96b9ae5fe64d",
      "alm_examples": [
        {
          "api_version": "helm.infinidat.com/v1alpha1",
          "kind": "InfiniboxCsiDriver",
          "metadata": {
            "name": "infiniboxcsidriver-sample"
          },
          "spec": {
            "Infinibox_Cred": {
              "SecretName": "infinibox-creds",
              "hostname": "hostname",
              "inbound_secret": "0.0000000000000",
              "inbound_user": "iqn.2020-06.com.csi-driver-iscsi.infinidat:commonout",
              "outbound_secret": "0.0000000000000",
              "outbound_user": "iqn.2020-06.com.csi-driver-iscsi.infinidat:commonin",
              "password": "password",
              "username": "username"
            },
            "csiDriverName": "infinibox-csi-driver",
            "csiDriverVersion": "v2.2.0",
            "images": {
              "attachersidecar": "k8s.gcr.io/sig-storage/csi-attacher@sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
              "attachersidecar_pull_policy": "IfNotPresent",
              "csidriver": "registry.connect.redhat.com/infinidat/infinibox-csidriver-certified@sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
              "csidriver_pull_policy": "Always",
              "imagePullSecret": "private-docker-reg-secret",
              "provisionersidecar": "k8s.gcr.io/sig-storage/csi-provisioner@sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
              "provisionersidecar_pull_policy": "IfNotPresent",
              "registrarsidecar": "k8s.gcr.io/sig-storage/csi-node-driver-registrar@sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
              "registrarsidecar_pull_policy": "IfNotPresent",
              "resizersidecar": "k8s.gcr.io/sig-storage/csi-resizer@sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
              "resizersidecar_pull_policy": "IfNotPresent",
              "snapshottersidecar": "k8s.gcr.io/sig-storage/csi-snapshotter@sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
              "snapshottersidecar_pull_policy": "IfNotPresent"
            },
            "instanceCount": 1,
            "logLevel": "debug",
            "replicaCount": 1,
            "volumeNamePrefix": "csi"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/infinidat/infinibox-operator-certified-bundle@sha256:0f9b84efc0f136468fbbeb29ddae1ea8e71748eb0aaac3196b95d792540bfd39",
      "bundle_path_digest": "sha256:0f9b84efc0f136468fbbeb29ddae1ea8e71748eb0aaac3196b95d792540bfd39",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-18T05:30:44.169000+00:00",
      "csv_description": "Infinidat InfiniBox Container Storage Interface (CSI) Driver is a CNCF-compliant Kubernetes integration for InfiniBox storage systems, offering advanced enterprise functionality for petabyte-scale Kubernetes deployments including Red Hat OpenShift.\n \n## Features and Benefits\n  \n* **Multi-protocol flexibility** - manage Kubernetes Persistent Volumes attached via block and file protocols, including Fibre Channel, iSCSI, and NFS, with all Kubernetes PV access modes\n* **Multi-petabyte scalability** - support hundreds of thousands of PVs per InfiniBox system and control multiple InfiniBox arrays within a single Kubernetes cluster  \n* **Advanced enterprise features** - manage native InfiniBox snapshots and clones, including restoring from snapshots, and import PVs created outside of InfiniBox CSI Driver\n  \n## Required Parameters\n  \n* `hostname` - IP address or hostname of the InfiniBox management interface\n* `username` / `password` - InfiniBox credentials\n* `SecretName` - secret name, to be used in the StorageClass to define a specific InfiniBox for persistent volumes\n\n## Optional Parameters\n* `inbound_user` / `inbound_secret` / `outbound_user` / `outbound_secret` - credentials for iSCSI CHAP authentication\n",
      "csv_display_name": "InfiniBox CSI Driver - Operator",
      "csv_metadata_description": "CNCF-compliant Kubernetes integration for Infinidat InfiniBox storage systems, offering advanced enterprise functionality for petabyte-scale Kubernetes deployments including Red Hat OpenShift Platform.",
      "csv_name": "infinibox-operator.v2.2.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:35:08.388000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "infinibox-operator-certified",
      "provided_apis": [
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotContent",
          "plural": "volumesnapshotcontents",
          "version": "v1beta1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshot",
          "plural": "volumesnapshots",
          "version": "v1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshot",
          "plural": "volumesnapshots",
          "version": "v1beta1"
        },
        {
          "group": "helm.infinidat.com",
          "kind": "InfiniboxCsiDriver",
          "plural": "infiniboxcsidrivers",
          "version": "v1alpha1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotClass",
          "plural": "volumesnapshotclasses",
          "version": "v1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotClass",
          "plural": "volumesnapshotclasses",
          "version": "v1beta1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotContent",
          "plural": "volumesnapshotcontents",
          "version": "v1"
        }
      ],
      "provider": "Infinidat",
      "related_images": [
        {
          "digest": "sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
          "image": "registry.connect.redhat.com/infinidat/infinibox-csidriver-certified@sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
          "name": "infinibox-csidriver-certified-1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be-annotation"
        },
        {
          "digest": "sha256:d99a8d144816b951a67648c12c0b988936ccd25cf3754f3cd85ab8c01592248f",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:d99a8d144816b951a67648c12c0b988936ccd25cf3754f3cd85ab8c01592248f",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:e2c7d7df9de11bd2f9ce1faf299a4f13891a0e1e83ebbdb5fcf22e62b40b6a2a",
          "image": "registry.connect.redhat.com/infinidat/infinibox-operator-certified@sha256:e2c7d7df9de11bd2f9ce1faf299a4f13891a0e1e83ebbdb5fcf22e62b40b6a2a",
          "name": "manager"
        },
        {
          "digest": "sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
          "image": "k8s.gcr.io/sig-storage/csi-snapshotter@sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
          "name": "csi-snapshotter-89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709-annotation"
        },
        {
          "digest": "sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
          "image": "k8s.gcr.io/sig-storage/csi-resizer@sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
          "name": "csi-resizer-9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4-annotation"
        },
        {
          "digest": "sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
          "image": "k8s.gcr.io/sig-storage/csi-node-driver-registrar@sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
          "name": "csi-node-driver-registrar-4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6-annotation"
        },
        {
          "digest": "sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
          "image": "k8s.gcr.io/sig-storage/csi-provisioner@sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
          "name": "csi-provisioner-122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119-annotation"
        },
        {
          "digest": "sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
          "image": "k8s.gcr.io/sig-storage/csi-attacher@sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
          "name": "csi-attacher-8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b-annotation"
        }
      ],
      "replaces": null,
      "skip_range": "<2.2.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2.2.0",
      "version_original": "2.2.0"
    },
    {
      "_id": "637718845e3261eca76d6a83",
      "alm_examples": [
        {
          "api_version": "helm.infinidat.com/v1alpha1",
          "kind": "InfiniboxCsiDriver",
          "metadata": {
            "name": "infiniboxcsidriver-sample"
          },
          "spec": {
            "Infinibox_Cred": {
              "SecretName": "infinibox-creds",
              "hostname": "hostname",
              "inbound_secret": "0.0000000000000",
              "inbound_user": "iqn.2020-06.com.csi-driver-iscsi.infinidat:commonout",
              "outbound_secret": "0.0000000000000",
              "outbound_user": "iqn.2020-06.com.csi-driver-iscsi.infinidat:commonin",
              "password": "password",
              "username": "username"
            },
            "csiDriverName": "infinibox-csi-driver",
            "csiDriverVersion": "v2.2.0",
            "images": {
              "attachersidecar": "k8s.gcr.io/sig-storage/csi-attacher@sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
              "attachersidecar_pull_policy": "IfNotPresent",
              "csidriver": "registry.connect.redhat.com/infinidat/infinibox-csidriver-certified@sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
              "csidriver_pull_policy": "Always",
              "imagePullSecret": "private-docker-reg-secret",
              "provisionersidecar": "k8s.gcr.io/sig-storage/csi-provisioner@sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
              "provisionersidecar_pull_policy": "IfNotPresent",
              "registrarsidecar": "k8s.gcr.io/sig-storage/csi-node-driver-registrar@sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
              "registrarsidecar_pull_policy": "IfNotPresent",
              "resizersidecar": "k8s.gcr.io/sig-storage/csi-resizer@sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
              "resizersidecar_pull_policy": "IfNotPresent",
              "snapshottersidecar": "k8s.gcr.io/sig-storage/csi-snapshotter@sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
              "snapshottersidecar_pull_policy": "IfNotPresent"
            },
            "instanceCount": 1,
            "logLevel": "debug",
            "replicaCount": 1,
            "volumeNamePrefix": "csi"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/infinidat/infinibox-operator-certified-bundle@sha256:0f9b84efc0f136468fbbeb29ddae1ea8e71748eb0aaac3196b95d792540bfd39",
      "bundle_path_digest": "sha256:0f9b84efc0f136468fbbeb29ddae1ea8e71748eb0aaac3196b95d792540bfd39",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-11-18T05:30:44.718000+00:00",
      "csv_description": "Infinidat InfiniBox Container Storage Interface (CSI) Driver is a CNCF-compliant Kubernetes integration for InfiniBox storage systems, offering advanced enterprise functionality for petabyte-scale Kubernetes deployments including Red Hat OpenShift.\n \n## Features and Benefits\n  \n* **Multi-protocol flexibility** - manage Kubernetes Persistent Volumes attached via block and file protocols, including Fibre Channel, iSCSI, and NFS, with all Kubernetes PV access modes\n* **Multi-petabyte scalability** - support hundreds of thousands of PVs per InfiniBox system and control multiple InfiniBox arrays within a single Kubernetes cluster  \n* **Advanced enterprise features** - manage native InfiniBox snapshots and clones, including restoring from snapshots, and import PVs created outside of InfiniBox CSI Driver\n  \n## Required Parameters\n  \n* `hostname` - IP address or hostname of the InfiniBox management interface\n* `username` / `password` - InfiniBox credentials\n* `SecretName` - secret name, to be used in the StorageClass to define a specific InfiniBox for persistent volumes\n\n## Optional Parameters\n* `inbound_user` / `inbound_secret` / `outbound_user` / `outbound_secret` - credentials for iSCSI CHAP authentication\n",
      "csv_display_name": "InfiniBox CSI Driver - Operator",
      "csv_metadata_description": "CNCF-compliant Kubernetes integration for Infinidat InfiniBox storage systems, offering advanced enterprise functionality for petabyte-scale Kubernetes deployments including Red Hat OpenShift Platform.",
      "csv_name": "infinibox-operator.v2.2.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T07:34:25.470000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "infinibox-operator-certified",
      "provided_apis": [
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotContent",
          "plural": "volumesnapshotcontents",
          "version": "v1beta1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshot",
          "plural": "volumesnapshots",
          "version": "v1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshot",
          "plural": "volumesnapshots",
          "version": "v1beta1"
        },
        {
          "group": "helm.infinidat.com",
          "kind": "InfiniboxCsiDriver",
          "plural": "infiniboxcsidrivers",
          "version": "v1alpha1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotClass",
          "plural": "volumesnapshotclasses",
          "version": "v1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotClass",
          "plural": "volumesnapshotclasses",
          "version": "v1beta1"
        },
        {
          "group": "snapshot.storage.k8s.io",
          "kind": "VolumeSnapshotContent",
          "plural": "volumesnapshotcontents",
          "version": "v1"
        }
      ],
      "provider": "Infinidat",
      "related_images": [
        {
          "digest": "sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
          "image": "registry.connect.redhat.com/infinidat/infinibox-csidriver-certified@sha256:1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be",
          "name": "infinibox-csidriver-certified-1b1cdeb2b733811a2a33b761f01771ef2f5a41bede3fb1bcde01a42ec8f767be-annotation"
        },
        {
          "digest": "sha256:d99a8d144816b951a67648c12c0b988936ccd25cf3754f3cd85ab8c01592248f",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:d99a8d144816b951a67648c12c0b988936ccd25cf3754f3cd85ab8c01592248f",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:e2c7d7df9de11bd2f9ce1faf299a4f13891a0e1e83ebbdb5fcf22e62b40b6a2a",
          "image": "registry.connect.redhat.com/infinidat/infinibox-operator-certified@sha256:e2c7d7df9de11bd2f9ce1faf299a4f13891a0e1e83ebbdb5fcf22e62b40b6a2a",
          "name": "manager"
        },
        {
          "digest": "sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
          "image": "k8s.gcr.io/sig-storage/csi-snapshotter@sha256:89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709",
          "name": "csi-snapshotter-89e900a160a986a1a7a4eba7f5259e510398fa87ca9b8a729e7dec59e04c7709-annotation"
        },
        {
          "digest": "sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
          "image": "k8s.gcr.io/sig-storage/csi-resizer@sha256:9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4",
          "name": "csi-resizer-9ebbf9f023e7b41ccee3d52afe39a89e3ddacdbb69269d583abfc25847cfd9e4-annotation"
        },
        {
          "digest": "sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
          "image": "k8s.gcr.io/sig-storage/csi-node-driver-registrar@sha256:4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6",
          "name": "csi-node-driver-registrar-4fd21f36075b44d1a423dfb262ad79202ce54e95f5cbc4622a6c1c38ab287ad6-annotation"
        },
        {
          "digest": "sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
          "image": "k8s.gcr.io/sig-storage/csi-provisioner@sha256:122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119",
          "name": "csi-provisioner-122bfb8c1edabb3c0edd63f06523e6940d958d19b3957dc7b1d6f81e9f1f6119-annotation"
        },
        {
          "digest": "sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
          "image": "k8s.gcr.io/sig-storage/csi-attacher@sha256:8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b",
          "name": "csi-attacher-8b9c313c05f54fb04f8d430896f5f5904b6cb157df261501b29adc04d2b2dc7b-annotation"
        }
      ],
      "replaces": null,
      "skip_range": "<2.2.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2.2.0",
      "version_original": "2.2.0"
    },
    {
      "_id": "63784672313b3f8bdba9c64b",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:152dcb1fe813809287218c03126a4e73f945a0a824c88a9856f88a90b2347bde",
      "bundle_path_digest": "sha256:152dcb1fe813809287218c03126a4e73f945a0a824c88a9856f88a90b2347bde",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-19T02:58:58.383000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.7.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-12-05T22:27:06.541000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b",
          "name": "kubeturbo-operator-36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b-annotation"
        },
        {
          "digest": "sha256:36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:ea8828ce8dabf1d9435cb1e8cd53e30624afd026edef280a0abe08df62ac9b2b",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:ea8828ce8dabf1d9435cb1e8cd53e30624afd026edef280a0abe08df62ac9b2b",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "8.7.1",
      "version_original": "8.7.1"
    },
    {
      "_id": "63784679799f60c3015c49b9",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:152dcb1fe813809287218c03126a4e73f945a0a824c88a9856f88a90b2347bde",
      "bundle_path_digest": "sha256:152dcb1fe813809287218c03126a4e73f945a0a824c88a9856f88a90b2347bde",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-19T02:59:05.310000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.7.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-12-05T22:26:16.319000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b",
          "name": "kubeturbo-operator-36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b-annotation"
        },
        {
          "digest": "sha256:36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:ea8828ce8dabf1d9435cb1e8cd53e30624afd026edef280a0abe08df62ac9b2b",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:ea8828ce8dabf1d9435cb1e8cd53e30624afd026edef280a0abe08df62ac9b2b",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "8.7.1",
      "version_original": "8.7.1"
    },
    {
      "_id": "637846b09dc40044c5f88fa2",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:152dcb1fe813809287218c03126a4e73f945a0a824c88a9856f88a90b2347bde",
      "bundle_path_digest": "sha256:152dcb1fe813809287218c03126a4e73f945a0a824c88a9856f88a90b2347bde",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-19T03:00:00.432000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.7.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-12-05T22:18:48.456000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b",
          "name": "kubeturbo-operator-36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b-annotation"
        },
        {
          "digest": "sha256:36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:ea8828ce8dabf1d9435cb1e8cd53e30624afd026edef280a0abe08df62ac9b2b",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:ea8828ce8dabf1d9435cb1e8cd53e30624afd026edef280a0abe08df62ac9b2b",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "8.7.1",
      "version_original": "8.7.1"
    },
    {
      "_id": "637846c139c557788946f227",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:152dcb1fe813809287218c03126a4e73f945a0a824c88a9856f88a90b2347bde",
      "bundle_path_digest": "sha256:152dcb1fe813809287218c03126a4e73f945a0a824c88a9856f88a90b2347bde",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-19T03:00:17.244000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.7.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-12-05T22:18:27.631000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b",
          "name": "kubeturbo-operator-36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b-annotation"
        },
        {
          "digest": "sha256:36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:ea8828ce8dabf1d9435cb1e8cd53e30624afd026edef280a0abe08df62ac9b2b",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:ea8828ce8dabf1d9435cb1e8cd53e30624afd026edef280a0abe08df62ac9b2b",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "8.7.1",
      "version_original": "8.7.1"
    },
    {
      "_id": "637847945e3261eca76f32bf",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:152dcb1fe813809287218c03126a4e73f945a0a824c88a9856f88a90b2347bde",
      "bundle_path_digest": "sha256:152dcb1fe813809287218c03126a4e73f945a0a824c88a9856f88a90b2347bde",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-19T03:03:48.536000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.7.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-12-05T22:30:45.336000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b",
          "name": "kubeturbo-operator-36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b-annotation"
        },
        {
          "digest": "sha256:36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:36580f7955fe80a089196de606bdac6d6899644c93b0a45521326e74fe3e681b",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:ea8828ce8dabf1d9435cb1e8cd53e30624afd026edef280a0abe08df62ac9b2b",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:ea8828ce8dabf1d9435cb1e8cd53e30624afd026edef280a0abe08df62ac9b2b",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "8.7.1",
      "version_original": "8.7.1"
    },
    {
      "_id": "637baddb884420e0c6262855",
      "alm_examples": [
        {
          "api_version": "eginnovations.com/v1beta1",
          "kind": "EgUniversalAgent",
          "metadata": {
            "name": "eguniversalagent",
            "namespace": "egagent"
          },
          "spec": {
            "agent": {
              "env": [
                {
                  "name": "EG_MANAGER",
                  "value": "Replace with eG Manager IP"
                },
                {
                  "name": "EG_MANAGER_PORT",
                  "value": "Replace with eG Manager Port"
                }
              ]
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/eginnovations/universal-agent-operator@sha256:5337b477268e78c222f5dff2e313a2db7c88e8aff25311ba2ac21259940aa515",
      "bundle_path_digest": "sha256:5337b477268e78c222f5dff2e313a2db7c88e8aff25311ba2ac21259940aa515",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "beta",
      "creation_date": "2022-11-21T16:56:59.435000+00:00",
      "csv_description": "eG Innovations\u2019 converged application and infrastructure performance monitoring capabilities provide end-to-end visibility and correlated analytics for every layer, every tier of your IT landscape.\n\nThe eG Enterprise Universal Agent Operator automatically configures a host agent on every Kubernetes worker node. The host agent auto-discovers the worker nodes and application containers running as Pods on each node and tracks their performance and utilization levels. In-depth monitoring of applications running on containers is also provided using the same host agent. No additional agents are required for the containers.\n\n### Capabilities\n  * Rolls out the eg Agent pod per node to monitor its pods and the node itself\n  * Automatic BTM profiler injection using webhook based injection for deep application monitoring and transection tracing.\n\n### Installation\n  1. Create the namespace \"egagent\" for installing eG Agent on OpenShift Cluster.\n\n     <br />``` $ oc create ns egagent ```\n  2. Add \"egagent\" serviceaccount to scc( Security Context Constraints ) of OpenShift Cluster as privileged using below command.\n\n     <br />``` $ oc adm policy add-scc-to-user privileged -z egagent -n egagent ```\n  2. Install eG Innovations Universal Agent operator from [OpenShift Container Platform](https://www.openshift.com/) OperatorHub.\n  3. Create the eG Universal Agent CRD (Custom Resource Definition)\n     a. Click \"View YAML Example\" and copy the yaml contents and save it to (filename).yaml on your host.\n     b. To apply the CRD run the following command\n\n     <br />``` $ kubectl apply -f (filename).yaml ```\n\n### Required Parameters\n  * EG\\_MANAGER, EG\\_MANAGER\\_PORT - provide the ip and port of your eG Manager Installation.\n\n### Advanced Options\n  * Disable Certificate Checking - disable any certificate validation that may interact poorly with proxies within your cluster\n  * Image Override - use a copy of the eG Iniversal Agent container image from a registry other that Docker's or Red Hat's\n  * Environment variables - define environment variables for the eG Universal Agent container of for APM profiler.\n  * Namespace Selectors- select a subset of namesapces to enable instrumentation for applications.\n\nFor complete list of supported parameters and the detailed documentation available in [eG Innovations Docs](https://docs.eginnovations.com)\n",
      "csv_display_name": "eG Innovations Universal Agent Operator",
      "csv_metadata_description": "",
      "csv_name": "eginnovations-operator.v0.0.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T08:26:07.744000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "eginnovations-operator",
      "provided_apis": [
        {
          "group": "eginnovations.com",
          "kind": "EgUniversalAgent",
          "plural": "eguniversalagents",
          "version": "v1beta1"
        }
      ],
      "provider": "eG Innovations",
      "related_images": [
        {
          "digest": "sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "image": "docker.io/eginnovations/universal-agent-operator@sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "name": "eginnovations-operator"
        },
        {
          "digest": "sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "image": "docker.io/eginnovations/universal-agent-operator@sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "name": "universal-agent-operator-a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623-annotation"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "image": "docker.io/eginnovations/universal-agent-operator@sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "0.0.3",
      "version_original": "0.0.3"
    },
    {
      "_id": "637bae025f23340823ae615c",
      "alm_examples": [
        {
          "api_version": "eginnovations.com/v1beta1",
          "kind": "EgUniversalAgent",
          "metadata": {
            "name": "eguniversalagent",
            "namespace": "egagent"
          },
          "spec": {
            "agent": {
              "env": [
                {
                  "name": "EG_MANAGER",
                  "value": "Replace with eG Manager IP"
                },
                {
                  "name": "EG_MANAGER_PORT",
                  "value": "Replace with eG Manager Port"
                }
              ]
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/eginnovations/universal-agent-operator@sha256:5337b477268e78c222f5dff2e313a2db7c88e8aff25311ba2ac21259940aa515",
      "bundle_path_digest": "sha256:5337b477268e78c222f5dff2e313a2db7c88e8aff25311ba2ac21259940aa515",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "beta",
      "creation_date": "2022-11-21T16:57:37.996000+00:00",
      "csv_description": "eG Innovations\u2019 converged application and infrastructure performance monitoring capabilities provide end-to-end visibility and correlated analytics for every layer, every tier of your IT landscape.\n\nThe eG Enterprise Universal Agent Operator automatically configures a host agent on every Kubernetes worker node. The host agent auto-discovers the worker nodes and application containers running as Pods on each node and tracks their performance and utilization levels. In-depth monitoring of applications running on containers is also provided using the same host agent. No additional agents are required for the containers.\n\n### Capabilities\n  * Rolls out the eg Agent pod per node to monitor its pods and the node itself\n  * Automatic BTM profiler injection using webhook based injection for deep application monitoring and transection tracing.\n\n### Installation\n  1. Create the namespace \"egagent\" for installing eG Agent on OpenShift Cluster.\n\n     <br />``` $ oc create ns egagent ```\n  2. Add \"egagent\" serviceaccount to scc( Security Context Constraints ) of OpenShift Cluster as privileged using below command.\n\n     <br />``` $ oc adm policy add-scc-to-user privileged -z egagent -n egagent ```\n  2. Install eG Innovations Universal Agent operator from [OpenShift Container Platform](https://www.openshift.com/) OperatorHub.\n  3. Create the eG Universal Agent CRD (Custom Resource Definition)\n     a. Click \"View YAML Example\" and copy the yaml contents and save it to (filename).yaml on your host.\n     b. To apply the CRD run the following command\n\n     <br />``` $ kubectl apply -f (filename).yaml ```\n\n### Required Parameters\n  * EG\\_MANAGER, EG\\_MANAGER\\_PORT - provide the ip and port of your eG Manager Installation.\n\n### Advanced Options\n  * Disable Certificate Checking - disable any certificate validation that may interact poorly with proxies within your cluster\n  * Image Override - use a copy of the eG Iniversal Agent container image from a registry other that Docker's or Red Hat's\n  * Environment variables - define environment variables for the eG Universal Agent container of for APM profiler.\n  * Namespace Selectors- select a subset of namesapces to enable instrumentation for applications.\n\nFor complete list of supported parameters and the detailed documentation available in [eG Innovations Docs](https://docs.eginnovations.com)\n",
      "csv_display_name": "eG Innovations Universal Agent Operator",
      "csv_metadata_description": "",
      "csv_name": "eginnovations-operator.v0.0.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:11:09.693000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "eginnovations-operator",
      "provided_apis": [
        {
          "group": "eginnovations.com",
          "kind": "EgUniversalAgent",
          "plural": "eguniversalagents",
          "version": "v1beta1"
        }
      ],
      "provider": "eG Innovations",
      "related_images": [
        {
          "digest": "sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "image": "docker.io/eginnovations/universal-agent-operator@sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "name": "eginnovations-operator"
        },
        {
          "digest": "sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "image": "docker.io/eginnovations/universal-agent-operator@sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "name": "universal-agent-operator-a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623-annotation"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "image": "docker.io/eginnovations/universal-agent-operator@sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "0.0.3",
      "version_original": "0.0.3"
    },
    {
      "_id": "637bae515f23340823ae6262",
      "alm_examples": [
        {
          "api_version": "eginnovations.com/v1beta1",
          "kind": "EgUniversalAgent",
          "metadata": {
            "name": "eguniversalagent",
            "namespace": "egagent"
          },
          "spec": {
            "agent": {
              "env": [
                {
                  "name": "EG_MANAGER",
                  "value": "Replace with eG Manager IP"
                },
                {
                  "name": "EG_MANAGER_PORT",
                  "value": "Replace with eG Manager Port"
                }
              ]
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/eginnovations/universal-agent-operator@sha256:5337b477268e78c222f5dff2e313a2db7c88e8aff25311ba2ac21259940aa515",
      "bundle_path_digest": "sha256:5337b477268e78c222f5dff2e313a2db7c88e8aff25311ba2ac21259940aa515",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "beta",
      "creation_date": "2022-11-21T16:58:57.888000+00:00",
      "csv_description": "eG Innovations\u2019 converged application and infrastructure performance monitoring capabilities provide end-to-end visibility and correlated analytics for every layer, every tier of your IT landscape.\n\nThe eG Enterprise Universal Agent Operator automatically configures a host agent on every Kubernetes worker node. The host agent auto-discovers the worker nodes and application containers running as Pods on each node and tracks their performance and utilization levels. In-depth monitoring of applications running on containers is also provided using the same host agent. No additional agents are required for the containers.\n\n### Capabilities\n  * Rolls out the eg Agent pod per node to monitor its pods and the node itself\n  * Automatic BTM profiler injection using webhook based injection for deep application monitoring and transection tracing.\n\n### Installation\n  1. Create the namespace \"egagent\" for installing eG Agent on OpenShift Cluster.\n\n     <br />``` $ oc create ns egagent ```\n  2. Add \"egagent\" serviceaccount to scc( Security Context Constraints ) of OpenShift Cluster as privileged using below command.\n\n     <br />``` $ oc adm policy add-scc-to-user privileged -z egagent -n egagent ```\n  2. Install eG Innovations Universal Agent operator from [OpenShift Container Platform](https://www.openshift.com/) OperatorHub.\n  3. Create the eG Universal Agent CRD (Custom Resource Definition)\n     a. Click \"View YAML Example\" and copy the yaml contents and save it to (filename).yaml on your host.\n     b. To apply the CRD run the following command\n\n     <br />``` $ kubectl apply -f (filename).yaml ```\n\n### Required Parameters\n  * EG\\_MANAGER, EG\\_MANAGER\\_PORT - provide the ip and port of your eG Manager Installation.\n\n### Advanced Options\n  * Disable Certificate Checking - disable any certificate validation that may interact poorly with proxies within your cluster\n  * Image Override - use a copy of the eG Iniversal Agent container image from a registry other that Docker's or Red Hat's\n  * Environment variables - define environment variables for the eG Universal Agent container of for APM profiler.\n  * Namespace Selectors- select a subset of namesapces to enable instrumentation for applications.\n\nFor complete list of supported parameters and the detailed documentation available in [eG Innovations Docs](https://docs.eginnovations.com)\n",
      "csv_display_name": "eG Innovations Universal Agent Operator",
      "csv_metadata_description": "",
      "csv_name": "eginnovations-operator.v0.0.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T06:41:38.964000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "eginnovations-operator",
      "provided_apis": [
        {
          "group": "eginnovations.com",
          "kind": "EgUniversalAgent",
          "version": "v1beta1"
        }
      ],
      "provider": "eG Innovations",
      "related_images": [
        {
          "digest": "sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "image": "docker.io/eginnovations/universal-agent-operator@sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "name": "eginnovations-operator"
        },
        {
          "digest": "sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "image": "docker.io/eginnovations/universal-agent-operator@sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "name": "universal-agent-operator-a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623-annotation"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "image": "docker.io/eginnovations/universal-agent-operator@sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "0.0.3",
      "version_original": "0.0.3"
    },
    {
      "_id": "637baf045f23340823ae6422",
      "alm_examples": [
        {
          "api_version": "eginnovations.com/v1beta1",
          "kind": "EgUniversalAgent",
          "metadata": {
            "name": "eguniversalagent",
            "namespace": "egagent"
          },
          "spec": {
            "agent": {
              "env": [
                {
                  "name": "EG_MANAGER",
                  "value": "Replace with eG Manager IP"
                },
                {
                  "name": "EG_MANAGER_PORT",
                  "value": "Replace with eG Manager Port"
                }
              ]
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/eginnovations/universal-agent-operator@sha256:5337b477268e78c222f5dff2e313a2db7c88e8aff25311ba2ac21259940aa515",
      "bundle_path_digest": "sha256:5337b477268e78c222f5dff2e313a2db7c88e8aff25311ba2ac21259940aa515",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "beta",
      "creation_date": "2022-11-21T17:01:56.062000+00:00",
      "csv_description": "eG Innovations\u2019 converged application and infrastructure performance monitoring capabilities provide end-to-end visibility and correlated analytics for every layer, every tier of your IT landscape.\n\nThe eG Enterprise Universal Agent Operator automatically configures a host agent on every Kubernetes worker node. The host agent auto-discovers the worker nodes and application containers running as Pods on each node and tracks their performance and utilization levels. In-depth monitoring of applications running on containers is also provided using the same host agent. No additional agents are required for the containers.\n\n### Capabilities\n  * Rolls out the eg Agent pod per node to monitor its pods and the node itself\n  * Automatic BTM profiler injection using webhook based injection for deep application monitoring and transection tracing.\n\n### Installation\n  1. Create the namespace \"egagent\" for installing eG Agent on OpenShift Cluster.\n\n     <br />``` $ oc create ns egagent ```\n  2. Add \"egagent\" serviceaccount to scc( Security Context Constraints ) of OpenShift Cluster as privileged using below command.\n\n     <br />``` $ oc adm policy add-scc-to-user privileged -z egagent -n egagent ```\n  2. Install eG Innovations Universal Agent operator from [OpenShift Container Platform](https://www.openshift.com/) OperatorHub.\n  3. Create the eG Universal Agent CRD (Custom Resource Definition)\n     a. Click \"View YAML Example\" and copy the yaml contents and save it to (filename).yaml on your host.\n     b. To apply the CRD run the following command\n\n     <br />``` $ kubectl apply -f (filename).yaml ```\n\n### Required Parameters\n  * EG\\_MANAGER, EG\\_MANAGER\\_PORT - provide the ip and port of your eG Manager Installation.\n\n### Advanced Options\n  * Disable Certificate Checking - disable any certificate validation that may interact poorly with proxies within your cluster\n  * Image Override - use a copy of the eG Iniversal Agent container image from a registry other that Docker's or Red Hat's\n  * Environment variables - define environment variables for the eG Universal Agent container of for APM profiler.\n  * Namespace Selectors- select a subset of namesapces to enable instrumentation for applications.\n\nFor complete list of supported parameters and the detailed documentation available in [eG Innovations Docs](https://docs.eginnovations.com)\n",
      "csv_display_name": "eG Innovations Universal Agent Operator",
      "csv_metadata_description": "",
      "csv_name": "eginnovations-operator.v0.0.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:40:43.331000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "eginnovations-operator",
      "provided_apis": [
        {
          "group": "eginnovations.com",
          "kind": "EgUniversalAgent",
          "plural": "eguniversalagents",
          "version": "v1beta1"
        }
      ],
      "provider": "eG Innovations",
      "related_images": [
        {
          "digest": "sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "image": "docker.io/eginnovations/universal-agent-operator@sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "name": "eginnovations-operator"
        },
        {
          "digest": "sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "image": "docker.io/eginnovations/universal-agent-operator@sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "name": "universal-agent-operator-a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623-annotation"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "image": "docker.io/eginnovations/universal-agent-operator@sha256:a624f4cd7930a688164dc2589733614c89c2e760da4ae0ee3eb6a0eb612ce623",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "0.0.3",
      "version_original": "0.0.3"
    },
    {
      "_id": "637c45665cd405bde9e21606",
      "alm_examples": [
        {
          "api_version": "apps.cloudcasa.io/v1",
          "kind": "Cloudcasa",
          "metadata": {
            "name": "cloudcasa"
          },
          "spec": {
            "cluster_id": ""
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/catalogicsoftware/cloudcasa-bundle@sha256:a4737548ece2ea96d79f3d9f6ffbe726cc737b95cd1cfadf1b631933e5f3857e",
      "bundle_path_digest": "sha256:a4737548ece2ea96d79f3d9f6ffbe726cc737b95cd1cfadf1b631933e5f3857e",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-11-22T03:43:34.311000+00:00",
      "csv_description": "CloudCasa is a powerful and easy-to-use data protection service for Kubernetes and cloud databases.  Configuration is quick and easy, and basic service is free. \n\n\n### How to Install \n* Create Namespace cloudcasa-operator. \n* Install the CloudCasa Operator by following the instructions presented when you click the Install button. Select **cloudcasa-operator** namespace. \n* After installing the operator, you will need to create an instance of the CloudCasa resource to configure the agent. \n* In order to create the CloudCasa resource you will need to generate a Cluster ID in CloudCasa.\n* Login to https://home.cloudcasa.io and add your OCP cluster under the Protection tab. Note the returned **Cluster ID**.\n* See the CloudCasa [Getting Started Guide](https://cloudcasa.io/get-started) for more information.\n* Navigate to the installed CloudCasa Operator and Click on the CloudCasa tab.\n* Create the CloudCasa resource and provide the **Cluster ID** noted in the previous step.\n\n\n### Supported Features\n\n* **AWS RDS Backup**\n\n* **Kubernetes cluster Backup** \n\n* **Kubernetes cluster restore**\n\n### Installation Checkpoints\n\n* **cloudcasa-io** namespace should be created.\n\n* **kubagent** pod should be created under **cloudcasa-io** namespace and should be in **running state.** \n\n* State of the OCP cluster on CloudCasa web UI should be **Active**.",
      "csv_display_name": "CloudCasa",
      "csv_metadata_description": "CloudCasa is a powerful and easy-to-use data protection service for Kubernetes and cloud databases.",
      "csv_name": "cloudcasa-operator.v3.2.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T08:23:38.902000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "cloudcasa-operator",
      "provided_apis": [
        {
          "group": "apps.cloudcasa.io",
          "kind": "Cloudcasa",
          "plural": "cloudcasas",
          "version": "v1"
        }
      ],
      "provider": "catalogic Software",
      "related_images": [
        {
          "digest": "sha256:4c13b5f5826ca64f4c9f397515f34cfe51f817f76bc7efcdbaef379b43cd1448",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:4c13b5f5826ca64f4c9f397515f34cfe51f817f76bc7efcdbaef379b43cd1448",
          "name": "ose-kube-rbac-proxy"
        },
        {
          "digest": "sha256:9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154",
          "image": "registry.connect.redhat.com/catalogicsoftware/cloudcasa-operator@sha256:9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154",
          "name": "cloudcasa-operator"
        },
        {
          "digest": "sha256:4c13b5f5826ca64f4c9f397515f34cfe51f817f76bc7efcdbaef379b43cd1448",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:4c13b5f5826ca64f4c9f397515f34cfe51f817f76bc7efcdbaef379b43cd1448",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154",
          "image": "registry.connect.redhat.com/catalogicsoftware/cloudcasa-operator@sha256:9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154",
          "name": "cloudcasa-operator-9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154-annotation"
        },
        {
          "digest": "sha256:9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154",
          "image": "registry.connect.redhat.com/catalogicsoftware/cloudcasa-operator@sha256:9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "3.2.0",
      "version_original": "3.2.0"
    },
    {
      "_id": "637c459374e9f4cddfbcd697",
      "alm_examples": [
        {
          "api_version": "apps.cloudcasa.io/v1",
          "kind": "Cloudcasa",
          "metadata": {
            "name": "cloudcasa"
          },
          "spec": {
            "cluster_id": ""
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/catalogicsoftware/cloudcasa-bundle@sha256:a4737548ece2ea96d79f3d9f6ffbe726cc737b95cd1cfadf1b631933e5f3857e",
      "bundle_path_digest": "sha256:a4737548ece2ea96d79f3d9f6ffbe726cc737b95cd1cfadf1b631933e5f3857e",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-11-22T03:44:19.042000+00:00",
      "csv_description": "CloudCasa is a powerful and easy-to-use data protection service for Kubernetes and cloud databases.  Configuration is quick and easy, and basic service is free. \n\n\n### How to Install \n* Create Namespace cloudcasa-operator. \n* Install the CloudCasa Operator by following the instructions presented when you click the Install button. Select **cloudcasa-operator** namespace. \n* After installing the operator, you will need to create an instance of the CloudCasa resource to configure the agent. \n* In order to create the CloudCasa resource you will need to generate a Cluster ID in CloudCasa.\n* Login to https://home.cloudcasa.io and add your OCP cluster under the Protection tab. Note the returned **Cluster ID**.\n* See the CloudCasa [Getting Started Guide](https://cloudcasa.io/get-started) for more information.\n* Navigate to the installed CloudCasa Operator and Click on the CloudCasa tab.\n* Create the CloudCasa resource and provide the **Cluster ID** noted in the previous step.\n\n\n### Supported Features\n\n* **AWS RDS Backup**\n\n* **Kubernetes cluster Backup** \n\n* **Kubernetes cluster restore**\n\n### Installation Checkpoints\n\n* **cloudcasa-io** namespace should be created.\n\n* **kubagent** pod should be created under **cloudcasa-io** namespace and should be in **running state.** \n\n* State of the OCP cluster on CloudCasa web UI should be **Active**.",
      "csv_display_name": "CloudCasa",
      "csv_metadata_description": "CloudCasa is a powerful and easy-to-use data protection service for Kubernetes and cloud databases.",
      "csv_name": "cloudcasa-operator.v3.2.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:08:17.963000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "cloudcasa-operator",
      "provided_apis": [
        {
          "group": "apps.cloudcasa.io",
          "kind": "Cloudcasa",
          "plural": "cloudcasas",
          "version": "v1"
        }
      ],
      "provider": "catalogic Software",
      "related_images": [
        {
          "digest": "sha256:4c13b5f5826ca64f4c9f397515f34cfe51f817f76bc7efcdbaef379b43cd1448",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:4c13b5f5826ca64f4c9f397515f34cfe51f817f76bc7efcdbaef379b43cd1448",
          "name": "ose-kube-rbac-proxy"
        },
        {
          "digest": "sha256:9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154",
          "image": "registry.connect.redhat.com/catalogicsoftware/cloudcasa-operator@sha256:9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154",
          "name": "cloudcasa-operator"
        },
        {
          "digest": "sha256:4c13b5f5826ca64f4c9f397515f34cfe51f817f76bc7efcdbaef379b43cd1448",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:4c13b5f5826ca64f4c9f397515f34cfe51f817f76bc7efcdbaef379b43cd1448",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154",
          "image": "registry.connect.redhat.com/catalogicsoftware/cloudcasa-operator@sha256:9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154",
          "name": "cloudcasa-operator-9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154-annotation"
        },
        {
          "digest": "sha256:9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154",
          "image": "registry.connect.redhat.com/catalogicsoftware/cloudcasa-operator@sha256:9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "3.2.0",
      "version_original": "3.2.0"
    },
    {
      "_id": "637c4687884420e0c6280cf2",
      "alm_examples": [
        {
          "api_version": "apps.cloudcasa.io/v1",
          "kind": "Cloudcasa",
          "metadata": {
            "name": "cloudcasa"
          },
          "spec": {
            "cluster_id": ""
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/catalogicsoftware/cloudcasa-bundle@sha256:a4737548ece2ea96d79f3d9f6ffbe726cc737b95cd1cfadf1b631933e5f3857e",
      "bundle_path_digest": "sha256:a4737548ece2ea96d79f3d9f6ffbe726cc737b95cd1cfadf1b631933e5f3857e",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-11-22T03:48:23.785000+00:00",
      "csv_description": "CloudCasa is a powerful and easy-to-use data protection service for Kubernetes and cloud databases.  Configuration is quick and easy, and basic service is free. \n\n\n### How to Install \n* Create Namespace cloudcasa-operator. \n* Install the CloudCasa Operator by following the instructions presented when you click the Install button. Select **cloudcasa-operator** namespace. \n* After installing the operator, you will need to create an instance of the CloudCasa resource to configure the agent. \n* In order to create the CloudCasa resource you will need to generate a Cluster ID in CloudCasa.\n* Login to https://home.cloudcasa.io and add your OCP cluster under the Protection tab. Note the returned **Cluster ID**.\n* See the CloudCasa [Getting Started Guide](https://cloudcasa.io/get-started) for more information.\n* Navigate to the installed CloudCasa Operator and Click on the CloudCasa tab.\n* Create the CloudCasa resource and provide the **Cluster ID** noted in the previous step.\n\n\n### Supported Features\n\n* **AWS RDS Backup**\n\n* **Kubernetes cluster Backup** \n\n* **Kubernetes cluster restore**\n\n### Installation Checkpoints\n\n* **cloudcasa-io** namespace should be created.\n\n* **kubagent** pod should be created under **cloudcasa-io** namespace and should be in **running state.** \n\n* State of the OCP cluster on CloudCasa web UI should be **Active**.",
      "csv_display_name": "CloudCasa",
      "csv_metadata_description": "CloudCasa is a powerful and easy-to-use data protection service for Kubernetes and cloud databases.",
      "csv_name": "cloudcasa-operator.v3.2.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:32:28.050000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "cloudcasa-operator",
      "provided_apis": [
        {
          "group": "apps.cloudcasa.io",
          "kind": "Cloudcasa",
          "plural": "cloudcasas",
          "version": "v1"
        }
      ],
      "provider": "catalogic Software",
      "related_images": [
        {
          "digest": "sha256:4c13b5f5826ca64f4c9f397515f34cfe51f817f76bc7efcdbaef379b43cd1448",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:4c13b5f5826ca64f4c9f397515f34cfe51f817f76bc7efcdbaef379b43cd1448",
          "name": "ose-kube-rbac-proxy"
        },
        {
          "digest": "sha256:9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154",
          "image": "registry.connect.redhat.com/catalogicsoftware/cloudcasa-operator@sha256:9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154",
          "name": "cloudcasa-operator"
        },
        {
          "digest": "sha256:4c13b5f5826ca64f4c9f397515f34cfe51f817f76bc7efcdbaef379b43cd1448",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:4c13b5f5826ca64f4c9f397515f34cfe51f817f76bc7efcdbaef379b43cd1448",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154",
          "image": "registry.connect.redhat.com/catalogicsoftware/cloudcasa-operator@sha256:9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154",
          "name": "cloudcasa-operator-9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154-annotation"
        },
        {
          "digest": "sha256:9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154",
          "image": "registry.connect.redhat.com/catalogicsoftware/cloudcasa-operator@sha256:9fbd17771eb18cf01eeeb7c9b3d7a15baf44932a92ab820b1c79422303aa1154",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "3.2.0",
      "version_original": "3.2.0"
    },
    {
      "_id": "637c848074e9f4cddfbdb013",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Prometurbo",
          "metadata": {
            "name": "prometurbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/prometurbo-operator-bundle@sha256:c09160ea899afd273d1baf6e9e41c01de79d20e7d0253b040ad581e2fd217f20",
      "bundle_path_digest": "sha256:c09160ea899afd273d1baf6e9e41c01de79d20e7d0253b040ad581e2fd217f20",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-22T08:12:48.470000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 PromeTurbo \u2014 that runs next to your Prometheus sever, which monitors your environment.\nPromeTurbo sends application and infrastructure monitoring data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Prometurbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "prometurbo-operator.v8.7.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-12-06T09:38:32.762000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "prometurbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Prometurbo",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Prometurbo",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2",
          "image": "registry.connect.redhat.com/turbonomic/prometurbo-operator@sha256:24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2",
          "name": "prometurbo-operator-24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2-annotation"
        },
        {
          "digest": "sha256:24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2",
          "image": "registry.connect.redhat.com/turbonomic/prometurbo-operator@sha256:24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2",
          "name": "prometurbo-operator"
        },
        {
          "digest": "sha256:4414946bd244559f663d53d7bb6a9a7b43b2de61c721b8bd1989320fac897a4a",
          "image": "registry.connect.redhat.com/turbonomic/prometurbo@sha256:4414946bd244559f663d53d7bb6a9a7b43b2de61c721b8bd1989320fac897a4a",
          "name": "prometurbo"
        },
        {
          "digest": "sha256:10cc0df99aea13f58eed3bd42106c37aa2e7b3e4129f27b3abeb23d842d31a9e",
          "image": "registry.connect.redhat.com/turbonomic/turbodif@sha256:10cc0df99aea13f58eed3bd42106c37aa2e7b3e4129f27b3abeb23d842d31a9e",
          "name": "turbodif"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "8.7.1",
      "version_original": "8.7.1"
    },
    {
      "_id": "637c84a974e9f4cddfbdb068",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Prometurbo",
          "metadata": {
            "name": "prometurbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/prometurbo-operator-bundle@sha256:c09160ea899afd273d1baf6e9e41c01de79d20e7d0253b040ad581e2fd217f20",
      "bundle_path_digest": "sha256:c09160ea899afd273d1baf6e9e41c01de79d20e7d0253b040ad581e2fd217f20",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-22T08:13:29.285000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 PromeTurbo \u2014 that runs next to your Prometheus sever, which monitors your environment.\nPromeTurbo sends application and infrastructure monitoring data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Prometurbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "prometurbo-operator.v8.7.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-12-06T09:40:17.064000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "prometurbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Prometurbo",
          "plural": "prometurbos",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Prometurbo",
          "plural": "prometurbos",
          "version": "v1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2",
          "image": "registry.connect.redhat.com/turbonomic/prometurbo-operator@sha256:24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2",
          "name": "prometurbo-operator-24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2-annotation"
        },
        {
          "digest": "sha256:24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2",
          "image": "registry.connect.redhat.com/turbonomic/prometurbo-operator@sha256:24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2",
          "name": "prometurbo-operator"
        },
        {
          "digest": "sha256:4414946bd244559f663d53d7bb6a9a7b43b2de61c721b8bd1989320fac897a4a",
          "image": "registry.connect.redhat.com/turbonomic/prometurbo@sha256:4414946bd244559f663d53d7bb6a9a7b43b2de61c721b8bd1989320fac897a4a",
          "name": "prometurbo"
        },
        {
          "digest": "sha256:10cc0df99aea13f58eed3bd42106c37aa2e7b3e4129f27b3abeb23d842d31a9e",
          "image": "registry.connect.redhat.com/turbonomic/turbodif@sha256:10cc0df99aea13f58eed3bd42106c37aa2e7b3e4129f27b3abeb23d842d31a9e",
          "name": "turbodif"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "8.7.1",
      "version_original": "8.7.1"
    },
    {
      "_id": "637c84c2829a0217f0be5649",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Prometurbo",
          "metadata": {
            "name": "prometurbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/prometurbo-operator-bundle@sha256:c09160ea899afd273d1baf6e9e41c01de79d20e7d0253b040ad581e2fd217f20",
      "bundle_path_digest": "sha256:c09160ea899afd273d1baf6e9e41c01de79d20e7d0253b040ad581e2fd217f20",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-22T08:13:54.377000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 PromeTurbo \u2014 that runs next to your Prometheus sever, which monitors your environment.\nPromeTurbo sends application and infrastructure monitoring data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Prometurbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "prometurbo-operator.v8.7.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-12-06T09:40:37.998000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "prometurbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Prometurbo",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Prometurbo",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2",
          "image": "registry.connect.redhat.com/turbonomic/prometurbo-operator@sha256:24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2",
          "name": "prometurbo-operator-24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2-annotation"
        },
        {
          "digest": "sha256:24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2",
          "image": "registry.connect.redhat.com/turbonomic/prometurbo-operator@sha256:24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2",
          "name": "prometurbo-operator"
        },
        {
          "digest": "sha256:4414946bd244559f663d53d7bb6a9a7b43b2de61c721b8bd1989320fac897a4a",
          "image": "registry.connect.redhat.com/turbonomic/prometurbo@sha256:4414946bd244559f663d53d7bb6a9a7b43b2de61c721b8bd1989320fac897a4a",
          "name": "prometurbo"
        },
        {
          "digest": "sha256:10cc0df99aea13f58eed3bd42106c37aa2e7b3e4129f27b3abeb23d842d31a9e",
          "image": "registry.connect.redhat.com/turbonomic/turbodif@sha256:10cc0df99aea13f58eed3bd42106c37aa2e7b3e4129f27b3abeb23d842d31a9e",
          "name": "turbodif"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "8.7.1",
      "version_original": "8.7.1"
    },
    {
      "_id": "637c84d140d971f54488ffde",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Prometurbo",
          "metadata": {
            "name": "prometurbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/prometurbo-operator-bundle@sha256:c09160ea899afd273d1baf6e9e41c01de79d20e7d0253b040ad581e2fd217f20",
      "bundle_path_digest": "sha256:c09160ea899afd273d1baf6e9e41c01de79d20e7d0253b040ad581e2fd217f20",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-22T08:14:09.736000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 PromeTurbo \u2014 that runs next to your Prometheus sever, which monitors your environment.\nPromeTurbo sends application and infrastructure monitoring data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Prometurbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "prometurbo-operator.v8.7.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-12-06T09:40:35.706000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "prometurbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Prometurbo",
          "plural": "prometurbos",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Prometurbo",
          "plural": "prometurbos",
          "version": "v1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2",
          "image": "registry.connect.redhat.com/turbonomic/prometurbo-operator@sha256:24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2",
          "name": "prometurbo-operator-24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2-annotation"
        },
        {
          "digest": "sha256:24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2",
          "image": "registry.connect.redhat.com/turbonomic/prometurbo-operator@sha256:24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2",
          "name": "prometurbo-operator"
        },
        {
          "digest": "sha256:4414946bd244559f663d53d7bb6a9a7b43b2de61c721b8bd1989320fac897a4a",
          "image": "registry.connect.redhat.com/turbonomic/prometurbo@sha256:4414946bd244559f663d53d7bb6a9a7b43b2de61c721b8bd1989320fac897a4a",
          "name": "prometurbo"
        },
        {
          "digest": "sha256:10cc0df99aea13f58eed3bd42106c37aa2e7b3e4129f27b3abeb23d842d31a9e",
          "image": "registry.connect.redhat.com/turbonomic/turbodif@sha256:10cc0df99aea13f58eed3bd42106c37aa2e7b3e4129f27b3abeb23d842d31a9e",
          "name": "turbodif"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "8.7.1",
      "version_original": "8.7.1"
    },
    {
      "_id": "637c85bf829a0217f0be583b",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Prometurbo",
          "metadata": {
            "name": "prometurbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/prometurbo-operator-bundle@sha256:c09160ea899afd273d1baf6e9e41c01de79d20e7d0253b040ad581e2fd217f20",
      "bundle_path_digest": "sha256:c09160ea899afd273d1baf6e9e41c01de79d20e7d0253b040ad581e2fd217f20",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-22T08:18:07.826000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 PromeTurbo \u2014 that runs next to your Prometheus sever, which monitors your environment.\nPromeTurbo sends application and infrastructure monitoring data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Prometurbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "prometurbo-operator.v8.7.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-12-06T09:43:37.352000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "prometurbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Prometurbo",
          "plural": "prometurbos",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Prometurbo",
          "plural": "prometurbos",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2",
          "image": "registry.connect.redhat.com/turbonomic/prometurbo-operator@sha256:24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2",
          "name": "prometurbo-operator-24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2-annotation"
        },
        {
          "digest": "sha256:24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2",
          "image": "registry.connect.redhat.com/turbonomic/prometurbo-operator@sha256:24f7df3375484ccdb779fd6f9efaaf38a9448f627781f4aa1b16514e044d6de2",
          "name": "prometurbo-operator"
        },
        {
          "digest": "sha256:4414946bd244559f663d53d7bb6a9a7b43b2de61c721b8bd1989320fac897a4a",
          "image": "registry.connect.redhat.com/turbonomic/prometurbo@sha256:4414946bd244559f663d53d7bb6a9a7b43b2de61c721b8bd1989320fac897a4a",
          "name": "prometurbo"
        },
        {
          "digest": "sha256:10cc0df99aea13f58eed3bd42106c37aa2e7b3e4129f27b3abeb23d842d31a9e",
          "image": "registry.connect.redhat.com/turbonomic/turbodif@sha256:10cc0df99aea13f58eed3bd42106c37aa2e7b3e4129f27b3abeb23d842d31a9e",
          "name": "turbodif"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "8.7.1",
      "version_original": "8.7.1"
    },
    {
      "_id": "637ca3ba788768d1d6f164b2",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true,
                    "manageAutoAttachWebhook": true,
                    "webhookEnabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "limits": {
                    "cpu": "2",
                    "memory": "4096Mi"
                  },
                  "port": 8085,
                  "requests": {
                    "cpu": "500m",
                    "memory": "500Mi"
                  }
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              }
            },
            "prefix": "k8s",
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "bundle_path_digest": "sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-11-22T10:26:02.620000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for OpenShift acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for OpenShift discovers and monitors all the containers on a host. This capability allows to monitor both the Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure.\n\nFor more information:\nhttps://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Install-UMA-for-OpenShift.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n\n   role: common\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n           webhookEnabled: true\n           manageAutoAttachWebhook: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         # The below properties define the resources for 'apmia-http-collector' deployment.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"4096Mi\"\n         requests:\n           cpu: \"500m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"500Mi\"\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.11.1-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T06:39:12.116000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "plural": "universalmonitoringagents",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator-5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713-annotation"
        },
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "2022.11.1-11",
      "version_original": "2022.11.1-11"
    },
    {
      "_id": "637ca3bf5f23340823b18a5e",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true,
                    "manageAutoAttachWebhook": true,
                    "webhookEnabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "limits": {
                    "cpu": "2",
                    "memory": "4096Mi"
                  },
                  "port": 8085,
                  "requests": {
                    "cpu": "500m",
                    "memory": "500Mi"
                  }
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              }
            },
            "prefix": "k8s",
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "bundle_path_digest": "sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "beta",
      "creation_date": "2022-11-22T10:26:07.069000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for OpenShift acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for OpenShift discovers and monitors all the containers on a host. This capability allows to monitor both the Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure.\n\nFor more information:\nhttps://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Install-UMA-for-OpenShift.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n\n   role: common\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n           webhookEnabled: true\n           manageAutoAttachWebhook: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         # The below properties define the resources for 'apmia-http-collector' deployment.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"4096Mi\"\n         requests:\n           cpu: \"500m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"500Mi\"\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.11.1-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T06:39:18.387000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "plural": "universalmonitoringagents",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator-5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713-annotation"
        },
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "2022.11.1-11",
      "version_original": "2022.11.1-11"
    },
    {
      "_id": "637ca3c45f23340823b18a77",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true,
                    "manageAutoAttachWebhook": true,
                    "webhookEnabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "limits": {
                    "cpu": "2",
                    "memory": "4096Mi"
                  },
                  "port": 8085,
                  "requests": {
                    "cpu": "500m",
                    "memory": "500Mi"
                  }
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              }
            },
            "prefix": "k8s",
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "bundle_path_digest": "sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-22T10:26:12.351000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for OpenShift acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for OpenShift discovers and monitors all the containers on a host. This capability allows to monitor both the Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure.\n\nFor more information:\nhttps://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Install-UMA-for-OpenShift.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n\n   role: common\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n           webhookEnabled: true\n           manageAutoAttachWebhook: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         # The below properties define the resources for 'apmia-http-collector' deployment.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"4096Mi\"\n         requests:\n           cpu: \"500m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"500Mi\"\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.11.1-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T06:39:25.089000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "plural": "universalmonitoringagents",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator-5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713-annotation"
        },
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "2022.11.1-11",
      "version_original": "2022.11.1-11"
    },
    {
      "_id": "637ca3e574e9f4cddfbe1e70",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true,
                    "manageAutoAttachWebhook": true,
                    "webhookEnabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "limits": {
                    "cpu": "2",
                    "memory": "4096Mi"
                  },
                  "port": 8085,
                  "requests": {
                    "cpu": "500m",
                    "memory": "500Mi"
                  }
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              }
            },
            "prefix": "k8s",
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "bundle_path_digest": "sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-11-22T10:26:45.886000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for OpenShift acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for OpenShift discovers and monitors all the containers on a host. This capability allows to monitor both the Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure.\n\nFor more information:\nhttps://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Install-UMA-for-OpenShift.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n\n   role: common\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n           webhookEnabled: true\n           manageAutoAttachWebhook: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         # The below properties define the resources for 'apmia-http-collector' deployment.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"4096Mi\"\n         requests:\n           cpu: \"500m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"500Mi\"\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.11.1-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T07:30:32.945000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "plural": "universalmonitoringagents",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator-5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713-annotation"
        },
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2022.11.1-11",
      "version_original": "2022.11.1-11"
    },
    {
      "_id": "637ca3e7884420e0c629516a",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true,
                    "manageAutoAttachWebhook": true,
                    "webhookEnabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "limits": {
                    "cpu": "2",
                    "memory": "4096Mi"
                  },
                  "port": 8085,
                  "requests": {
                    "cpu": "500m",
                    "memory": "500Mi"
                  }
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              }
            },
            "prefix": "k8s",
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "bundle_path_digest": "sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "beta",
      "creation_date": "2022-11-22T10:26:47.966000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for OpenShift acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for OpenShift discovers and monitors all the containers on a host. This capability allows to monitor both the Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure.\n\nFor more information:\nhttps://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Install-UMA-for-OpenShift.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n\n   role: common\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n           webhookEnabled: true\n           manageAutoAttachWebhook: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         # The below properties define the resources for 'apmia-http-collector' deployment.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"4096Mi\"\n         requests:\n           cpu: \"500m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"500Mi\"\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.11.1-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T07:30:34.405000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "plural": "universalmonitoringagents",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator-5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713-annotation"
        },
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2022.11.1-11",
      "version_original": "2022.11.1-11"
    },
    {
      "_id": "637ca3eb788768d1d6f16591",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true,
                    "manageAutoAttachWebhook": true,
                    "webhookEnabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "limits": {
                    "cpu": "2",
                    "memory": "4096Mi"
                  },
                  "port": 8085,
                  "requests": {
                    "cpu": "500m",
                    "memory": "500Mi"
                  }
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              }
            },
            "prefix": "k8s",
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "bundle_path_digest": "sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-22T10:26:51.316000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for OpenShift acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for OpenShift discovers and monitors all the containers on a host. This capability allows to monitor both the Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure.\n\nFor more information:\nhttps://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Install-UMA-for-OpenShift.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n\n   role: common\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n           webhookEnabled: true\n           manageAutoAttachWebhook: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         # The below properties define the resources for 'apmia-http-collector' deployment.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"4096Mi\"\n         requests:\n           cpu: \"500m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"500Mi\"\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.11.1-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:30:37.497000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "plural": "universalmonitoringagents",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator-5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713-annotation"
        },
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2022.11.1-11",
      "version_original": "2022.11.1-11"
    },
    {
      "_id": "637ca43874e9f4cddfbe1f64",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true,
                    "manageAutoAttachWebhook": true,
                    "webhookEnabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "limits": {
                    "cpu": "2",
                    "memory": "4096Mi"
                  },
                  "port": 8085,
                  "requests": {
                    "cpu": "500m",
                    "memory": "500Mi"
                  }
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              }
            },
            "prefix": "k8s",
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "bundle_path_digest": "sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-11-22T10:28:08.135000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for OpenShift acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for OpenShift discovers and monitors all the containers on a host. This capability allows to monitor both the Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure.\n\nFor more information:\nhttps://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Install-UMA-for-OpenShift.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n\n   role: common\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n           webhookEnabled: true\n           manageAutoAttachWebhook: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         # The below properties define the resources for 'apmia-http-collector' deployment.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"4096Mi\"\n         requests:\n           cpu: \"500m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"500Mi\"\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.11.1-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T08:47:14.784000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator-5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713-annotation"
        },
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "2022.11.1-11",
      "version_original": "2022.11.1-11"
    },
    {
      "_id": "637ca4390ee97ebabe35e326",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true,
                    "manageAutoAttachWebhook": true,
                    "webhookEnabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "limits": {
                    "cpu": "2",
                    "memory": "4096Mi"
                  },
                  "port": 8085,
                  "requests": {
                    "cpu": "500m",
                    "memory": "500Mi"
                  }
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              }
            },
            "prefix": "k8s",
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "bundle_path_digest": "sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "beta",
      "creation_date": "2022-11-22T10:28:09.386000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for OpenShift acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for OpenShift discovers and monitors all the containers on a host. This capability allows to monitor both the Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure.\n\nFor more information:\nhttps://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Install-UMA-for-OpenShift.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n\n   role: common\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n           webhookEnabled: true\n           manageAutoAttachWebhook: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         # The below properties define the resources for 'apmia-http-collector' deployment.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"4096Mi\"\n         requests:\n           cpu: \"500m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"500Mi\"\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.11.1-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T08:47:24.216000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator-5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713-annotation"
        },
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "2022.11.1-11",
      "version_original": "2022.11.1-11"
    },
    {
      "_id": "637ca43a40d971f544896c8e",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true,
                    "manageAutoAttachWebhook": true,
                    "webhookEnabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "limits": {
                    "cpu": "2",
                    "memory": "4096Mi"
                  },
                  "port": 8085,
                  "requests": {
                    "cpu": "500m",
                    "memory": "500Mi"
                  }
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              }
            },
            "prefix": "k8s",
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "bundle_path_digest": "sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-22T10:28:10.142000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for OpenShift acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for OpenShift discovers and monitors all the containers on a host. This capability allows to monitor both the Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure.\n\nFor more information:\nhttps://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Install-UMA-for-OpenShift.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n\n   role: common\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n           webhookEnabled: true\n           manageAutoAttachWebhook: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         # The below properties define the resources for 'apmia-http-collector' deployment.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"4096Mi\"\n         requests:\n           cpu: \"500m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"500Mi\"\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.11.1-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T08:47:31.959000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator-5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713-annotation"
        },
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "2022.11.1-11",
      "version_original": "2022.11.1-11"
    },
    {
      "_id": "637ca4a9884420e0c62953e0",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true,
                    "manageAutoAttachWebhook": true,
                    "webhookEnabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "limits": {
                    "cpu": "2",
                    "memory": "4096Mi"
                  },
                  "port": 8085,
                  "requests": {
                    "cpu": "500m",
                    "memory": "500Mi"
                  }
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              }
            },
            "prefix": "k8s",
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "bundle_path_digest": "sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-11-22T10:30:01.675000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for OpenShift acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for OpenShift discovers and monitors all the containers on a host. This capability allows to monitor both the Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure.\n\nFor more information:\nhttps://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Install-UMA-for-OpenShift.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n\n   role: common\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n           webhookEnabled: true\n           manageAutoAttachWebhook: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         # The below properties define the resources for 'apmia-http-collector' deployment.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"4096Mi\"\n         requests:\n           cpu: \"500m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"500Mi\"\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.11.1-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T06:51:32.134000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator-5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713-annotation"
        },
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2022.11.1-11",
      "version_original": "2022.11.1-11"
    },
    {
      "_id": "637ca4aa74e9f4cddfbe20dc",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true,
                    "manageAutoAttachWebhook": true,
                    "webhookEnabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "limits": {
                    "cpu": "2",
                    "memory": "4096Mi"
                  },
                  "port": 8085,
                  "requests": {
                    "cpu": "500m",
                    "memory": "500Mi"
                  }
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              }
            },
            "prefix": "k8s",
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "bundle_path_digest": "sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "beta",
      "creation_date": "2022-11-22T10:30:02.347000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for OpenShift acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for OpenShift discovers and monitors all the containers on a host. This capability allows to monitor both the Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure.\n\nFor more information:\nhttps://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Install-UMA-for-OpenShift.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n\n   role: common\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n           webhookEnabled: true\n           manageAutoAttachWebhook: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         # The below properties define the resources for 'apmia-http-collector' deployment.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"4096Mi\"\n         requests:\n           cpu: \"500m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"500Mi\"\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.11.1-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T06:51:41.241000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator-5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713-annotation"
        },
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2022.11.1-11",
      "version_original": "2022.11.1-11"
    },
    {
      "_id": "637ca4aa40d971f544896dfc",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true,
                    "manageAutoAttachWebhook": true,
                    "webhookEnabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "limits": {
                    "cpu": "2",
                    "memory": "4096Mi"
                  },
                  "port": 8085,
                  "requests": {
                    "cpu": "500m",
                    "memory": "500Mi"
                  }
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              }
            },
            "prefix": "k8s",
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "bundle_path_digest": "sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-22T10:30:02.829000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for OpenShift acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for OpenShift discovers and monitors all the containers on a host. This capability allows to monitor both the Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure.\n\nFor more information:\nhttps://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Install-UMA-for-OpenShift.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n\n   role: common\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n           webhookEnabled: true\n           manageAutoAttachWebhook: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         # The below properties define the resources for 'apmia-http-collector' deployment.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"4096Mi\"\n         requests:\n           cpu: \"500m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"500Mi\"\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.11.1-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T06:51:26.386000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator-5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713-annotation"
        },
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2022.11.1-11",
      "version_original": "2022.11.1-11"
    },
    {
      "_id": "637ca6110ee97ebabe35ec1a",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true,
                    "manageAutoAttachWebhook": true,
                    "webhookEnabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "limits": {
                    "cpu": "2",
                    "memory": "4096Mi"
                  },
                  "port": 8085,
                  "requests": {
                    "cpu": "500m",
                    "memory": "500Mi"
                  }
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              }
            },
            "prefix": "k8s",
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "bundle_path_digest": "sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-11-22T10:36:00.986000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for OpenShift acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for OpenShift discovers and monitors all the containers on a host. This capability allows to monitor both the Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure.\n\nFor more information:\nhttps://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Install-UMA-for-OpenShift.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n\n   role: common\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n           webhookEnabled: true\n           manageAutoAttachWebhook: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         # The below properties define the resources for 'apmia-http-collector' deployment.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"4096Mi\"\n         requests:\n           cpu: \"500m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"500Mi\"\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.11.1-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T07:37:17.851000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "plural": "universalmonitoringagents",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator-5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713-annotation"
        },
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2022.11.1-11",
      "version_original": "2022.11.1-11"
    },
    {
      "_id": "637ca6115cd405bde9e3688d",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true,
                    "manageAutoAttachWebhook": true,
                    "webhookEnabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "limits": {
                    "cpu": "2",
                    "memory": "4096Mi"
                  },
                  "port": 8085,
                  "requests": {
                    "cpu": "500m",
                    "memory": "500Mi"
                  }
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              }
            },
            "prefix": "k8s",
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "bundle_path_digest": "sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "beta",
      "creation_date": "2022-11-22T10:36:01.624000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for OpenShift acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for OpenShift discovers and monitors all the containers on a host. This capability allows to monitor both the Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure.\n\nFor more information:\nhttps://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Install-UMA-for-OpenShift.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n\n   role: common\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n           webhookEnabled: true\n           manageAutoAttachWebhook: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         # The below properties define the resources for 'apmia-http-collector' deployment.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"4096Mi\"\n         requests:\n           cpu: \"500m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"500Mi\"\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.11.1-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T07:34:30.573000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "plural": "universalmonitoringagents",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator-5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713-annotation"
        },
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2022.11.1-11",
      "version_original": "2022.11.1-11"
    },
    {
      "_id": "637ca612829a0217f0becd57",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true,
                    "manageAutoAttachWebhook": true,
                    "webhookEnabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "limits": {
                    "cpu": "2",
                    "memory": "4096Mi"
                  },
                  "port": 8085,
                  "requests": {
                    "cpu": "500m",
                    "memory": "500Mi"
                  }
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              }
            },
            "prefix": "k8s",
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "bundle_path_digest": "sha256:ec24f43f19cdc2fbc29932e4f4dccc39018d6fc37fb5b70016f1d3edfd582ebb",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-22T10:36:02.621000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for OpenShift acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for OpenShift discovers and monitors all the containers on a host. This capability allows to monitor both the Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure.\n\nFor more information:\nhttps://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Install-UMA-for-OpenShift.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n\n   role: common\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n           webhookEnabled: true\n           manageAutoAttachWebhook: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         # The below properties define the resources for 'apmia-http-collector' deployment.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"4096Mi\"\n         requests:\n           cpu: \"500m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"500Mi\"\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.11.1-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:46:21.155000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "plural": "universalmonitoringagents",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator-5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713-annotation"
        },
        {
          "digest": "sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:5e89f4d0c8546be2d51c239c5ef1263689256d5eee383e46fa2240d715844713",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2022.11.1-11",
      "version_original": "2022.11.1-11"
    },
    {
      "_id": "637cbfb240d971f54489e063",
      "alm_examples": [
        {
          "api_version": "operator.antrea.vmware.com/v1",
          "kind": "AntreaInstall",
          "metadata": {
            "name": "antrea-install",
            "namespace": "antrea-operator"
          },
          "spec": {
            "antreaAgentConfig": "# FeatureGates is a map of feature names to bools that enable or disable experimental features.\nfeatureGates:\n# AllAlpha is a global toggle for alpha features. Per-feature key values override the default set by AllAlpha.\n#  AllAlpha: false\n\n# AllBeta is a global toggle for beta features. Per-feature key values override the default set by AllBeta.\n#  AllBeta: false\n\n# Enable AntreaProxy which provides ServiceLB for in-cluster Services in antrea-agent.\n# It should be enabled on Windows, otherwise NetworkPolicy will not take effect on\n# Service traffic.\n#  AntreaProxy: true\n\n# Enable EndpointSlice support in AntreaProxy. Don't enable this feature unless that EndpointSlice\n# API version v1 is supported and set as enabled in Kubernetes. If AntreaProxy is not enabled,\n# this flag will not take effect.\n#  EndpointSlice: false\n\n# Enable TopologyAwareHints in AntreaProxy. This requires AntreaProxy and EndpointSlice to be\n# enabled, otherwise this flag will not take effect.\n#  TopologyAwareHints: false\n\n# Enable traceflow which provides packet tracing feature to diagnose network issue.\n#  Traceflow: true\n\n# Enable NodePortLocal feature to make the Pods reachable externally through NodePort\n#  NodePortLocal: true\n\n# Enable Antrea ClusterNetworkPolicy feature to complement K8s NetworkPolicy for cluster admins\n# to define security policies which apply to the entire cluster, and Antrea NetworkPolicy\n# feature that supports priorities, rule actions and externalEntities in the future.\n#  AntreaPolicy: true\n\n# Enable flowexporter which exports polled conntrack connections as IPFIX flow records from each\n# agent to a configured collector.\n#  FlowExporter: false\n\n# Enable collecting and exposing NetworkPolicy statistics.\n#  NetworkPolicyStats: true\n\n# Enable controlling SNAT IPs of Pod egress traffic.\n#  Egress: true\n\n# Enable AntreaIPAM, which can allocate IP addresses from IPPools. AntreaIPAM is required by the\n# bridging mode and allocates IPs to Pods in bridging mode. It is also required to use Antrea for\n# IPAM when configuring secondary network interfaces with Multus.\n#  AntreaIPAM: false\n\n# Enable multicast traffic.\n#  Multicast: false\n\n# Enable Antrea Multi-cluster Gateway to support cross-cluster traffic.\n# This feature is supported only with encap mode.\n#  Multicluster: false\n\n# Enable support for provisioning secondary network interfaces for Pods (using\n# Pod annotations). At the moment, Antrea can only create secondary network\n# interfaces using SR-IOV VFs on baremetal Nodes.\n#  SecondaryNetwork: false\n\n# Enable managing external IPs of Services of LoadBalancer type.\n#  ServiceExternalIP: false\n\n# Enable mirroring or redirecting the traffic Pods send or receive.\n#  TrafficControl: false\n\n# Enable certificated-based authentication for IPsec.\n#  IPsecCertAuth: false\n\n# Name of the OpenVSwitch bridge antrea-agent will create and use.\n# Make sure it doesn't conflict with your existing OpenVSwitch bridges.\novsBridge: \"br-int\"\n\n# Datapath type to use for the OpenVSwitch bridge created by Antrea. At the moment, the only\n# supported value is 'system', which corresponds to the kernel datapath.\n#ovsDatapathType: system\n\n# Name of the interface antrea-agent will create and use for host <--> pod communication.\n# Make sure it doesn't conflict with your existing interfaces.\nhostGateway: \"antrea-gw0\"\n\n# Determines how traffic is encapsulated. It has the following options:\n# encap(default):    Inter-node Pod traffic is always encapsulated and Pod to external network\n#                    traffic is SNAT'd.\n# noEncap:           Inter-node Pod traffic is not encapsulated; Pod to external network traffic is\n#                    SNAT'd if noSNAT is not set to true. Underlying network must be capable of\n#                    supporting Pod traffic across IP subnets.\n# hybrid:            noEncap if source and destination Nodes are on the same subnet, otherwise encap.\n# networkPolicyOnly: Antrea enforces NetworkPolicy only, and utilizes CNI chaining and delegates Pod\n#                    IPAM and connectivity to the primary CNI.\n#\ntrafficEncapMode: \"encap\"\n\n# Whether or not to SNAT (using the Node IP) the egress traffic from a Pod to the external network.\n# This option is for the noEncap traffic mode only, and the default value is false. In the noEncap\n# mode, if the cluster's Pod CIDR is reachable from the external network, then the Pod traffic to\n# the external network needs not be SNAT'd. In the networkPolicyOnly mode, antrea-agent never\n# performs SNAT and this option will be ignored; for other modes it must be set to false.\nnoSNAT: false\n\n# Tunnel protocols used for encapsulating traffic across Nodes. If WireGuard is enabled in trafficEncryptionMode,\n# this option will not take effect. Supported values:\n# - geneve (default)\n# - vxlan\n# - gre\n# - stt\n# Note that \"gre\" is not supported for IPv6 clusters (IPv6-only or dual-stack clusters).\ntunnelType: \"geneve\"\n\n# TunnelPort is the destination port for UDP and TCP based tunnel protocols (Geneve, VXLAN, and STT).\n# If zero, it will use the assigned IANA port for the protocol, i.e. 6081 for Geneve, 4789 for VXLAN,\n# and 7471 for STT.\ntunnelPort: 0\n\n# TunnelCsum determines whether to compute UDP encapsulation header (Geneve or VXLAN) checksums on outgoing\n# packets. For Linux kernel before Mar 2021, UDP checksum must be present to trigger GRO on the receiver for better\n# performance of Geneve and VXLAN tunnels. The issue has been fixed by\n# https://github.com/torvalds/linux/commit/89e5c58fc1e2857ccdaae506fb8bc5fed57ee063, thus computing UDP checksum is\n# no longer necessary.\n# It should only be set to true when you are using an unpatched Linux kernel and observing poor transfer performance.\ntunnelCsum: false\n\n# Determines how tunnel traffic is encrypted. Currently encryption only works with encap mode.\n# It has the following options:\n# - none (default):  Inter-node Pod traffic will not be encrypted.\n# - ipsec:           Enable IPsec (ESP) encryption for Pod traffic across Nodes. Antrea uses\n#                    Preshared Key (PSK) for IKE authentication. When IPsec tunnel is enabled,\n#                    the PSK value must be passed to Antrea Agent through an environment\n#                    variable: ANTREA_IPSEC_PSK.\n# - wireGuard:       Enable WireGuard for tunnel traffic encryption.\ntrafficEncryptionMode: \"none\"\n\n# Enable bridging mode of Pod network on Nodes, in which the Node's transport interface is connected\n# to the OVS bridge, and cross-Node/VLAN traffic of AntreaIPAM Pods (Pods whose IP addresses are\n# allocated by AntreaIPAM from IPPools) is sent to the underlay network, and forwarded/routed by the\n# underlay network.\n# This option requires the `AntreaIPAM` feature gate to be enabled. At this moment, it supports only\n# IPv4 and Linux Nodes, and can be enabled only when `ovsDatapathType` is `system`,\n# `trafficEncapMode` is `noEncap`, and `noSNAT` is true.\nenableBridgingMode: false\n\n# Disable TX checksum offloading for container network interfaces. It's supposed to be set to true when the\n# datapath doesn't support TX checksum offloading, which causes packets to be dropped due to bad checksum.\n# It affects Pods running on Linux Nodes only.\ndisableTXChecksumOffload: false\n\n# Default MTU to use for the host gateway interface and the network interface of each Pod.\n# If omitted, antrea-agent will discover the MTU of the Node's primary interface and\n# also adjust MTU to accommodate for tunnel encapsulation overhead (if applicable).\ndefaultMTU: 0\n\n# wireGuard specifies WireGuard related configurations.\nwireGuard:\n  # The port for WireGuard to receive traffic.\n  port: 51820\n\negress:\n  # exceptCIDRs is the CIDR ranges to which outbound Pod traffic will not be SNAT'd by Egresses.\n  exceptCIDRs:\n\n# ClusterIP CIDR range for Services. It's required when AntreaProxy is not enabled, and should be\n# set to the same value as the one specified by --service-cluster-ip-range for kube-apiserver. When\n# AntreaProxy is enabled, this parameter is not needed and will be ignored if provided.\nserviceCIDR: \"\"\n\n# ClusterIP CIDR range for IPv6 Services. It's required when using kube-proxy to provide IPv6 Service in a Dual-Stack\n# cluster or an IPv6 only cluster. The value should be the same as the configuration for kube-apiserver specified by\n# --service-cluster-ip-range. When AntreaProxy is enabled, this parameter is not needed.\n# No default value for this field.\nserviceCIDRv6: \"\"\n\n# The port for the antrea-agent APIServer to serve on.\n# Note that if it's set to another value, the `containerPort` of the `api` port of the\n# `antrea-agent` container must be set to the same value.\napiPort: 10350\n\n# Enable metrics exposure via Prometheus. Initializes Prometheus metrics listener.\nenablePrometheusMetrics: true\n\n# Provide the IPFIX collector address as a string with format <HOST>:[<PORT>][:<PROTO>].\n# HOST can either be the DNS name or the IP of the Flow Collector. For example,\n# \"flow-aggregator.flow-aggregator.svc\" can be provided as DNS name to connect\n# to the Antrea Flow Aggregator service. If IP, it can be either IPv4 or IPv6.\n# However, IPv6 address should be wrapped with [].\n# If PORT is empty, we default to 4739, the standard IPFIX port.\n# If no PROTO is given, we consider \"tls\" as default. We support \"tls\", \"tcp\" and\n# \"udp\" protocols. \"tls\" is used for securing communication between flow exporter and\n# flow aggregator.\nflowCollectorAddr: \"flow-aggregator.flow-aggregator.svc:4739:tls\"\n\n# Provide flow poll interval as a duration string. This determines how often the\n# flow exporter dumps connections from the conntrack module. Flow poll interval\n# should be greater than or equal to 1s (one second).\n# Valid time units are \"ns\", \"us\" (or \"\u00b5s\"), \"ms\", \"s\", \"m\", \"h\".\nflowPollInterval: \"5s\"\n\n# Provide the active flow export timeout, which is the timeout after which a flow\n# record is sent to the collector for active flows. Thus, for flows with a continuous\n# stream of packets, a flow record will be exported to the collector once the elapsed\n# time since the last export event is equal to the value of this timeout.\n# Valid time units are \"ns\", \"us\" (or \"\u00b5s\"), \"ms\", \"s\", \"m\", \"h\".\nactiveFlowExportTimeout: \"5s\"\n\n# Provide the idle flow export timeout, which is the timeout after which a flow\n# record is sent to the collector for idle flows. A flow is considered idle if no\n# packet matching this flow has been observed since the last export event.\n# Valid time units are \"ns\", \"us\" (or \"\u00b5s\"), \"ms\", \"s\", \"m\", \"h\".\nidleFlowExportTimeout: \"15s\"\n\nnodePortLocal:\n# Enable NodePortLocal, a feature used to make Pods reachable using port forwarding on the host. To\n# enable this feature, you need to set \"enable\" to true, and ensure that the NodePortLocal feature\n# gate is also enabled (which is the default).\n  enable: false\n# Provide the port range used by NodePortLocal. When the NodePortLocal feature is enabled, a port\n# from that range will be assigned whenever a Pod's container defines a specific port to be exposed\n# (each container can define a list of ports as pod.spec.containers[].ports), and all Node traffic\n# directed to that port will be forwarded to the Pod.\n  portRange: \"61000-62000\"\n\n# Provide the address of Kubernetes apiserver, to override any value provided in kubeconfig or InClusterConfig.\n# Defaults to \"\". It must be a host string, a host:port pair, or a URL to the base of the apiserver.\nkubeAPIServerOverride: \"\"\n\n# Provide the address of DNS server, to override the kube-dns service. It's used to resolve hostname in FQDN policy.\n# Defaults to \"\". It must be a host string or a host:port pair of the DNS server (e.g. 10.96.0.10, 10.96.0.10:53,\n# [fd00:10:96::a]:53).\ndnsServerOverride: \"\"\n\n# Comma-separated list of Cipher Suites. If omitted, the default Go Cipher Suites will be used.\n# https://golang.org/pkg/crypto/tls/#pkg-constants\n# Note that TLS1.3 Cipher Suites cannot be added to the list. But the apiserver will always\n# prefer TLS1.3 Cipher Suites whenever possible.\ntlsCipherSuites: \"\"\n\n# TLS min version from: VersionTLS10, VersionTLS11, VersionTLS12, VersionTLS13.\ntlsMinVersion: \"\"\n\n# The name of the interface on Node which is used for tunneling or routing the traffic across Nodes.\n# If there are multiple IP addresses configured on the interface, the first one is used. The IP\n# address used for tunneling or routing traffic to remote Nodes is decided in the following order of\n# preference (from highest to lowest):\n# 1. transportInterface\n# 2. transportInterfaceCIDRs\n# 3. The Node IP\ntransportInterface: \"\"\n\nmulticast:\n# The names of the interfaces on Nodes that are used to forward multicast traffic.\n# Defaults to transport interface if not set.\n  multicastInterfaces:\n\n# The interval at which the antrea-agent sends IGMP queries to Pods.\n# Valid time units are \"ns\", \"us\" (or \"\u00b5s\"), \"ms\", \"s\", \"m\", \"h\".\n  igmpQueryInterval: \"125s\"\n\n# The network CIDRs of the interface on Node which is used for tunneling or routing the traffic across\n# Nodes. If there are multiple interfaces configured the same network CIDR, the first one is used. The\n# IP address used for tunneling or routing traffic to remote Nodes is decided in the following order of\n# preference (from highest to lowest):\n# 1. transportInterface\n# 2. transportInterfaceCIDRs\n# 3. The Node IP\ntransportInterfaceCIDRs:\n\n# Option antreaProxy contains AntreaProxy related configuration options.\nantreaProxy:\n  # ProxyAll tells antrea-agent to proxy all Service traffic, including NodePort, LoadBalancer, and ClusterIP traffic,\n  # regardless of where they come from. Therefore, running kube-proxy is no longer required. This requires the AntreaProxy\n  # feature to be enabled.\n  # Note that this option is experimental. If kube-proxy is removed, option kubeAPIServerOverride must be used to access\n  # apiserver directly.\n  proxyAll: false\n  # A string array of values which specifies the host IPv4/IPv6 addresses for NodePort. Values can be valid IP blocks.\n  # (e.g. 1.2.3.0/24, 1.2.3.4/32). An empty string slice is meant to select all host IPv4/IPv6 addresses.\n  # Note that the option is only valid when proxyAll is true.\n  nodePortAddresses:\n  # An array of string values to specify a list of Services which should be ignored by AntreaProxy (traffic to these\n  # Services will not be load-balanced). Values can be a valid ClusterIP (e.g. 10.11.1.2) or a Service name\n  # with Namespace (e.g. kube-system/kube-dns)\n  skipServices:\n  # When ProxyLoadBalancerIPs is set to false, AntreaProxy no longer load-balances traffic destined to the\n  # External IPs of LoadBalancer Services. This is useful when the external LoadBalancer provides additional\n  # capabilities (e.g. TLS termination) and it is desirable for Pod-to-ExternalIP traffic to be sent to the\n  # external LoadBalancer instead of being load-balanced to an Endpoint directly by AntreaProxy.\n  # Note that setting ProxyLoadBalancerIPs to false usually only makes sense when ProxyAll is set to true and\n  # kube-proxy is removed from the cluser, otherwise kube-proxy will still load-balance this traffic.\n  proxyLoadBalancerIPs: true\n\n# IPsec tunnel related configurations.\nipsec:\n  # The authentication mode of IPsec tunnel. It has the following options:\n  # - psk (default): Use pre-shared key (PSK) for IKE authentication.\n  # - cert:          Use CA-signed certificates for IKE authentication. This option requires the `IPsecCertAuth`\n  #                  feature gate to be enabled.\n  authenticationMode: \"psk\"\n\nmulticluster:\n# Enable Antrea Multi-cluster Gateway to support cross-cluster traffic.\n# This feature is supported only with encap mode.\n  enable: false\n# The Namespace where Antrea Multi-cluster Controller is running.\n# The default is antrea-agent's Namespace.\n  namespace: \"\"\n",
            "antreaCNIConfig": "{\n    \"cniVersion\":\"0.3.0\",\n    \"name\": \"antrea\",\n    \"plugins\": [\n        {\n            \"type\": \"antrea\",\n            \"ipam\": {\n                \"type\": \"host-local\"\n            }\n        }\n        ,\n        {\n            \"type\": \"portmap\",\n            \"capabilities\": {\"portMappings\": true}\n        }\n        ,\n        {\n            \"type\": \"bandwidth\",\n            \"capabilities\": {\"bandwidth\": true}\n        }\n    ]\n}\n",
            "antreaControllerConfig": "# FeatureGates is a map of feature names to bools that enable or disable experimental features.\nfeatureGates:\n# AllAlpha is a global toggle for alpha features. Per-feature key values override the default set by AllAlpha.\n#  AllAlpha: false\n\n# AllBeta is a global toggle for beta features. Per-feature key values override the default set by AllBeta.\n#  AllBeta: false\n\n# Enable traceflow which provides packet tracing feature to diagnose network issue.\n#  Traceflow: true\n\n# Enable Antrea ClusterNetworkPolicy feature to complement K8s NetworkPolicy for cluster admins\n# to define security policies which apply to the entire cluster, and Antrea NetworkPolicy\n# feature that supports priorities, rule actions and externalEntities in the future.\n#  AntreaPolicy: true\n\n# Enable collecting and exposing NetworkPolicy statistics.\n#  NetworkPolicyStats: true\n\n# Enable multicast traffic.\n#  Multicast: false\n\n# Enable controlling SNAT IPs of Pod egress traffic.\n#  Egress: true\n\n# Run Kubernetes NodeIPAMController with Antrea.\n#  NodeIPAM: false\n\n# Enable AntreaIPAM, which can allocate IP addresses from IPPools. AntreaIPAM is required by the\n# bridging mode and allocates IPs to Pods in bridging mode. It is also required to use Antrea for\n# IPAM when configuring secondary network interfaces with Multus.\n#  AntreaIPAM: false\n\n# Enable managing external IPs of Services of LoadBalancer type.\n#  ServiceExternalIP: false\n\n# Enable certificated-based authentication for IPsec.\n#  IPsecCertAuth: false\n\n# Enable managing ExternalNode for unmanaged VM/BM.\n#  ExternalNode: false\n\n# The port for the antrea-controller APIServer to serve on.\n# Note that if it's set to another value, the `containerPort` of the `api` port of the\n# `antrea-controller` container must be set to the same value.\napiPort: 10349\n\n# Enable metrics exposure via Prometheus. Initializes Prometheus metrics listener.\nenablePrometheusMetrics: true\n\n# Indicates whether to use auto-generated self-signed TLS certificate.\n# If false, a Secret named \"antrea-controller-tls\" must be provided with the following keys:\n#   ca.crt: <CA certificate>\n#   tls.crt: <TLS certificate>\n#   tls.key: <TLS private key>\nselfSignedCert: true\n\n# Comma-separated list of Cipher Suites. If omitted, the default Go Cipher Suites will be used.\n# https://golang.org/pkg/crypto/tls/#pkg-constants\n# Note that TLS1.3 Cipher Suites cannot be added to the list. But the apiserver will always\n# prefer TLS1.3 Cipher Suites whenever possible.\ntlsCipherSuites: \"\"\n\n# TLS min version from: VersionTLS10, VersionTLS11, VersionTLS12, VersionTLS13.\ntlsMinVersion: \"\"\n\nnodeIPAM:\n  # Enable the integrated Node IPAM controller within the Antrea controller.\n  enableNodeIPAM: false\n  # CIDR ranges for Pods in cluster. String array containing single CIDR range, or multiple ranges.\n  # The CIDRs could be either IPv4 or IPv6. At most one CIDR may be specified for each IP family.\n  # Value ignored when enableNodeIPAM is false.\n  clusterCIDRs:\n  # CIDR ranges for Services in cluster. It is not necessary to specify it when there is no overlap with clusterCIDRs.\n  # Value ignored when enableNodeIPAM is false.\n  serviceCIDR: \"\"\n  serviceCIDRv6: \"\"\n  # Mask size for IPv4 Node CIDR in IPv4 or dual-stack cluster. Value ignored when enableNodeIPAM is false\n  # or when IPv4 Pod CIDR is not configured. Valid range is 16 to 30.\n  nodeCIDRMaskSizeIPv4: 24\n  # Mask size for IPv6 Node CIDR in IPv6 or dual-stack cluster. Value ignored when enableNodeIPAM is false\n  # or when IPv6 Pod CIDR is not configured. Valid range is 64 to 126.\n  nodeCIDRMaskSizeIPv6: 64\n\nipsecCSRSigner:\n  # Determines the auto-approve policy of Antrea CSR signer for IPsec certificates management.\n  # If enabled, Antrea will auto-approve the CertificateSingingRequest (CSR) if its subject and x509 extensions\n  # are permitted, and the requestor can be validated. If K8s `BoundServiceAccountTokenVolume` feature is enabled,\n  # the Pod identity will also be validated to provide maximum security.\n  # If set to false, Antrea will not auto-approve CertificateSingingRequests and they need to be approved\n  # manually by `kubectl certificate approve`.\n  autoApprove: true\n  # Indicates whether to use auto-generated self-signed CA certificate.\n  # If false, a Secret named \"antrea-ipsec-ca\" must be provided with the following keys:\n  #   tls.crt: <CA certificate>\n  #   tls.key: <CA private key>\n  selfSignedCA: true\n",
            "antreaImage": "antrea/antrea-ubi:v1.9.0",
            "antreaPlatform": "openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/wavefronthq/antrea-openshift-operator@sha256:9f49b07ff1623ff85d55ff51eaf1575b2ebe83d88f1d484ebbc44a5c38a74ef8",
      "bundle_path_digest": "sha256:9f49b07ff1623ff85d55ff51eaf1575b2ebe83d88f1d484ebbc44a5c38a74ef8",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-11-22T12:25:22.209000+00:00",
      "csv_description": "An operator which installs Antrea network CNI plugin on the Kubernetes cluster.",
      "csv_display_name": "Antrea Operator",
      "csv_metadata_description": "An operator which installs Antrea network CNI plugin on the Kubernetes cluster.",
      "csv_name": "antrea-operator-for-kubernetes.v1.9.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T08:19:00.790000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "antrea-operator-for-kubernetes",
      "provided_apis": [
        {
          "group": "operator.antrea.vmware.com",
          "kind": "AntreaInstall",
          "plural": "antreainstalls",
          "version": "v1"
        }
      ],
      "provider": "antrea.io",
      "related_images": [
        {
          "digest": "sha256:ce0420d1a534f94f682cedf92add736356bcc1b9fa1bd3b2731d4d27e69000c3",
          "image": "antrea/antrea-operator@sha256:ce0420d1a534f94f682cedf92add736356bcc1b9fa1bd3b2731d4d27e69000c3",
          "name": "antrea-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.9.0",
      "version_original": "1.9.0"
    },
    {
      "_id": "637cc06c5cd405bde9e3d454",
      "alm_examples": [
        {
          "api_version": "operator.antrea.vmware.com/v1",
          "kind": "AntreaInstall",
          "metadata": {
            "name": "antrea-install",
            "namespace": "antrea-operator"
          },
          "spec": {
            "antreaAgentConfig": "# FeatureGates is a map of feature names to bools that enable or disable experimental features.\nfeatureGates:\n# AllAlpha is a global toggle for alpha features. Per-feature key values override the default set by AllAlpha.\n#  AllAlpha: false\n\n# AllBeta is a global toggle for beta features. Per-feature key values override the default set by AllBeta.\n#  AllBeta: false\n\n# Enable AntreaProxy which provides ServiceLB for in-cluster Services in antrea-agent.\n# It should be enabled on Windows, otherwise NetworkPolicy will not take effect on\n# Service traffic.\n#  AntreaProxy: true\n\n# Enable EndpointSlice support in AntreaProxy. Don't enable this feature unless that EndpointSlice\n# API version v1 is supported and set as enabled in Kubernetes. If AntreaProxy is not enabled,\n# this flag will not take effect.\n#  EndpointSlice: false\n\n# Enable TopologyAwareHints in AntreaProxy. This requires AntreaProxy and EndpointSlice to be\n# enabled, otherwise this flag will not take effect.\n#  TopologyAwareHints: false\n\n# Enable traceflow which provides packet tracing feature to diagnose network issue.\n#  Traceflow: true\n\n# Enable NodePortLocal feature to make the Pods reachable externally through NodePort\n#  NodePortLocal: true\n\n# Enable Antrea ClusterNetworkPolicy feature to complement K8s NetworkPolicy for cluster admins\n# to define security policies which apply to the entire cluster, and Antrea NetworkPolicy\n# feature that supports priorities, rule actions and externalEntities in the future.\n#  AntreaPolicy: true\n\n# Enable flowexporter which exports polled conntrack connections as IPFIX flow records from each\n# agent to a configured collector.\n#  FlowExporter: false\n\n# Enable collecting and exposing NetworkPolicy statistics.\n#  NetworkPolicyStats: true\n\n# Enable controlling SNAT IPs of Pod egress traffic.\n#  Egress: true\n\n# Enable AntreaIPAM, which can allocate IP addresses from IPPools. AntreaIPAM is required by the\n# bridging mode and allocates IPs to Pods in bridging mode. It is also required to use Antrea for\n# IPAM when configuring secondary network interfaces with Multus.\n#  AntreaIPAM: false\n\n# Enable multicast traffic.\n#  Multicast: false\n\n# Enable Antrea Multi-cluster Gateway to support cross-cluster traffic.\n# This feature is supported only with encap mode.\n#  Multicluster: false\n\n# Enable support for provisioning secondary network interfaces for Pods (using\n# Pod annotations). At the moment, Antrea can only create secondary network\n# interfaces using SR-IOV VFs on baremetal Nodes.\n#  SecondaryNetwork: false\n\n# Enable managing external IPs of Services of LoadBalancer type.\n#  ServiceExternalIP: false\n\n# Enable mirroring or redirecting the traffic Pods send or receive.\n#  TrafficControl: false\n\n# Enable certificated-based authentication for IPsec.\n#  IPsecCertAuth: false\n\n# Name of the OpenVSwitch bridge antrea-agent will create and use.\n# Make sure it doesn't conflict with your existing OpenVSwitch bridges.\novsBridge: \"br-int\"\n\n# Datapath type to use for the OpenVSwitch bridge created by Antrea. At the moment, the only\n# supported value is 'system', which corresponds to the kernel datapath.\n#ovsDatapathType: system\n\n# Name of the interface antrea-agent will create and use for host <--> pod communication.\n# Make sure it doesn't conflict with your existing interfaces.\nhostGateway: \"antrea-gw0\"\n\n# Determines how traffic is encapsulated. It has the following options:\n# encap(default):    Inter-node Pod traffic is always encapsulated and Pod to external network\n#                    traffic is SNAT'd.\n# noEncap:           Inter-node Pod traffic is not encapsulated; Pod to external network traffic is\n#                    SNAT'd if noSNAT is not set to true. Underlying network must be capable of\n#                    supporting Pod traffic across IP subnets.\n# hybrid:            noEncap if source and destination Nodes are on the same subnet, otherwise encap.\n# networkPolicyOnly: Antrea enforces NetworkPolicy only, and utilizes CNI chaining and delegates Pod\n#                    IPAM and connectivity to the primary CNI.\n#\ntrafficEncapMode: \"encap\"\n\n# Whether or not to SNAT (using the Node IP) the egress traffic from a Pod to the external network.\n# This option is for the noEncap traffic mode only, and the default value is false. In the noEncap\n# mode, if the cluster's Pod CIDR is reachable from the external network, then the Pod traffic to\n# the external network needs not be SNAT'd. In the networkPolicyOnly mode, antrea-agent never\n# performs SNAT and this option will be ignored; for other modes it must be set to false.\nnoSNAT: false\n\n# Tunnel protocols used for encapsulating traffic across Nodes. If WireGuard is enabled in trafficEncryptionMode,\n# this option will not take effect. Supported values:\n# - geneve (default)\n# - vxlan\n# - gre\n# - stt\n# Note that \"gre\" is not supported for IPv6 clusters (IPv6-only or dual-stack clusters).\ntunnelType: \"geneve\"\n\n# TunnelPort is the destination port for UDP and TCP based tunnel protocols (Geneve, VXLAN, and STT).\n# If zero, it will use the assigned IANA port for the protocol, i.e. 6081 for Geneve, 4789 for VXLAN,\n# and 7471 for STT.\ntunnelPort: 0\n\n# TunnelCsum determines whether to compute UDP encapsulation header (Geneve or VXLAN) checksums on outgoing\n# packets. For Linux kernel before Mar 2021, UDP checksum must be present to trigger GRO on the receiver for better\n# performance of Geneve and VXLAN tunnels. The issue has been fixed by\n# https://github.com/torvalds/linux/commit/89e5c58fc1e2857ccdaae506fb8bc5fed57ee063, thus computing UDP checksum is\n# no longer necessary.\n# It should only be set to true when you are using an unpatched Linux kernel and observing poor transfer performance.\ntunnelCsum: false\n\n# Determines how tunnel traffic is encrypted. Currently encryption only works with encap mode.\n# It has the following options:\n# - none (default):  Inter-node Pod traffic will not be encrypted.\n# - ipsec:           Enable IPsec (ESP) encryption for Pod traffic across Nodes. Antrea uses\n#                    Preshared Key (PSK) for IKE authentication. When IPsec tunnel is enabled,\n#                    the PSK value must be passed to Antrea Agent through an environment\n#                    variable: ANTREA_IPSEC_PSK.\n# - wireGuard:       Enable WireGuard for tunnel traffic encryption.\ntrafficEncryptionMode: \"none\"\n\n# Enable bridging mode of Pod network on Nodes, in which the Node's transport interface is connected\n# to the OVS bridge, and cross-Node/VLAN traffic of AntreaIPAM Pods (Pods whose IP addresses are\n# allocated by AntreaIPAM from IPPools) is sent to the underlay network, and forwarded/routed by the\n# underlay network.\n# This option requires the `AntreaIPAM` feature gate to be enabled. At this moment, it supports only\n# IPv4 and Linux Nodes, and can be enabled only when `ovsDatapathType` is `system`,\n# `trafficEncapMode` is `noEncap`, and `noSNAT` is true.\nenableBridgingMode: false\n\n# Disable TX checksum offloading for container network interfaces. It's supposed to be set to true when the\n# datapath doesn't support TX checksum offloading, which causes packets to be dropped due to bad checksum.\n# It affects Pods running on Linux Nodes only.\ndisableTXChecksumOffload: false\n\n# Default MTU to use for the host gateway interface and the network interface of each Pod.\n# If omitted, antrea-agent will discover the MTU of the Node's primary interface and\n# also adjust MTU to accommodate for tunnel encapsulation overhead (if applicable).\ndefaultMTU: 0\n\n# wireGuard specifies WireGuard related configurations.\nwireGuard:\n  # The port for WireGuard to receive traffic.\n  port: 51820\n\negress:\n  # exceptCIDRs is the CIDR ranges to which outbound Pod traffic will not be SNAT'd by Egresses.\n  exceptCIDRs:\n\n# ClusterIP CIDR range for Services. It's required when AntreaProxy is not enabled, and should be\n# set to the same value as the one specified by --service-cluster-ip-range for kube-apiserver. When\n# AntreaProxy is enabled, this parameter is not needed and will be ignored if provided.\nserviceCIDR: \"\"\n\n# ClusterIP CIDR range for IPv6 Services. It's required when using kube-proxy to provide IPv6 Service in a Dual-Stack\n# cluster or an IPv6 only cluster. The value should be the same as the configuration for kube-apiserver specified by\n# --service-cluster-ip-range. When AntreaProxy is enabled, this parameter is not needed.\n# No default value for this field.\nserviceCIDRv6: \"\"\n\n# The port for the antrea-agent APIServer to serve on.\n# Note that if it's set to another value, the `containerPort` of the `api` port of the\n# `antrea-agent` container must be set to the same value.\napiPort: 10350\n\n# Enable metrics exposure via Prometheus. Initializes Prometheus metrics listener.\nenablePrometheusMetrics: true\n\n# Provide the IPFIX collector address as a string with format <HOST>:[<PORT>][:<PROTO>].\n# HOST can either be the DNS name or the IP of the Flow Collector. For example,\n# \"flow-aggregator.flow-aggregator.svc\" can be provided as DNS name to connect\n# to the Antrea Flow Aggregator service. If IP, it can be either IPv4 or IPv6.\n# However, IPv6 address should be wrapped with [].\n# If PORT is empty, we default to 4739, the standard IPFIX port.\n# If no PROTO is given, we consider \"tls\" as default. We support \"tls\", \"tcp\" and\n# \"udp\" protocols. \"tls\" is used for securing communication between flow exporter and\n# flow aggregator.\nflowCollectorAddr: \"flow-aggregator.flow-aggregator.svc:4739:tls\"\n\n# Provide flow poll interval as a duration string. This determines how often the\n# flow exporter dumps connections from the conntrack module. Flow poll interval\n# should be greater than or equal to 1s (one second).\n# Valid time units are \"ns\", \"us\" (or \"\u00b5s\"), \"ms\", \"s\", \"m\", \"h\".\nflowPollInterval: \"5s\"\n\n# Provide the active flow export timeout, which is the timeout after which a flow\n# record is sent to the collector for active flows. Thus, for flows with a continuous\n# stream of packets, a flow record will be exported to the collector once the elapsed\n# time since the last export event is equal to the value of this timeout.\n# Valid time units are \"ns\", \"us\" (or \"\u00b5s\"), \"ms\", \"s\", \"m\", \"h\".\nactiveFlowExportTimeout: \"5s\"\n\n# Provide the idle flow export timeout, which is the timeout after which a flow\n# record is sent to the collector for idle flows. A flow is considered idle if no\n# packet matching this flow has been observed since the last export event.\n# Valid time units are \"ns\", \"us\" (or \"\u00b5s\"), \"ms\", \"s\", \"m\", \"h\".\nidleFlowExportTimeout: \"15s\"\n\nnodePortLocal:\n# Enable NodePortLocal, a feature used to make Pods reachable using port forwarding on the host. To\n# enable this feature, you need to set \"enable\" to true, and ensure that the NodePortLocal feature\n# gate is also enabled (which is the default).\n  enable: false\n# Provide the port range used by NodePortLocal. When the NodePortLocal feature is enabled, a port\n# from that range will be assigned whenever a Pod's container defines a specific port to be exposed\n# (each container can define a list of ports as pod.spec.containers[].ports), and all Node traffic\n# directed to that port will be forwarded to the Pod.\n  portRange: \"61000-62000\"\n\n# Provide the address of Kubernetes apiserver, to override any value provided in kubeconfig or InClusterConfig.\n# Defaults to \"\". It must be a host string, a host:port pair, or a URL to the base of the apiserver.\nkubeAPIServerOverride: \"\"\n\n# Provide the address of DNS server, to override the kube-dns service. It's used to resolve hostname in FQDN policy.\n# Defaults to \"\". It must be a host string or a host:port pair of the DNS server (e.g. 10.96.0.10, 10.96.0.10:53,\n# [fd00:10:96::a]:53).\ndnsServerOverride: \"\"\n\n# Comma-separated list of Cipher Suites. If omitted, the default Go Cipher Suites will be used.\n# https://golang.org/pkg/crypto/tls/#pkg-constants\n# Note that TLS1.3 Cipher Suites cannot be added to the list. But the apiserver will always\n# prefer TLS1.3 Cipher Suites whenever possible.\ntlsCipherSuites: \"\"\n\n# TLS min version from: VersionTLS10, VersionTLS11, VersionTLS12, VersionTLS13.\ntlsMinVersion: \"\"\n\n# The name of the interface on Node which is used for tunneling or routing the traffic across Nodes.\n# If there are multiple IP addresses configured on the interface, the first one is used. The IP\n# address used for tunneling or routing traffic to remote Nodes is decided in the following order of\n# preference (from highest to lowest):\n# 1. transportInterface\n# 2. transportInterfaceCIDRs\n# 3. The Node IP\ntransportInterface: \"\"\n\nmulticast:\n# The names of the interfaces on Nodes that are used to forward multicast traffic.\n# Defaults to transport interface if not set.\n  multicastInterfaces:\n\n# The interval at which the antrea-agent sends IGMP queries to Pods.\n# Valid time units are \"ns\", \"us\" (or \"\u00b5s\"), \"ms\", \"s\", \"m\", \"h\".\n  igmpQueryInterval: \"125s\"\n\n# The network CIDRs of the interface on Node which is used for tunneling or routing the traffic across\n# Nodes. If there are multiple interfaces configured the same network CIDR, the first one is used. The\n# IP address used for tunneling or routing traffic to remote Nodes is decided in the following order of\n# preference (from highest to lowest):\n# 1. transportInterface\n# 2. transportInterfaceCIDRs\n# 3. The Node IP\ntransportInterfaceCIDRs:\n\n# Option antreaProxy contains AntreaProxy related configuration options.\nantreaProxy:\n  # ProxyAll tells antrea-agent to proxy all Service traffic, including NodePort, LoadBalancer, and ClusterIP traffic,\n  # regardless of where they come from. Therefore, running kube-proxy is no longer required. This requires the AntreaProxy\n  # feature to be enabled.\n  # Note that this option is experimental. If kube-proxy is removed, option kubeAPIServerOverride must be used to access\n  # apiserver directly.\n  proxyAll: false\n  # A string array of values which specifies the host IPv4/IPv6 addresses for NodePort. Values can be valid IP blocks.\n  # (e.g. 1.2.3.0/24, 1.2.3.4/32). An empty string slice is meant to select all host IPv4/IPv6 addresses.\n  # Note that the option is only valid when proxyAll is true.\n  nodePortAddresses:\n  # An array of string values to specify a list of Services which should be ignored by AntreaProxy (traffic to these\n  # Services will not be load-balanced). Values can be a valid ClusterIP (e.g. 10.11.1.2) or a Service name\n  # with Namespace (e.g. kube-system/kube-dns)\n  skipServices:\n  # When ProxyLoadBalancerIPs is set to false, AntreaProxy no longer load-balances traffic destined to the\n  # External IPs of LoadBalancer Services. This is useful when the external LoadBalancer provides additional\n  # capabilities (e.g. TLS termination) and it is desirable for Pod-to-ExternalIP traffic to be sent to the\n  # external LoadBalancer instead of being load-balanced to an Endpoint directly by AntreaProxy.\n  # Note that setting ProxyLoadBalancerIPs to false usually only makes sense when ProxyAll is set to true and\n  # kube-proxy is removed from the cluser, otherwise kube-proxy will still load-balance this traffic.\n  proxyLoadBalancerIPs: true\n\n# IPsec tunnel related configurations.\nipsec:\n  # The authentication mode of IPsec tunnel. It has the following options:\n  # - psk (default): Use pre-shared key (PSK) for IKE authentication.\n  # - cert:          Use CA-signed certificates for IKE authentication. This option requires the `IPsecCertAuth`\n  #                  feature gate to be enabled.\n  authenticationMode: \"psk\"\n\nmulticluster:\n# Enable Antrea Multi-cluster Gateway to support cross-cluster traffic.\n# This feature is supported only with encap mode.\n  enable: false\n# The Namespace where Antrea Multi-cluster Controller is running.\n# The default is antrea-agent's Namespace.\n  namespace: \"\"\n",
            "antreaCNIConfig": "{\n    \"cniVersion\":\"0.3.0\",\n    \"name\": \"antrea\",\n    \"plugins\": [\n        {\n            \"type\": \"antrea\",\n            \"ipam\": {\n                \"type\": \"host-local\"\n            }\n        }\n        ,\n        {\n            \"type\": \"portmap\",\n            \"capabilities\": {\"portMappings\": true}\n        }\n        ,\n        {\n            \"type\": \"bandwidth\",\n            \"capabilities\": {\"bandwidth\": true}\n        }\n    ]\n}\n",
            "antreaControllerConfig": "# FeatureGates is a map of feature names to bools that enable or disable experimental features.\nfeatureGates:\n# AllAlpha is a global toggle for alpha features. Per-feature key values override the default set by AllAlpha.\n#  AllAlpha: false\n\n# AllBeta is a global toggle for beta features. Per-feature key values override the default set by AllBeta.\n#  AllBeta: false\n\n# Enable traceflow which provides packet tracing feature to diagnose network issue.\n#  Traceflow: true\n\n# Enable Antrea ClusterNetworkPolicy feature to complement K8s NetworkPolicy for cluster admins\n# to define security policies which apply to the entire cluster, and Antrea NetworkPolicy\n# feature that supports priorities, rule actions and externalEntities in the future.\n#  AntreaPolicy: true\n\n# Enable collecting and exposing NetworkPolicy statistics.\n#  NetworkPolicyStats: true\n\n# Enable multicast traffic.\n#  Multicast: false\n\n# Enable controlling SNAT IPs of Pod egress traffic.\n#  Egress: true\n\n# Run Kubernetes NodeIPAMController with Antrea.\n#  NodeIPAM: false\n\n# Enable AntreaIPAM, which can allocate IP addresses from IPPools. AntreaIPAM is required by the\n# bridging mode and allocates IPs to Pods in bridging mode. It is also required to use Antrea for\n# IPAM when configuring secondary network interfaces with Multus.\n#  AntreaIPAM: false\n\n# Enable managing external IPs of Services of LoadBalancer type.\n#  ServiceExternalIP: false\n\n# Enable certificated-based authentication for IPsec.\n#  IPsecCertAuth: false\n\n# Enable managing ExternalNode for unmanaged VM/BM.\n#  ExternalNode: false\n\n# The port for the antrea-controller APIServer to serve on.\n# Note that if it's set to another value, the `containerPort` of the `api` port of the\n# `antrea-controller` container must be set to the same value.\napiPort: 10349\n\n# Enable metrics exposure via Prometheus. Initializes Prometheus metrics listener.\nenablePrometheusMetrics: true\n\n# Indicates whether to use auto-generated self-signed TLS certificate.\n# If false, a Secret named \"antrea-controller-tls\" must be provided with the following keys:\n#   ca.crt: <CA certificate>\n#   tls.crt: <TLS certificate>\n#   tls.key: <TLS private key>\nselfSignedCert: true\n\n# Comma-separated list of Cipher Suites. If omitted, the default Go Cipher Suites will be used.\n# https://golang.org/pkg/crypto/tls/#pkg-constants\n# Note that TLS1.3 Cipher Suites cannot be added to the list. But the apiserver will always\n# prefer TLS1.3 Cipher Suites whenever possible.\ntlsCipherSuites: \"\"\n\n# TLS min version from: VersionTLS10, VersionTLS11, VersionTLS12, VersionTLS13.\ntlsMinVersion: \"\"\n\nnodeIPAM:\n  # Enable the integrated Node IPAM controller within the Antrea controller.\n  enableNodeIPAM: false\n  # CIDR ranges for Pods in cluster. String array containing single CIDR range, or multiple ranges.\n  # The CIDRs could be either IPv4 or IPv6. At most one CIDR may be specified for each IP family.\n  # Value ignored when enableNodeIPAM is false.\n  clusterCIDRs:\n  # CIDR ranges for Services in cluster. It is not necessary to specify it when there is no overlap with clusterCIDRs.\n  # Value ignored when enableNodeIPAM is false.\n  serviceCIDR: \"\"\n  serviceCIDRv6: \"\"\n  # Mask size for IPv4 Node CIDR in IPv4 or dual-stack cluster. Value ignored when enableNodeIPAM is false\n  # or when IPv4 Pod CIDR is not configured. Valid range is 16 to 30.\n  nodeCIDRMaskSizeIPv4: 24\n  # Mask size for IPv6 Node CIDR in IPv6 or dual-stack cluster. Value ignored when enableNodeIPAM is false\n  # or when IPv6 Pod CIDR is not configured. Valid range is 64 to 126.\n  nodeCIDRMaskSizeIPv6: 64\n\nipsecCSRSigner:\n  # Determines the auto-approve policy of Antrea CSR signer for IPsec certificates management.\n  # If enabled, Antrea will auto-approve the CertificateSingingRequest (CSR) if its subject and x509 extensions\n  # are permitted, and the requestor can be validated. If K8s `BoundServiceAccountTokenVolume` feature is enabled,\n  # the Pod identity will also be validated to provide maximum security.\n  # If set to false, Antrea will not auto-approve CertificateSingingRequests and they need to be approved\n  # manually by `kubectl certificate approve`.\n  autoApprove: true\n  # Indicates whether to use auto-generated self-signed CA certificate.\n  # If false, a Secret named \"antrea-ipsec-ca\" must be provided with the following keys:\n  #   tls.crt: <CA certificate>\n  #   tls.key: <CA private key>\n  selfSignedCA: true\n",
            "antreaImage": "antrea/antrea-ubi:v1.9.0",
            "antreaPlatform": "openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/wavefronthq/antrea-openshift-operator@sha256:9f49b07ff1623ff85d55ff51eaf1575b2ebe83d88f1d484ebbc44a5c38a74ef8",
      "bundle_path_digest": "sha256:9f49b07ff1623ff85d55ff51eaf1575b2ebe83d88f1d484ebbc44a5c38a74ef8",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-11-22T12:28:28.741000+00:00",
      "csv_description": "An operator which installs Antrea network CNI plugin on the Kubernetes cluster.",
      "csv_display_name": "Antrea Operator",
      "csv_metadata_description": "An operator which installs Antrea network CNI plugin on the Kubernetes cluster.",
      "csv_name": "antrea-operator-for-kubernetes.v1.9.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:03:06.130000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "antrea-operator-for-kubernetes",
      "provided_apis": [
        {
          "group": "operator.antrea.vmware.com",
          "kind": "AntreaInstall",
          "plural": "antreainstalls",
          "version": "v1"
        }
      ],
      "provider": "antrea.io",
      "related_images": [
        {
          "digest": "sha256:ce0420d1a534f94f682cedf92add736356bcc1b9fa1bd3b2731d4d27e69000c3",
          "image": "antrea/antrea-operator@sha256:ce0420d1a534f94f682cedf92add736356bcc1b9fa1bd3b2731d4d27e69000c3",
          "name": "antrea-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.9.0",
      "version_original": "1.9.0"
    },
    {
      "_id": "637cd8b1884420e0c62a0c45",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgentsAdmin",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "collector": {
                    "limits": {
                      "cpu": "2",
                      "memory": "2048Mi"
                    },
                    "requests": {
                      "cpu": "200m",
                      "memory": "500Mi"
                    }
                  },
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "prefix": "k8s",
            "role": "admin",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-admin-operator-bundle@sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "bundle_path_digest": "sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-22T14:12:01.723000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent Admin For Multi-tenancy**  installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.\nThe Application Administrator for each application team that uses a DX APM tenant installs the UMA Team capability by using **DX APM Universal Monitoring Agent Team For Multi-tenancy** operator and specifying the namespaces the team owns or wants to monitor.\n\nNote:  Currently UMA multi-tenancy deployment does not support other UMA monitoring capabilities, such as Prometheus metric ingestion,  probe auto-attach(node.js, php), AWS Monitoring, and the UMA for HTTP Collector\n\nFor more information: https://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Deploy-UMA-in-a-Multi-tenant-Environment.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgentsAdmin\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n   role: admin\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n         collector:\n           # The below properties define the resources for 'collector' deployment.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"2048Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"500Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent Admin For Multi-tenancy",
      "csv_metadata_description": "The DX APM Universal Monitoring Agent Admin For Multi-tenancy installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.",
      "csv_name": "uma-admin-operator.v2022.11.2-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T08:23:49.722000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "uma-admin-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgentsAdmin",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator-4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e-annotation"
        },
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "2022.11.2-11",
      "version_original": "2022.11.2-11"
    },
    {
      "_id": "637cd8b20ee97ebabe369be8",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgentsAdmin",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "collector": {
                    "limits": {
                      "cpu": "2",
                      "memory": "2048Mi"
                    },
                    "requests": {
                      "cpu": "200m",
                      "memory": "500Mi"
                    }
                  },
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "prefix": "k8s",
            "role": "admin",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-admin-operator-bundle@sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "bundle_path_digest": "sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-11-22T14:12:02.754000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent Admin For Multi-tenancy**  installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.\nThe Application Administrator for each application team that uses a DX APM tenant installs the UMA Team capability by using **DX APM Universal Monitoring Agent Team For Multi-tenancy** operator and specifying the namespaces the team owns or wants to monitor.\n\nNote:  Currently UMA multi-tenancy deployment does not support other UMA monitoring capabilities, such as Prometheus metric ingestion,  probe auto-attach(node.js, php), AWS Monitoring, and the UMA for HTTP Collector\n\nFor more information: https://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Deploy-UMA-in-a-Multi-tenant-Environment.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgentsAdmin\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n   role: admin\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n         collector:\n           # The below properties define the resources for 'collector' deployment.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"2048Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"500Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent Admin For Multi-tenancy",
      "csv_metadata_description": "The DX APM Universal Monitoring Agent Admin For Multi-tenancy installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.",
      "csv_name": "uma-admin-operator.v2022.11.2-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T08:23:38.450000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "uma-admin-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgentsAdmin",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator-4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e-annotation"
        },
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "2022.11.2-11",
      "version_original": "2022.11.2-11"
    },
    {
      "_id": "637cd8b3788768d1d6f22098",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgentsAdmin",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "collector": {
                    "limits": {
                      "cpu": "2",
                      "memory": "2048Mi"
                    },
                    "requests": {
                      "cpu": "200m",
                      "memory": "500Mi"
                    }
                  },
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "prefix": "k8s",
            "role": "admin",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-admin-operator-bundle@sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "bundle_path_digest": "sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "beta",
      "creation_date": "2022-11-22T14:12:03.749000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent Admin For Multi-tenancy**  installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.\nThe Application Administrator for each application team that uses a DX APM tenant installs the UMA Team capability by using **DX APM Universal Monitoring Agent Team For Multi-tenancy** operator and specifying the namespaces the team owns or wants to monitor.\n\nNote:  Currently UMA multi-tenancy deployment does not support other UMA monitoring capabilities, such as Prometheus metric ingestion,  probe auto-attach(node.js, php), AWS Monitoring, and the UMA for HTTP Collector\n\nFor more information: https://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Deploy-UMA-in-a-Multi-tenant-Environment.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgentsAdmin\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n   role: admin\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n         collector:\n           # The below properties define the resources for 'collector' deployment.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"2048Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"500Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent Admin For Multi-tenancy",
      "csv_metadata_description": "The DX APM Universal Monitoring Agent Admin For Multi-tenancy installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.",
      "csv_name": "uma-admin-operator.v2022.11.2-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T08:23:44.136000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "uma-admin-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgentsAdmin",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator-4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e-annotation"
        },
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "2022.11.2-11",
      "version_original": "2022.11.2-11"
    },
    {
      "_id": "637cd91c74e9f4cddfbeda3b",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgentsAdmin",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "collector": {
                    "limits": {
                      "cpu": "2",
                      "memory": "2048Mi"
                    },
                    "requests": {
                      "cpu": "200m",
                      "memory": "500Mi"
                    }
                  },
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "prefix": "k8s",
            "role": "admin",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-admin-operator-bundle@sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "bundle_path_digest": "sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "beta",
      "creation_date": "2022-11-22T14:13:48.154000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent Admin For Multi-tenancy**  installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.\nThe Application Administrator for each application team that uses a DX APM tenant installs the UMA Team capability by using **DX APM Universal Monitoring Agent Team For Multi-tenancy** operator and specifying the namespaces the team owns or wants to monitor.\n\nNote:  Currently UMA multi-tenancy deployment does not support other UMA monitoring capabilities, such as Prometheus metric ingestion,  probe auto-attach(node.js, php), AWS Monitoring, and the UMA for HTTP Collector\n\nFor more information: https://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Deploy-UMA-in-a-Multi-tenant-Environment.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgentsAdmin\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n   role: admin\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n         collector:\n           # The below properties define the resources for 'collector' deployment.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"2048Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"500Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent Admin For Multi-tenancy",
      "csv_metadata_description": "The DX APM Universal Monitoring Agent Admin For Multi-tenancy installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.",
      "csv_name": "uma-admin-operator.v2022.11.2-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T06:53:01.664000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "uma-admin-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgentsAdmin",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator-4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e-annotation"
        },
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2022.11.2-11",
      "version_original": "2022.11.2-11"
    },
    {
      "_id": "637cd91c74e9f4cddfbeda3f",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgentsAdmin",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "collector": {
                    "limits": {
                      "cpu": "2",
                      "memory": "2048Mi"
                    },
                    "requests": {
                      "cpu": "200m",
                      "memory": "500Mi"
                    }
                  },
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "prefix": "k8s",
            "role": "admin",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-admin-operator-bundle@sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "bundle_path_digest": "sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-22T14:13:48.826000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent Admin For Multi-tenancy**  installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.\nThe Application Administrator for each application team that uses a DX APM tenant installs the UMA Team capability by using **DX APM Universal Monitoring Agent Team For Multi-tenancy** operator and specifying the namespaces the team owns or wants to monitor.\n\nNote:  Currently UMA multi-tenancy deployment does not support other UMA monitoring capabilities, such as Prometheus metric ingestion,  probe auto-attach(node.js, php), AWS Monitoring, and the UMA for HTTP Collector\n\nFor more information: https://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Deploy-UMA-in-a-Multi-tenant-Environment.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgentsAdmin\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n   role: admin\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n         collector:\n           # The below properties define the resources for 'collector' deployment.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"2048Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"500Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent Admin For Multi-tenancy",
      "csv_metadata_description": "The DX APM Universal Monitoring Agent Admin For Multi-tenancy installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.",
      "csv_name": "uma-admin-operator.v2022.11.2-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T06:53:08.852000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "uma-admin-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgentsAdmin",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator-4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e-annotation"
        },
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2022.11.2-11",
      "version_original": "2022.11.2-11"
    },
    {
      "_id": "637cd91d884420e0c62a0d52",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgentsAdmin",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "collector": {
                    "limits": {
                      "cpu": "2",
                      "memory": "2048Mi"
                    },
                    "requests": {
                      "cpu": "200m",
                      "memory": "500Mi"
                    }
                  },
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "prefix": "k8s",
            "role": "admin",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-admin-operator-bundle@sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "bundle_path_digest": "sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-11-22T14:13:49.444000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent Admin For Multi-tenancy**  installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.\nThe Application Administrator for each application team that uses a DX APM tenant installs the UMA Team capability by using **DX APM Universal Monitoring Agent Team For Multi-tenancy** operator and specifying the namespaces the team owns or wants to monitor.\n\nNote:  Currently UMA multi-tenancy deployment does not support other UMA monitoring capabilities, such as Prometheus metric ingestion,  probe auto-attach(node.js, php), AWS Monitoring, and the UMA for HTTP Collector\n\nFor more information: https://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Deploy-UMA-in-a-Multi-tenant-Environment.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgentsAdmin\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n   role: admin\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n         collector:\n           # The below properties define the resources for 'collector' deployment.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"2048Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"500Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent Admin For Multi-tenancy",
      "csv_metadata_description": "The DX APM Universal Monitoring Agent Admin For Multi-tenancy installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.",
      "csv_name": "uma-admin-operator.v2022.11.2-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T06:52:55.094000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "uma-admin-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgentsAdmin",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator-4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e-annotation"
        },
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2022.11.2-11",
      "version_original": "2022.11.2-11"
    },
    {
      "_id": "637cdad15f23340823b24b50",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgentsAdmin",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "collector": {
                    "limits": {
                      "cpu": "2",
                      "memory": "2048Mi"
                    },
                    "requests": {
                      "cpu": "200m",
                      "memory": "500Mi"
                    }
                  },
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "prefix": "k8s",
            "role": "admin",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-admin-operator-bundle@sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "bundle_path_digest": "sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-11-22T14:21:05.791000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent Admin For Multi-tenancy**  installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.\nThe Application Administrator for each application team that uses a DX APM tenant installs the UMA Team capability by using **DX APM Universal Monitoring Agent Team For Multi-tenancy** operator and specifying the namespaces the team owns or wants to monitor.\n\nNote:  Currently UMA multi-tenancy deployment does not support other UMA monitoring capabilities, such as Prometheus metric ingestion,  probe auto-attach(node.js, php), AWS Monitoring, and the UMA for HTTP Collector\n\nFor more information: https://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Deploy-UMA-in-a-Multi-tenant-Environment.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgentsAdmin\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n   role: admin\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n         collector:\n           # The below properties define the resources for 'collector' deployment.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"2048Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"500Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent Admin For Multi-tenancy",
      "csv_metadata_description": "The DX APM Universal Monitoring Agent Admin For Multi-tenancy installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.",
      "csv_name": "uma-admin-operator.v2022.11.2-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T07:36:37.120000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "uma-admin-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgentsAdmin",
          "plural": "universalmonitoringagentsadmins",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator-4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e-annotation"
        },
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2022.11.2-11",
      "version_original": "2022.11.2-11"
    },
    {
      "_id": "637cdad740d971f5448a2c00",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgentsAdmin",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "collector": {
                    "limits": {
                      "cpu": "2",
                      "memory": "2048Mi"
                    },
                    "requests": {
                      "cpu": "200m",
                      "memory": "500Mi"
                    }
                  },
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "prefix": "k8s",
            "role": "admin",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-admin-operator-bundle@sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "bundle_path_digest": "sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-22T14:21:11.482000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent Admin For Multi-tenancy**  installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.\nThe Application Administrator for each application team that uses a DX APM tenant installs the UMA Team capability by using **DX APM Universal Monitoring Agent Team For Multi-tenancy** operator and specifying the namespaces the team owns or wants to monitor.\n\nNote:  Currently UMA multi-tenancy deployment does not support other UMA monitoring capabilities, such as Prometheus metric ingestion,  probe auto-attach(node.js, php), AWS Monitoring, and the UMA for HTTP Collector\n\nFor more information: https://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Deploy-UMA-in-a-Multi-tenant-Environment.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgentsAdmin\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n   role: admin\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n         collector:\n           # The below properties define the resources for 'collector' deployment.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"2048Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"500Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent Admin For Multi-tenancy",
      "csv_metadata_description": "The DX APM Universal Monitoring Agent Admin For Multi-tenancy installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.",
      "csv_name": "uma-admin-operator.v2022.11.2-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:40:27.879000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "uma-admin-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgentsAdmin",
          "plural": "universalmonitoringagentsadmins",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator-4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e-annotation"
        },
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2022.11.2-11",
      "version_original": "2022.11.2-11"
    },
    {
      "_id": "637cdadd884420e0c62a116a",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgentsAdmin",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "collector": {
                    "limits": {
                      "cpu": "2",
                      "memory": "2048Mi"
                    },
                    "requests": {
                      "cpu": "200m",
                      "memory": "500Mi"
                    }
                  },
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "prefix": "k8s",
            "role": "admin",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-admin-operator-bundle@sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "bundle_path_digest": "sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "beta",
      "creation_date": "2022-11-22T14:21:17.953000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent Admin For Multi-tenancy**  installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.\nThe Application Administrator for each application team that uses a DX APM tenant installs the UMA Team capability by using **DX APM Universal Monitoring Agent Team For Multi-tenancy** operator and specifying the namespaces the team owns or wants to monitor.\n\nNote:  Currently UMA multi-tenancy deployment does not support other UMA monitoring capabilities, such as Prometheus metric ingestion,  probe auto-attach(node.js, php), AWS Monitoring, and the UMA for HTTP Collector\n\nFor more information: https://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Deploy-UMA-in-a-Multi-tenant-Environment.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgentsAdmin\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n   role: admin\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n         collector:\n           # The below properties define the resources for 'collector' deployment.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"2048Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"500Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent Admin For Multi-tenancy",
      "csv_metadata_description": "The DX APM Universal Monitoring Agent Admin For Multi-tenancy installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.",
      "csv_name": "uma-admin-operator.v2022.11.2-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T07:30:23.509000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "uma-admin-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgentsAdmin",
          "plural": "universalmonitoringagentsadmins",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator-4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e-annotation"
        },
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2022.11.2-11",
      "version_original": "2022.11.2-11"
    },
    {
      "_id": "637cdb3b5556118ee8dfc142",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgentsAdmin",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "collector": {
                    "limits": {
                      "cpu": "2",
                      "memory": "2048Mi"
                    },
                    "requests": {
                      "cpu": "200m",
                      "memory": "500Mi"
                    }
                  },
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "prefix": "k8s",
            "role": "admin",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-admin-operator-bundle@sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "bundle_path_digest": "sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-11-22T14:22:51.249000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent Admin For Multi-tenancy**  installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.\nThe Application Administrator for each application team that uses a DX APM tenant installs the UMA Team capability by using **DX APM Universal Monitoring Agent Team For Multi-tenancy** operator and specifying the namespaces the team owns or wants to monitor.\n\nNote:  Currently UMA multi-tenancy deployment does not support other UMA monitoring capabilities, such as Prometheus metric ingestion,  probe auto-attach(node.js, php), AWS Monitoring, and the UMA for HTTP Collector\n\nFor more information: https://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Deploy-UMA-in-a-Multi-tenant-Environment.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgentsAdmin\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n   role: admin\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n         collector:\n           # The below properties define the resources for 'collector' deployment.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"2048Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"500Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent Admin For Multi-tenancy",
      "csv_metadata_description": "The DX APM Universal Monitoring Agent Admin For Multi-tenancy installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.",
      "csv_name": "uma-admin-operator.v2022.11.2-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T06:38:50.582000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "uma-admin-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgentsAdmin",
          "plural": "universalmonitoringagentsadmins",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator-4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e-annotation"
        },
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "2022.11.2-11",
      "version_original": "2022.11.2-11"
    },
    {
      "_id": "637cdb3dc96e3e7d20bb20d6",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgentsAdmin",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "collector": {
                    "limits": {
                      "cpu": "2",
                      "memory": "2048Mi"
                    },
                    "requests": {
                      "cpu": "200m",
                      "memory": "500Mi"
                    }
                  },
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "prefix": "k8s",
            "role": "admin",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-admin-operator-bundle@sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "bundle_path_digest": "sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "beta",
      "creation_date": "2022-11-22T14:22:53.498000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent Admin For Multi-tenancy**  installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.\nThe Application Administrator for each application team that uses a DX APM tenant installs the UMA Team capability by using **DX APM Universal Monitoring Agent Team For Multi-tenancy** operator and specifying the namespaces the team owns or wants to monitor.\n\nNote:  Currently UMA multi-tenancy deployment does not support other UMA monitoring capabilities, such as Prometheus metric ingestion,  probe auto-attach(node.js, php), AWS Monitoring, and the UMA for HTTP Collector\n\nFor more information: https://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Deploy-UMA-in-a-Multi-tenant-Environment.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgentsAdmin\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n   role: admin\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n         collector:\n           # The below properties define the resources for 'collector' deployment.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"2048Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"500Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent Admin For Multi-tenancy",
      "csv_metadata_description": "The DX APM Universal Monitoring Agent Admin For Multi-tenancy installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.",
      "csv_name": "uma-admin-operator.v2022.11.2-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T06:38:58.067000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "uma-admin-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgentsAdmin",
          "plural": "universalmonitoringagentsadmins",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator-4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e-annotation"
        },
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "2022.11.2-11",
      "version_original": "2022.11.2-11"
    },
    {
      "_id": "637cdb3fc96e3e7d20bb20e2",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgentsAdmin",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "collector": {
                    "limits": {
                      "cpu": "2",
                      "memory": "2048Mi"
                    },
                    "requests": {
                      "cpu": "200m",
                      "memory": "500Mi"
                    }
                  },
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "prefix": "k8s",
            "role": "admin",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-admin-operator-bundle@sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "bundle_path_digest": "sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-22T14:22:55.699000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent Admin For Multi-tenancy**  installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.\nThe Application Administrator for each application team that uses a DX APM tenant installs the UMA Team capability by using **DX APM Universal Monitoring Agent Team For Multi-tenancy** operator and specifying the namespaces the team owns or wants to monitor.\n\nNote:  Currently UMA multi-tenancy deployment does not support other UMA monitoring capabilities, such as Prometheus metric ingestion,  probe auto-attach(node.js, php), AWS Monitoring, and the UMA for HTTP Collector\n\nFor more information: https://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Deploy-UMA-in-a-Multi-tenant-Environment.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgentsAdmin\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n   role: admin\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n         collector:\n           # The below properties define the resources for 'collector' deployment.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"2048Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"500Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent Admin For Multi-tenancy",
      "csv_metadata_description": "The DX APM Universal Monitoring Agent Admin For Multi-tenancy installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.",
      "csv_name": "uma-admin-operator.v2022.11.2-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T06:39:04.071000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "uma-admin-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgentsAdmin",
          "plural": "universalmonitoringagentsadmins",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator-4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e-annotation"
        },
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "2022.11.2-11",
      "version_original": "2022.11.2-11"
    },
    {
      "_id": "637cdb6140d971f5448a2d6e",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgentsAdmin",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "collector": {
                    "limits": {
                      "cpu": "2",
                      "memory": "2048Mi"
                    },
                    "requests": {
                      "cpu": "200m",
                      "memory": "500Mi"
                    }
                  },
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "prefix": "k8s",
            "role": "admin",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-admin-operator-bundle@sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "bundle_path_digest": "sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-11-22T14:23:29.811000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent Admin For Multi-tenancy**  installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.\nThe Application Administrator for each application team that uses a DX APM tenant installs the UMA Team capability by using **DX APM Universal Monitoring Agent Team For Multi-tenancy** operator and specifying the namespaces the team owns or wants to monitor.\n\nNote:  Currently UMA multi-tenancy deployment does not support other UMA monitoring capabilities, such as Prometheus metric ingestion,  probe auto-attach(node.js, php), AWS Monitoring, and the UMA for HTTP Collector\n\nFor more information: https://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Deploy-UMA-in-a-Multi-tenant-Environment.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgentsAdmin\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n   role: admin\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n         collector:\n           # The below properties define the resources for 'collector' deployment.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"2048Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"500Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent Admin For Multi-tenancy",
      "csv_metadata_description": "The DX APM Universal Monitoring Agent Admin For Multi-tenancy installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.",
      "csv_name": "uma-admin-operator.v2022.11.2-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T07:30:26.581000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "uma-admin-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgentsAdmin",
          "plural": "universalmonitoringagentsadmins",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator-4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e-annotation"
        },
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2022.11.2-11",
      "version_original": "2022.11.2-11"
    },
    {
      "_id": "637cdb6274e9f4cddfbedff3",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgentsAdmin",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "collector": {
                    "limits": {
                      "cpu": "2",
                      "memory": "2048Mi"
                    },
                    "requests": {
                      "cpu": "200m",
                      "memory": "500Mi"
                    }
                  },
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "prefix": "k8s",
            "role": "admin",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-admin-operator-bundle@sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "bundle_path_digest": "sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "beta",
      "creation_date": "2022-11-22T14:23:30.428000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent Admin For Multi-tenancy**  installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.\nThe Application Administrator for each application team that uses a DX APM tenant installs the UMA Team capability by using **DX APM Universal Monitoring Agent Team For Multi-tenancy** operator and specifying the namespaces the team owns or wants to monitor.\n\nNote:  Currently UMA multi-tenancy deployment does not support other UMA monitoring capabilities, such as Prometheus metric ingestion,  probe auto-attach(node.js, php), AWS Monitoring, and the UMA for HTTP Collector\n\nFor more information: https://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Deploy-UMA-in-a-Multi-tenant-Environment.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgentsAdmin\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n   role: admin\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n         collector:\n           # The below properties define the resources for 'collector' deployment.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"2048Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"500Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent Admin For Multi-tenancy",
      "csv_metadata_description": "The DX APM Universal Monitoring Agent Admin For Multi-tenancy installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.",
      "csv_name": "uma-admin-operator.v2022.11.2-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T07:30:28.155000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "uma-admin-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgentsAdmin",
          "plural": "universalmonitoringagentsadmins",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator-4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e-annotation"
        },
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2022.11.2-11",
      "version_original": "2022.11.2-11"
    },
    {
      "_id": "637cdb6374e9f4cddfbedff6",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgentsAdmin",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "EnableResourceLimits": true,
            "agentManager": {
              "credential": "",
              "httpProxy": {},
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                },
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/storage"
                },
                {
                  "effect": "NoSchedule",
                  "operator": "Exists"
                },
                {
                  "effect": "NoExecute",
                  "operator": "Exists"
                }
              ]
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "3096Mi"
                },
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "800Mi"
                }
              },
              "container": {
                "dockerstats": {
                  "collector": {
                    "limits": {
                      "cpu": "2",
                      "memory": "2048Mi"
                    },
                    "requests": {
                      "cpu": "200m",
                      "memory": "500Mi"
                    }
                  },
                  "daemonset": {
                    "apmia": {
                      "epagent": {
                        "port": 8889
                      }
                    },
                    "limits": {
                      "cpu": "2",
                      "memory": "1024Mi"
                    },
                    "privileged": true,
                    "requests": {
                      "cpu": "200m",
                      "memory": "300Mi"
                    }
                  },
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  },
                  "limits": {
                    "cpu": "2",
                    "memory": "1024Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "300Mi"
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "prefix": "k8s",
            "role": "admin",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-admin-operator-bundle@sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "bundle_path_digest": "sha256:b973c8ee827e28f9459a2d789cd674b0c7c365a2ce31286b61f89d4be276a3f8",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-22T14:23:31.021000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent Admin For Multi-tenancy**  installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.\nThe Application Administrator for each application team that uses a DX APM tenant installs the UMA Team capability by using **DX APM Universal Monitoring Agent Team For Multi-tenancy** operator and specifying the namespaces the team owns or wants to monitor.\n\nNote:  Currently UMA multi-tenancy deployment does not support other UMA monitoring capabilities, such as Prometheus metric ingestion,  probe auto-attach(node.js, php), AWS Monitoring, and the UMA for HTTP Collector\n\nFor more information: https://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Deploy-UMA-in-a-Multi-tenant-Environment.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgentsAdmin\n metadata:\n   name: uma-monitor\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n     httpProxy:\n       host:\n       port:\n       username:\n       password:\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   prefix: k8s\n   openshift311Support: false\n   EnableResourceLimits: true\n   role: admin\n\n   monitor:\n     application:\n       autoattach:\n         filterType: whitelist\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             url: \"\"\n             username: \"\"\n             password: \"\"\n             token: \"\"\n             configFiles: \"\"\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name: \"\"\n             value: \"\"\n           custom:\n             promqlConfigMap: custom-promql-config\n         # The below properties define the resources for 'cluster-performance-prometheus' deployment that is responsible for\n         # Prometheus metrics ingestion.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n\n       dockerstats:\n         enabled: true\n         daemonset:\n           privileged: true\n           # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n           apmia:\n             epagent:\n               port: 8889\n           # The below properties define the resources for 'app-container-monitor' daemonset.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"1024Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"300Mi\"\n         collector:\n           # The below properties define the resources for 'collector' deployment.\n           limits:\n             cpu: \"2\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"2048Mi\"\n           requests:\n             cpu: \"200m\"\n             # Assign memory resources in 'Mi'(mebibytes) units only.\n             memory: \"500Mi\"\n     clusterPerformance:\n       enabled: true\n       # The below properties define the resources for 'clusterinfo' deployment.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"3096Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"800Mi\"\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'container-monitor' deployment that is responsible for\n         # posting the K8s/OpenShift Cluster performance metrics, map data etc.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"1024Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"300Mi\"\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment or daemonset\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey: \"\"\n       secretKey: \"\"\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList: \"\"\n       # The below properties define the resources for AWS monitoring deployment 'aws-monitor'\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/storage\"\n       - effect: \"NoSchedule\"\n         operator: \"Exists\"\n       - effect: \"NoExecute\"\n         operator: \"Exists\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent Admin For Multi-tenancy",
      "csv_metadata_description": "The DX APM Universal Monitoring Agent Admin For Multi-tenancy installs the UMA Admin deployment on a cluster. This deployment is required for the Cluster Administrator to view the DX APM cluster performance metrics. This UMA Admin capability provides the Cluster Administrator with complete cluster monitoring visibility. Installing the UMA Admin deployment requires admin privileges and the Application Administrator install the UMA Team capability.",
      "csv_name": "uma-admin-operator.v2022.11.2-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:30:30.051000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "uma-admin-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgentsAdmin",
          "plural": "universalmonitoringagentsadmins",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator-4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e-annotation"
        },
        {
          "digest": "sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:4cb838cdabf97e31504271715a42c3af72463a47161e5c14444792ee35fe8e0e",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2022.11.2-11",
      "version_original": "2022.11.2-11"
    },
    {
      "_id": "637cdfde5f23340823b25aab",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com1/v1alpha1",
          "kind": "UniversalMonitoringAgentsTeam",
          "metadata": {
            "name": "uma-monitor-team"
          },
          "spec": {
            "adminNamespaceName": "broadcom-aiops",
            "agentManager": {
              "credential": "",
              "tenantID": "",
              "url": "localhost:5001"
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master",
                  "operator": "",
                  "value": ""
                }
              ]
            },
            "monitor": {
              "application": {
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "2048Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "800Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                }
              },
              "container": {
                "dockerstats": {
                  "enabled": true
                }
              },
              "events": {
                "enabled": false
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                }
              }
            },
            "namespaces": "",
            "role": "team",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-team-operator-bundle@sha256:7fd74845057b1e1b15239afcac12e02b77d33be96d50565786aabfbcbf260589",
      "bundle_path_digest": "sha256:7fd74845057b1e1b15239afcac12e02b77d33be96d50565786aabfbcbf260589",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-11-22T14:42:38.597000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent Team For Multi-tenancy** installed by Application Administrator. Each application team that uses a DX APM tenant installs the UMA Team capability, specifying the namespaces the team owns or wants to monitor. UMA Team acts as a client, using a REST API to pull the namespace performance data from the UMA Admin deployment(DX APM Universal Monitoring Agent Team For Multi-tenancy). The UMA Team capability reports the application, pod, and node performance metrics only for the specified namespaces. This capability limits your application teams to seeing performance metrics only for their applications running in different environments on the tenant. Example environments include development, verification, pre-production, and production.\n\n**Prerequisite:**\n   1. The **DX APM Universal Monitoring Agent Team For Multi-tenancy** operator needs to be installed by the Cluster Administrator before UMA Team is installed.\n   2. UMA Team acts as a client, using a REST API to pull the namespace performance data from the UMA Admin deployment. So any network policy that restricts the communication to the Services running in the UMA Admin namespace, needs to be updated to allow the traffic from UMA team.\n\nFor more information: https://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Deploy-UMA-in-a-Multi-tenant-Environment.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com1/v1alpha1\n kind: UniversalMonitoringAgentsTeam\n metadata:\n   name: uma-monitor-team\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     tenantID: \"\"\n\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   role: team\n   namespaces: \"\"\n   adminNamespaceName: broadcom-aiops\n\n   monitor:\n     application:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n     container:\n       dockerstats:\n         enabled: true\n     clusterPerformance:\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'broadcom-monitor' deployment that does cluster and container monitoring.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"2048Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"800Mi\"\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n     node:\n       enabled: true\n       # The below properties define the resources for 'broadcom-monitor-host' deployment that does host monitoring.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n         operator: \"\"\n         value: \"\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent Team For Multi-tenancy",
      "csv_metadata_description": "DX APM Universal Monitoring Agent Team For Multi-tenancy acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes given namespaces.",
      "csv_name": "uma-team-operator.v2022.11.2-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T08:27:57.315000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "uma-team-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com1",
          "kind": "UniversalMonitoringAgentsTeam",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:152985e9cd88b827000dd95e7dae47d6bbdd583d13b6f4dab21ef24e585da706",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:152985e9cd88b827000dd95e7dae47d6bbdd583d13b6f4dab21ef24e585da706",
          "name": "uma-operator-152985e9cd88b827000dd95e7dae47d6bbdd583d13b6f4dab21ef24e585da706-annotation"
        },
        {
          "digest": "sha256:152985e9cd88b827000dd95e7dae47d6bbdd583d13b6f4dab21ef24e585da706",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:152985e9cd88b827000dd95e7dae47d6bbdd583d13b6f4dab21ef24e585da706",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "2022.11.2-11",
      "version_original": "2022.11.2-11"
    },
    {
      "_id": "637cdfdfc96e3e7d20bb2f02",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com1/v1alpha1",
          "kind": "UniversalMonitoringAgentsTeam",
          "metadata": {
            "name": "uma-monitor-team"
          },
          "spec": {
            "adminNamespaceName": "broadcom-aiops",
            "agentManager": {
              "credential": "",
              "tenantID": "",
              "url": "localhost:5001"
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master",
                  "operator": "",
                  "value": ""
                }
              ]
            },
            "monitor": {
              "application": {
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "2048Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "800Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                }
              },
              "container": {
                "dockerstats": {
                  "enabled": true
                }
              },
              "events": {
                "enabled": false
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                }
              }
            },
            "namespaces": "",
            "role": "team",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-team-operator-bundle@sha256:7fd74845057b1e1b15239afcac12e02b77d33be96d50565786aabfbcbf260589",
      "bundle_path_digest": "sha256:7fd74845057b1e1b15239afcac12e02b77d33be96d50565786aabfbcbf260589",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "beta",
      "creation_date": "2022-11-22T14:42:39.956000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent Team For Multi-tenancy** installed by Application Administrator. Each application team that uses a DX APM tenant installs the UMA Team capability, specifying the namespaces the team owns or wants to monitor. UMA Team acts as a client, using a REST API to pull the namespace performance data from the UMA Admin deployment(DX APM Universal Monitoring Agent Team For Multi-tenancy). The UMA Team capability reports the application, pod, and node performance metrics only for the specified namespaces. This capability limits your application teams to seeing performance metrics only for their applications running in different environments on the tenant. Example environments include development, verification, pre-production, and production.\n\n**Prerequisite:**\n   1. The **DX APM Universal Monitoring Agent Team For Multi-tenancy** operator needs to be installed by the Cluster Administrator before UMA Team is installed.\n   2. UMA Team acts as a client, using a REST API to pull the namespace performance data from the UMA Admin deployment. So any network policy that restricts the communication to the Services running in the UMA Admin namespace, needs to be updated to allow the traffic from UMA team.\n\nFor more information: https://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Deploy-UMA-in-a-Multi-tenant-Environment.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com1/v1alpha1\n kind: UniversalMonitoringAgentsTeam\n metadata:\n   name: uma-monitor-team\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     tenantID: \"\"\n\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   role: team\n   namespaces: \"\"\n   adminNamespaceName: broadcom-aiops\n\n   monitor:\n     application:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n     container:\n       dockerstats:\n         enabled: true\n     clusterPerformance:\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'broadcom-monitor' deployment that does cluster and container monitoring.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"2048Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"800Mi\"\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n     node:\n       enabled: true\n       # The below properties define the resources for 'broadcom-monitor-host' deployment that does host monitoring.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n         operator: \"\"\n         value: \"\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent Team For Multi-tenancy",
      "csv_metadata_description": "DX APM Universal Monitoring Agent Team For Multi-tenancy acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes given namespaces.",
      "csv_name": "uma-team-operator.v2022.11.2-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-11-23T08:28:03.645000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "uma-team-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com1",
          "kind": "UniversalMonitoringAgentsTeam",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:152985e9cd88b827000dd95e7dae47d6bbdd583d13b6f4dab21ef24e585da706",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:152985e9cd88b827000dd95e7dae47d6bbdd583d13b6f4dab21ef24e585da706",
          "name": "uma-operator-152985e9cd88b827000dd95e7dae47d6bbdd583d13b6f4dab21ef24e585da706-annotation"
        },
        {
          "digest": "sha256:152985e9cd88b827000dd95e7dae47d6bbdd583d13b6f4dab21ef24e585da706",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:152985e9cd88b827000dd95e7dae47d6bbdd583d13b6f4dab21ef24e585da706",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "2022.11.2-11",
      "version_original": "2022.11.2-11"
    },
    {
      "_id": "637cdfe040d971f5448a3b42",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com1/v1alpha1",
          "kind": "UniversalMonitoringAgentsTeam",
          "metadata": {
            "name": "uma-monitor-team"
          },
          "spec": {
            "adminNamespaceName": "broadcom-aiops",
            "agentManager": {
              "credential": "",
              "tenantID": "",
              "url": "localhost:5001"
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master",
                  "operator": "",
                  "value": ""
                }
              ]
            },
            "monitor": {
              "application": {
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "2048Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "800Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                }
              },
              "container": {
                "dockerstats": {
                  "enabled": true
                }
              },
              "events": {
                "enabled": false
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                }
              }
            },
            "namespaces": "",
            "role": "team",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-team-operator-bundle@sha256:7fd74845057b1e1b15239afcac12e02b77d33be96d50565786aabfbcbf260589",
      "bundle_path_digest": "sha256:7fd74845057b1e1b15239afcac12e02b77d33be96d50565786aabfbcbf260589",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-22T14:42:40.453000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent Team For Multi-tenancy** installed by Application Administrator. Each application team that uses a DX APM tenant installs the UMA Team capability, specifying the namespaces the team owns or wants to monitor. UMA Team acts as a client, using a REST API to pull the namespace performance data from the UMA Admin deployment(DX APM Universal Monitoring Agent Team For Multi-tenancy). The UMA Team capability reports the application, pod, and node performance metrics only for the specified namespaces. This capability limits your application teams to seeing performance metrics only for their applications running in different environments on the tenant. Example environments include development, verification, pre-production, and production.\n\n**Prerequisite:**\n   1. The **DX APM Universal Monitoring Agent Team For Multi-tenancy** operator needs to be installed by the Cluster Administrator before UMA Team is installed.\n   2. UMA Team acts as a client, using a REST API to pull the namespace performance data from the UMA Admin deployment. So any network policy that restricts the communication to the Services running in the UMA Admin namespace, needs to be updated to allow the traffic from UMA team.\n\nFor more information: https://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Deploy-UMA-in-a-Multi-tenant-Environment.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com1/v1alpha1\n kind: UniversalMonitoringAgentsTeam\n metadata:\n   name: uma-monitor-team\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     tenantID: \"\"\n\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   role: team\n   namespaces: \"\"\n   adminNamespaceName: broadcom-aiops\n\n   monitor:\n     application:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n     container:\n       dockerstats:\n         enabled: true\n     clusterPerformance:\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'broadcom-monitor' deployment that does cluster and container monitoring.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"2048Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"800Mi\"\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n     node:\n       enabled: true\n       # The below properties define the resources for 'broadcom-monitor-host' deployment that does host monitoring.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n         operator: \"\"\n         value: \"\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent Team For Multi-tenancy",
      "csv_metadata_description": "DX APM Universal Monitoring Agent Team For Multi-tenancy acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes given namespaces.",
      "csv_name": "uma-team-operator.v2022.11.2-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T08:27:50.478000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "uma-team-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com1",
          "kind": "UniversalMonitoringAgentsTeam",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:152985e9cd88b827000dd95e7dae47d6bbdd583d13b6f4dab21ef24e585da706",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:152985e9cd88b827000dd95e7dae47d6bbdd583d13b6f4dab21ef24e585da706",
          "name": "uma-operator-152985e9cd88b827000dd95e7dae47d6bbdd583d13b6f4dab21ef24e585da706-annotation"
        },
        {
          "digest": "sha256:152985e9cd88b827000dd95e7dae47d6bbdd583d13b6f4dab21ef24e585da706",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:152985e9cd88b827000dd95e7dae47d6bbdd583d13b6f4dab21ef24e585da706",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "2022.11.2-11",
      "version_original": "2022.11.2-11"
    },
    {
      "_id": "637ce01574e9f4cddfbeee62",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com1/v1alpha1",
          "kind": "UniversalMonitoringAgentsTeam",
          "metadata": {
            "name": "uma-monitor-team"
          },
          "spec": {
            "adminNamespaceName": "broadcom-aiops",
            "agentManager": {
              "credential": "",
              "tenantID": "",
              "url": "localhost:5001"
            },
            "clusterName": "DevelopmentCluster",
            "globalDeployment": {
              "nodeAffinity": {},
              "nodeSelector": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master",
                  "operator": "",
                  "value": ""
                }
              ]
            },
            "monitor": {
              "application": {
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "limits": {
                    "cpu": "2",
                    "memory": "2048Mi"
                  },
                  "requests": {
                    "cpu": "200m",
                    "memory": "800Mi"
                  },
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                }
              },
              "container": {
                "dockerstats": {
                  "enabled": true
                }
              },
              "events": {
                "enabled": false
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true,
                "limits": {
                  "cpu": "2",
                  "memory": "1024Mi"
                },
                "requests": {
                  "cpu": "200m",
                  "memory": "300Mi"
                }
              }
            },
            "namespaces": "",
            "role": "team",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-team-operator-bundle@sha256:7fd74845057b1e1b15239afcac12e02b77d33be96d50565786aabfbcbf260589",
      "bundle_path_digest": "sha256:7fd74845057b1e1b15239afcac12e02b77d33be96d50565786aabfbcbf260589",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-11-22T14:43:33.440000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent Team For Multi-tenancy** installed by Application Administrator. Each application team that uses a DX APM tenant installs the UMA Team capability, specifying the namespaces the team owns or wants to monitor. UMA Team acts as a client, using a REST API to pull the namespace performance data from the UMA Admin deployment(DX APM Universal Monitoring Agent Team For Multi-tenancy). The UMA Team capability reports the application, pod, and node performance metrics only for the specified namespaces. This capability limits your application teams to seeing performance metrics only for their applications running in different environments on the tenant. Example environments include development, verification, pre-production, and production.\n\n**Prerequisite:**\n   1. The **DX APM Universal Monitoring Agent Team For Multi-tenancy** operator needs to be installed by the Cluster Administrator before UMA Team is installed.\n   2. UMA Team acts as a client, using a REST API to pull the namespace performance data from the UMA Admin deployment. So any network policy that restricts the communication to the Services running in the UMA Admin namespace, needs to be updated to allow the traffic from UMA team.\n\nFor more information: https://techdocs.broadcom.com/us/en/ca-enterprise-software/it-operations-management/dx-apm-agents/SaaS/Universal-Monitoring-Agent/Install-the-Universal-Monitoring-Agent/Deploy-UMA-in-a-Multi-tenant-Environment.html\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com1/v1alpha1\n kind: UniversalMonitoringAgentsTeam\n metadata:\n   name: uma-monitor-team\n spec:\n   agentManager:\n     url: localhost:5001\n     credential: \"\"\n     tenantID: \"\"\n\n   # Name of the cluster.\n   clusterName: DevelopmentCluster\n   # Cluster type, either Kubernetes or OpenShift.\n   type: Kubernetes\n   role: team\n   namespaces: \"\"\n   adminNamespaceName: broadcom-aiops\n\n   monitor:\n     application:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: false\n     container:\n       dockerstats:\n         enabled: true\n     clusterPerformance:\n       dataReporter:\n         vertex:\n           ttl: 720\n           refreshInterval: 360\n         # The below properties define the resources for 'broadcom-monitor' deployment that does cluster and container monitoring.\n         limits:\n           cpu: \"2\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"2048Mi\"\n         requests:\n           cpu: \"200m\"\n           # Assign memory resources in 'Mi'(mebibytes) units only.\n           memory: \"800Mi\"\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n           # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n           # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n       # The below properties define the resources for 'apm-kafka-monitor' deployment\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n     node:\n       enabled: true\n       # The below properties define the resources for 'broadcom-monitor-host' deployment that does host monitoring.\n       limits:\n         cpu: \"2\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"1024Mi\"\n       requests:\n         cpu: \"200m\"\n         # Assign memory resources in 'Mi'(mebibytes) units only.\n         memory: \"300Mi\"\n\n   globalDeployment:\n     # Node affinity rules for UMA Pods\n     # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity\n     nodeAffinity: {}\n\n     # Node labels for UMA Pods\n     # Ref: https://kubernetes.io/docs/user-guide/node-selection/\n     nodeSelector: {}\n\n     # Additional tolerations for UMA pods\n     # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\n     # Default toleration used by UMA\n     tolerations:\n       - effect: \"NoSchedule\"\n         key: \"node-role.kubernetes.io/master\"\n         operator: \"\"\n         value: \"\"\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent Team For Multi-tenancy",
      "csv_metadata_description": "DX APM Universal Monitoring Agent Team For Multi-tenancy acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes given namespaces.",
      "csv_name": "uma-team-operator.v2022.11.2-11",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-11-23T07:07:56.814000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "uma-team-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com1",
          "kind": "UniversalMonitoringAgentsTeam",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:152985e9cd88b827000dd95e7dae47d6bbdd583d13b6f4dab21ef24e585da706",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:152985e9cd88b827000dd95e7dae47d6bbdd583d13b6f4dab21ef24e585da706",
          "name": "uma-operator-152985e9cd88b827000dd95e7dae47d6bbdd583d13b6f4dab21ef24e585da706-annotation"
        },
        {
          "digest": "sha256:152985e9cd88b827000dd95e7dae47d6bbdd583d13b6f4dab21ef24e585da706",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:152985e9cd88b827000dd95e7dae47d6bbdd583d13b6f4dab21ef24e585da706",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:6d6e7d9f0c662c0b24b7a3d0ac1d8526305ad17144c8e23b462965bce8e4d45e",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.11.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2022.11.2-11",
      "version_original": "2022.11.2-11"
    }
  ]
}
